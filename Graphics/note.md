그래픽스
========

숙제는 그 날 밤 자정 12시까지

### 쳌

1.  D. Hearn and M.P. Baker, Computer Graphics with OpenGL, 3rd edition, Prentice Hall
2.  Steven Gortler, Foundations of 3D Computer Graphics, MIT Press
3.  OpenGL Programming Guide, Addison Wesley. This book is available online at
    http://fly.srk.fer.hr/~unreal/theredbook/

### Prerequisites

A good knowledge on C or C++ programming

### What is computer graphics?

좁은 정의

..

넓은 정의: Interactive Computer Graphics

-   Man-machine graphical communication
    * Ivan Sutherland's Sketchpad
-   "Interactivity" is as important as "visual output"
-   Nowadays, the term computer graphics includes almost everything on computers
    that is not text

### Sketchpad (Ivan Sutherland 1963)

*   The first program ever to utilize a complete graphical user interface using
    CRT and light pen
*   펀치카드, 배치 프로세스 시절 라이트 펜을 만들어서 그림을 그리는 시스템을
    만들었음.
*   한낱 계산기에 불과하던 컴퓨터에 Interactivity 를 부여함

### A Brief History of Computer Graphics

1885: CRT

1960: William F. Boeing coins "Computer Graphics"

1961: John Whitney, Intro to Alfred Hitchcock's Vertigo

1961: Spacewars, 1st video game, 이즈음에 삼각함수 계산이 가능한 벡스 컴퓨터들이
등장해서 비디오게임이 등장하기 시작함

1974: z-buffer, Ed Catmull, 원래 교수였다가 현재 픽사의 사장

1975: Phong shading

1980: Tron, 1st feature film by CG

Mid 1980's: GUI의 등장

1986: Luxo Jr. nominated for Oscar. 픽사 로고에 뛰는 램프가 있는 이유. 이거
만든사람 감독이 지금 디즈니 부사장 (빅히어로, 토이스토리, ...)

1995: Toy Story, 1st full CG feature film

1999: Cheap consumer 3D graphics == 그래픽카드의 등장. 이 전까지는 그래픽스
연구를 하려면 각자 자기 책상 앞에 3천만원짜리, 2억원짜리 장비를 놓아야 했음.

### What is Computer Graphics About?

*   In 1980, **Holy Grail**, Big agenda of computer graphics: Replicate the real world in computers

    = Done.

*   21세기: Visualize your imagination in computers.
*   CG = Reality + Imagination
*   근데 지금 헐리웃에 가서 특수효과팀에 가서 얘기를 하면, 이미 당신이 무슨
    생각을 하던 내가 모두 화면에 띄울수 있다고 말한다.
*   또 다른 Goal 이 필요해짐

*   Now: 내가 현실에서 가지고온것, 그리고 그것을 상상과 함친것, 그것을 다시
    현실에 갔다놓는것이 지금시대의 목표.
*   저(교수)는 20년동안 이 분야에 있어왔는데 큰 Goal이 두번 바뀌는것을 보았다.
    그리고 또 목표가 어떻게 바뀔지 모르겠다. 하지만 여러분들은 이제 그 첫번째
    단계를 배우게될것이다.

*   이 과목을 통해서는 1970년대까지 커버할수있을것이다. 그 이후의것은 교과서에
    잘 안들어감. 지금 연구의 수준은, 컴퓨터 그래픽스라는건 굉장히 독특한 성격이
    있어서 컴퓨터그래픽스는 옛날부터 융합적인 성격을 띄어왔다. 어느 분야에서든
    그분야에서 진짜 잘하는사람 - 기하학의 완전 대가, 컴퓨테이셔널 유체역학의
    완전 대가 - 어느시점에 다다르면 다 컴퓨터그래픽스에 와서 논문을
    내고싶어한다. 한마디로, 그래픽스는 온갖분야의 사람들이 와서 다 논문을 낸다 -
    주제가 다 여러분야로 퍼져서, 그래픽스를 공부하는사람들은 다 분야가 아주
    넓다. 오만갖 분야의 내용들이 뒤섞여있고 그럼. 그러면 도대체 교과서를 어떻게
    쓰느냐 - 교과서를 백과사전으로 만드느냐 - 그래서 근래의 내용은 교과서에 잘
    안넣음. 수업시간으로 배우는 그래픽스는 다 Old fassioned.

> 3월 5일

옛날 이야기
--------

*   CRT

    이제는 소니밖에 안만듬

*   빛의 3원색?

    3원색이 아님, 3개면 사람이 인식할수있는 색공간을 대부분 커버가능

*   Vecter CRT vs Raster CRT

    메모리가 너무 비싸서 래스터 CRT를 쓸 수 없었음. 그리는것이 많아질수록
    주사율이 낮아짐.

*   Scan conversion

    화면에 라인바이 라인으로, 윗쪽부터 그리기 시작함.

*   Frame buffer

*   Color depth

    1bit, 8bit, 15-16bit, 24bit 순으로 발전해옴, 이 뒤로 15년간 발전 안해옴.
    최근 몇몇 디스플레이는 96비트를 지원함.

*   주사율

    1930년대에도 이미 24프레임으로 촬영해옴, 그뒤로 발전이 없다가 3년전 호빗이
    초당 48프레임으로 발전.

    최근 영화관에서 영화를 보는것에 대한 큰 이득이 없어져서, 영화관에서 새로운
    시도를 하는데 그중하나가 3D이고, 나머지 하나가 48프레임.

    근데 아직 블루레이도 48프레임 지원을 안해서 극장이 아니면 보기 힘듬.

*   Color lookup table

*   Deeper Frame buffer

    색에 24비트, 알파채널에 8비트, z버퍼에 16비트, 더블버퍼링

    (24 + 8 + 16)*2 = 96

*   Interlacing

    홀/짝 따로 그림. Prograssive scaning 으로 대체됨 (그냥 구분안하고 다 제때
    60Hz로 그리는거)

*   Display Processor

    Frame buffer가 시스템 메모리에 직접 들어있는건 애플2 시절 이야기.

    지금은 Frame buffer가 System bus 밖으로 빠져있고 별도의 하드웨어에 들어있음.
    근데 이것도 옛날이야기.

    GPU엔 디스플레이 프로세서도 있고, 프로세서도 있고 비디오 컨트롤러도 있는데
    디스플레이 프로세서가 엄청 크고 자기 자체의 메모리, BUS 를 가짐

*   인텔

    GPU 회사들은 전적으로 병렬 프로세서에 기대고 있었음. 인텔은 70년대에
    병렬처리에 대한 가능성을 믿지 않았고, 클럭스피드를 미친듯이 올리기 시작.
    클럭스피드를 올리는 제일 쉬운방법은 회선 굵기를 줄이는것. 지금 시그널당
    들어가는 전자 갯수가 100개 단위. 물리적인 한계에 도착해서 이제 인텔은 뒤늦게
    GPU 시장에 들어가기 시작.

*   Flat Panel Displays

    - Thin, light
    - Flicker free
    - Narrower color gamut? Not anymore

*   OpenGL

    실리콘 그래픽스에서 만든 GL (그래픽 워크스테이션 만드는 회사) 이라는
    라이브러리가 있었는데, 그 회사가 없어지기 전 이 라이브러리를 오픈했고

    산업계에서 이걸 표준화해서 (위원회를 거친것은 아님) OpenGL 로 만듬

Affine Geometric
--------

> 3월 12일

Geometric Transformations
--------

* Linear transformation
* Rigid transformation
* Affine transformation
* Projective transformation

### Linear Transformations

어떤 Vector들의 Combination을 Linear Transformation한것이나,
어떤 Vector들의 Transformations들을 Combine한것이나 같을경우

Linear combination is invariant under *T*

T(v) = M33 v31 (Column major)
     = v13 N33 (Row major)

교과서는 칼럼메이저로 쓰는게 종이를 덜 차지함

Examples:

1. Scaling
1. Shear
1. Reflection
1. Rotation

*   모든 3D 선형변환은 3x3 행렬의 곱으로 표현할 수 있음
*   모든 3D 선형변환은 회전, 스케일링, Shear의 조합으로 표현될 수 있다.
*   회전은 스케일링과 Shear의 조합으로 표현될 수 있다. 과거에 이미지
    프로세싱하는사람들은 절대로 로테이션 매트릭스를 그대로 쓰지 않았음. 무조건
    Scaling과 Shear의 조합으로 썼음

Matrix decomposition은 어렵다. 마음에 드는 decomposition 종류가 별로 없다.
종류가 아주 수많음.

Transform은 decompose가 쉽게 되지 않음. 기본 단위를 정하기 어렵다.

### Changing bases

v0/v1 벡터 공간 위의 (x, y) 점이 있다. 이 점은 가만히 냅두고 좌표계를 v0'/v1'로
바꾸고싶다

```
x'v0' + y'v1' = xv0 + yv1
```

```
v0 = a0v0' + a1v1'
v1 = b0v0' + b1v1'
```

```
| x' |   | a0 b0 || x |
| y' | = | a1 b1 || y |
```

### Affine Transformations

어파인 변환 T.

T maps vectors to vetors, points to points

Affine combination is invariant under T

T(p) = M33p31 + T31

### Homogeneous Coordinates

```
T(p) = | M33 T31 || p31 |
       |  0   1  ||  1  |
```

Affine transformation is *linear* in Homogeneouse Coordinates

### Affine Transformation의 속성

어파인변환은..
1.  선을 선으로 매핑한다
1.  평행선 둘을 평행선 둘로 매핑한다.
1.  선 상의 점들의 거리 비율을 유지한다.
1.  절대적인 길이나 각도를 유지시켜주지 못한다.

```
| x` |   | a0 b0 c0 || x |
| y` | = | a1 b1 c1 || y |
| 1  |   | 0  0  1  || 1 |
```

### Rigid Transformations

Rigid Transformations는 변환 전/후에, 모든 거리들이 유지되는 변환

T

1.  T는 벡터를 벡터로, 점을 점으로 매핑
1.  T는 모든 점 사이의 거리를 유지
1.  T는 모든 벡터들 사이의 외적을 유지 (to avoid reflection)

리지드 트랜스폼은 딱 두개밖에 없음.

1.  로테이션
1.  트랜슬레이션

```
Orthogonal: R * R^T = R^T * R = I
Special: det R = 1
3D Transform
```

SO(3) 라고 한다.

### Rigid Body Rotation

R is orthogonal

칼럼벡터를 그려도 90도, 로우벡터를 그려도 90도라는 뜻이다.

이건 설명이 잘 안되고 여러분들이 열심히 들여다보세요.

### Taxonomy of Transformations

* Linear
* Rigid
* Affine
* Projective

Linear, Rigid < Affine < Projective

### Composition of Transforms

* Linear + Linear -> Linear
* Affine + Affine -> Affine
* Rigid + Rigid -> Rigid

* Linear transformation의 Linear Combination은 Linear transformation
* Affine transformation의 Linear Combination은 Affine함
* Affine transformation의 Affine Combination은 Affine함
* Rigid transformation의 Affine Combination은 Affine transformation

--------

> 3월 17일 화요일

회전행렬의 정의 = A^-1 이 A^T 인것.

코디네이트를 새 코디네이트 시스템으로 보내주는것과
한 코디네이트가 있을때, 새 코디네이트 시스템에서의 이 점의 좌표를 보는것은
전혀 다르다

임의의 축에 대한 회전 만드는법.

1. Old fassioned
2. Modern way

코딩할때 아크코사인 쓰지마라. 뭔가 잘못되고있는것. 금기시되는 함수

코사인이랑 사인을 알면 이미 행렬을 만들 수 있으니 각도를 몰라도 됨.

### 천재를 구분하는 방법

어떤 결론에 도달했는데, 왜 그 결론에 도달했는지 아무리 노력해도 그 이유를 알 수
없을때 그를 천재라고 한다.

오일러 각도

아폴로 우주선 핸들이 짐버였다고 함

인공위성의 지상촬영 카메라도 짐블에 달려있음

xyz, xyx, xzy, xzx, 등 12가지 방법으로 오일러각도를 만들 수 있음

로테이션을 시키다보면 xyx가 xyz로 변신할 수 있음.

로테이션의 비극

짐버락

자유도가 사라지는 마법을 보여주마

현질의 physics와 mathmatical repr이 매치하지 않아서 나타나는 일

오일러 각도는 Ambiguous 함

(x, pi/2, 0) = (0, pi/2, -x)

이거떔에 이십년정도 전에 모 방송사에서 2억원주고 wavefront 샀더니 망한일이 있음

* 지오메트리
* 렌더링
* 애니메이션

학과 사무실에 있는 3D 프린터 내(이제희 교수님) 핑계 대고 막 쓰세요

--------

### 3D Object repr
- 바운더리 레프리젠테이션
  - 너무 유명한 그것
- Space partitioning
  - 복셀. CT사진
- Procedural methods
  - 수식으로 모델 표현
- 컨스트럭티브 솔리드 죠메트리
- 피지컬리 베이스드 모델링

### 뭘 골라야할까?
- 계산 코스트
  - 저장용량
  - 컨스트럭션 타임
  - 디스플레이 타임

남들이 뭘 할때 비웃을때엔 조심해야해요.
10년만 지나도 세상이 변해요.
처음 복셀렌더링 나왔을때 사람들이 모두 비웃었어요.

- 특정 피노미나를 얼마나 효과적으로 표현할 수 있는가
  - 시뮬레이션의 정확도
  - Looks good
- 구현 복잡도
  - 프리미티브가 얼마나 많고, 복잡한가

### Polyhedra
모든 폴리히드라는 Planar graph로 표현가능

오일러 포뮬라
```
V - E + F = 2
```

오일러 푸앙카레 포뮬라
```
V - E + F - L = 2(S - G)
```
푸앙카레가 뭐한사람인지 알아요?
추측한 사람이요.
푸앙카레는 지독히도 계산을 못했던 사람이에요
두자리수 곱하기 두자리수 계산은
이사람에게는 불가능하게 느껴졌대요
수학시험을 보면 항상 0점 비슷한 점수를 받지않겠어요?
프랑스 모 대학에서 수학을 0점을 받고
이 이후로 너무도 유명한 사람이 되니까
그래서 학교 입학시험에 예외규정이 들어감
너무 특이한 성적의 사람은 셤 한번 더볼수있음

### Functional Repr
Explicit
```
z = f(x, y)
```

Implicit
```
f(x, y, z) = 0
```

Parametric
```
(x(t), y(t), z(t)) for t in [a, b]
```

##### Issues
- Repr power
  - Explicit이 제일 제한됨 (지형), Implicit이랑 Parameter는 경우에 따라 양쪽이
    더 나은 표현력을 가진 경우가 있음.
- Easy to render
  - Explicit이랑 Parametric은 그리기 아주 쉽지만, Implicit은 그리기 매우 힘듬
- Manupulate (translate, rotate, ...)
  - Imlicit이 제일 어려움

결과적으로 파라메트릭 repr이 제일 보편적임. 표준화된 방법. OpenGL에도 parametric
form들은 제공됨.

### Implicit Surfaces
- Quadric surfaces
  - 코닉 섹션(원뿔 곡선)이 진화된 Quadrics. 제일 차수가 낮은 곡면이라서 배움.
- Superquadric surfaces
- Blobby objects

### Superquadrics
```
(x/a)**(2/S) + (y/b)**(2/S) = 1
```

### Blobby Objects (metaballs)
A collection of density functions

### Spatial partitioning
복셀

파티셔닝을 넌유니폼하게 수행, 옥트리를 그려서 메모리를 절약. 근데 대충구현하면
별로 효과가 없음. 복셀들마다 링크드리스트 만드는게 오히려 시간 더걸림

##### Binary Space Partitioning tree
공간을 한번에 하나의 기울기와 위치가 자유로운 Plain으로 나눔.

컴퓨터 게임엔진에 굉장히 많이 들어감. 던전 딱 들어가면 자동문 달려있고, 어디
부터 어디까지 보이고 이런거 할때 쓰임. Visible polygon이랑 Invisible polygon
구분하는데에 많이 쓰임

### Constructive Solid Geometry
이도 저도 아닌 중간쯤. 기본적으로 간단한 프리미티브를 갖고있고, 이
프리미티브들로 불리언 오퍼레이션을 해서 새 쉐입을 만듬. 쉐입은 트리로 표현됨.

트리의 leaf엔 리프노드와 리프노트에 대한 트랜스포메이션이 있고, 인터널 노드엔
오퍼레이터가 들어있음. 저장효율이 매우 뛰어남, 그리는데에 시간이 너무 오래걸림.

보통 렌더링할때 레이캐스팅을 씀. 레이를 공간상에 그어놓고, 불리언 오퍼레이션을
1차원 상에서 함.

기계설계하는 캐드시스템에 많이 들어있음

### Procedural Method
자기유사성 프랙탈, Demensionality에 대한 새로운 인식.

Space filling curve. 원래 얘 본질이 뭐냐에 상관없이, 얘가 어떤 절차를 거치느냐에
따라 차원이 달라질수 있다, 1.x 차원도 될 수 있다.

Terrain by random perturbation. 절차적 지형생성.

### Physically Based Modeling
파티클 시스템. 모델링과 애니메이션을 구분하지 않음. 물리에 기반해 현상을
시뮬레이션함. 물, 불, 옷감, 바람, 천체 시뮬레이션, ...

--------

> 4월 21일

### Matrix Equations for B-splines

### Curve refinement
베지에곡선 둘로 쪼개기

### Binary Subdivision

### Subdivision Rule for Cubic B-Spline
컨트롤포인트를 잘게 쪼개가도, 같은 곡선이 나옴. 이걸 무한히 하면 그냥 곡선이
나옴

### Chakin's Algorithm
Corner cutting subdivision

이걸 반복하면 quadratic B-spline으로 수렴함.

### Interpolating subdivision
Weight의 합은 항상 1

### Subdivision Surfaces
캣멀과 클락.

4각형, N각형에 서브디비젼을 적용

이 아이디어가 제법 그럴싸했는데, 모든사람들이 B-spline과 lerps를 연구하던 시대.
비웃음만 사다가, 78년도에 논문이 나왔는데 80년대 후반에나 재조명받기 시작함. 그
사이엔 원래 하던대로 베이시스 펑션을 가지고, 임의의 서페이스를 그리려고
시도했음. 하지만 box-spline 연구는 실패.

굉장히 복잡한 모양을 만들 수 있고, 마음대로 refine 할 수 있음.

### Subdivision in Action
아주 부드럽고 말캉말캉한건 시뮬레이션이 잘되는데 딱딱한건 잘 안됨. 말랑말랑하면
타임스텝이 넓어도 되는데, 딱딱하면 타임스텝을 상당히 조밀하게 놓아야함.

Cloth 시뮬레이션하는거랑 완전히 딱딱한거 시뮬레이션하는건 방법이 아예 다름.

B-spline이 약한게 뾰족뾰족한거인데, 그냥 displacement mapping 해서 꾜족하게
만든다는거임. 강력한 테크닉임

Environment mapping

스키닝

그래픽스하는사람들은 항상 조절할 수 있는것을 좋아해요

차회 예고: 쿼터니온으로 어파인 변환하는 이야기가 나옴.

### Displaying Spline Curves
목표: 덧셈만 가지고 그릴 수 있다!

x(t)를 안다면, x(t+d)를 빠르게 계산할 수 있다!

합 크라프트: 우리 이전세대에 온갖 교과서를 다쓴사람. 코넬에서 연구 슬슬 접으면서
자기 인생 마지막 문제라고 들고온게 exact computation이었음.

무덤분야. 아무도 해답을 못냄. Box spline도 그렇고, 손대면 백수가 되는 분야가
있음. 문제를 잘골라야됨.

문제를 잘못고르면 폭삭 망해요
문제를 잘고르는게 굉장히 중요합니다.
무덤 연구분야가 있어요.
수업시간에 되게 잘하고 그랬던 친구가
내가 추천서 써서 유학을 보내줬는데
지도교수 찾은게 딱 그 지오메트리 하는 양반을 찾았어요.
LM에 가있어요
스타워즈 만든회사
fluid sim도 하다가
다른것도 하고
내가 데리고있는 포스닥중 한명은
웨타에 가있어요
반지의 제왕 시리즈
킹콩
호빚
거기서 모션캡쳐를 하는 스페셜리스트로 일을 하죠
질문: 그래픽스 하는사람 별로 없어요?
모든 분야가 유행을 타요
내가 그래픽스 하던시절엔 그래픽스가 최고의 인기 분야였어요
가장 똑똑한 사람들이 오는 분야였어요
근데 요즘은 그렇진 않고
적절한 숫자에 적절한 학생들이
나는 곧 죽어도 이걸 하겠다는 학생들이 와요
이건 좋은사람들이 하는 분야에요
뭔가 그려지고 보여지고 내맘대로 조작할 수 있는게 확 끌리는 사람들이 해야해요
이걸 하는사람들은 굉장히 종류가 다양해요
입맛에 따라서 사람들이 꽤 편차가 있을 수 있어요
어느 분야든 마찬가지지만
그래픽스는 항상 다른걸 해요
자꾸 바꿔가면서
새로운걸 찾아다냐요
원래 연구를 하는 사람들은 어쩔 수 없이 새로운것을 뒤져가는 사람이에요
학생들중에 그거에 적응을 잘 하는 사람이 있고 아닌 사람이 있어요
편한게 좋은지 아니면 막막한게 좋은지
마치 김명수교수님같군
스스로한테 한번 물어보세요
우리 연구실에 들어오는 학생들은 연구실에 들어와서
내가 10몇년전에 했던걸 하고싶어해요
나는 그때 할떄 나혼자 황무지에서 아무도 하는사람 없고 혼자했는데
학생들은 내가 10몇년전 전에 했던걸 하고싶어해요
왜냐면 정리가 잘되어있거든
그렇게 가는 사람들은 다 망해요
원래 대학원에 가면 제일 좋은건
교수든 학생이든 Agree해야하는데
학생들을 황무지에 놓고 버리고 오는거에요
그리고 거기를 번듯한 땅으로 바꿔놓는게 학생들이 하는일이에요
댛가운에 들어갔는데
대학원에 들어가는데
익숙하고 잘 닦인 일을 한다면
굉장히 고민해야해요
그런데서 들어가서 연구하는거 아니에요
20년전에 누가 이미 다 해놨다는 뜻이에요
세상은 그렇게 돌아가는겁니다
제일 좋은건 지금은 황무지인데 10년뒤에 진짜 잘풀릴곳을 가야하는데
그게 찾기가 힘들어요
황무지에 가서 메말라죽거나
황무지에 가서 살아 돌아오거나
근데 그건 반반 확률이잖아요
잘 닦여진곳에 가면 그대로 죽는거에요
뉴튼이 한 유명한 말이 있어요
내가 멀리볼 수 있었던 이유는
거인의 어꺠에서 시작했기 때문이라고
대학원생들은 지도교수들의 어깨에서 시작합니다
훌륭한 지도교수를 둔 대학원생들은
손을 조금뻗치면 State of art가 손에 닿습니다.
근데 여기 밑에서부터 시작하면 마르고 닳도록 노력해도 닿지 않아요
그게 공부하는 방법이에요
근데 가끔 보면 똑똑한 학생들일수록 그런경우가 많은데
우리는 뭔가 만들어야하거든요
근데 그 만드는걸 밑바닥부터 만들겠대요
남이 하던거 위에 하는건 잘 못하겠대요
근데 밑이 어딘데
도대체 어디서부터 만들면 밑바닥이냐고 항상 싸워요
교수들은 니 선배들이 했던거 절대 반복하지 마라 그러는데
자꾸 학생들은 자기가 배운것부터 쌓겠대요
저래가지고 언제 끝날까
그게 되풀이되는 교수와 학생들의 싸움 중 하나입니다.
여러분중에 나중에 대학원가서 그런일 할 사람이 분명 있어요
교수가 보기에 땡깡이에요 땡깡
몇년동안 쭈그리고 앉아서 졸업할 생각도 없고
뻔히 전세대가 한걸 하겠대요
여러분들은 새로운걸 하는겁니다
그럴 마음의 준비를 하고
대학원을 가도 그렇고
사회생활을 해도 그래요
익숙하지 않은걸 즐길 준비를 하십시오.

물 시뮬레이션 제대로된거 처음 나온게 벅스라이프

--------

> 5월 12일

Chromaticity Diagram

### CIE XYZ Color Space
색깔을 원색을 섞은걸로 표현하려고 하면 negative coefficient가 있음.

그래서 물리적으로 존재할 수 없는 가상의 X, Y, Z 색을 만듬. 얘네는 positive
coefficient만 있고 이걸 섞으면 모든 색이 표현됨.

x = X/(X+Y+Z), y = Y/(X+Y+Z)로 만든다음에 이걸로 Colorspace diagram을 그릴 수
있음.

CIE XYZ 다이어그램, 제일 흰 색 기준이 좀 애매함. 그래서 걍 임의로 정해놨음.
사람들 문화에 따라 제일 흰색이 뭐다 받아들이는 기준이 다름.

CIE XYZ 컬러스페이스는 linearity가 만족됨.

sRGB는 color gamut이 좁아서, 아주 붉은색이나 아주 녹색은 범위 밖임.

보통 Adobe RGB를 씀. 어도비 RGB 지원하는 모니터는 좀 더 잘보임. 근데 sRGB
모니터에 비해 가격이 너무 비쌈. 이런애들은 모니터 옆에 가림막 있고 터무니없이
비싸고 그럼.

Illuminant C, 이걸 기준으로 보색을 정의함

Dominant Wavelength

### CIELAB, CIE Lab
Perceptuallc Uniform color space

### CCD
Bayer filter

녹색 민감도가 높다고 믿어지고 있음. 그래서 그냥 녹색 CCD를 많이 넣음.

경계가 깨끗하게 나오지 못함.

### White Balance
Chromatic adaptation

사람의 눈은 절대적인 값보단 상대적인거에 민감. 사람의 의식은, 세상에 대한 모델을
구축한다.

오토매틱 화이트밸런스는, 사람이 보고싶은 영상을 보여줘야함. 이게 똑바로 될리가
없다.

### The infamous gamma curve
감마 조절.

### Color quantization gamma
http://en.wikipedia.org/wiki/Weber%E2%80%93Fechner_law
```
<@지현> 오늘 이제희 교수님 명언
<@지현> "고문은 익스포넨셜 하게 해야지"
<@지현> "이 친구가 느끼는 고통이 리니어하게 증가해요"
<@지현> 인지과학
```

### HDR

--------

> 5월 14일 목요일

### Halftoning
출판물에서 쓰임. 색의 표현범위가 적을떄 이를 표현하는 방법.

### 디더링

Ray Tracing
--------
### LI vs GI
GI
* Ray tracing
* Radiosity
* Photon mapping

### Forward Ray Tracing
### Backward Ray Tracing
빤짝빤짝 꺠끗하고 깔끔하게 비춰보이고 그래요. Specular reflection/refraction이
계산하기 쉬워서.

### Binary Ray-Tracing Tree
### Ray-surface Intersections
### Ray-Implicit Surface Intersections
### Ray-Polygon Intersections
### 안/밖 판단
재수없으면 꼭지점을 지나서 에러가 남.

해결법
1.  여러번 해보기
2.  임의의 에지의 중점쪽으로 쏨

### Acceleration Techniques
김명수 교수님

김명수 교수님
세상의 누구보다도
인터섹션에 대해 제일 많이 아는 분이셔요

* Space-subdivision
  - Uniform subdivision
  - Adaptive subdivision (Octrees)
  - BSP trees
* Ray classification
  - Classify 5D ray space
  - Can be reduced to 4D ray space

지난 30~40년동안 죽도록 이뤄진 연구. 여러분이 요만한 이미지를 그려서
레이트레이싱 돌리는데 5시간 걸렸는데, 똑바로 하는사람은 그걸 리얼타임으로 해요

요즘은
레이트레이싱도
리얼타임으로 돌아가요
근데 여러분은 잘 못할거에요
의지고 있고
시간이 남고
정력이 남으면 한번 빠르게 해보세요

### Camera Obscura
### 회절
### 렌즈

자네는 어디서 카메라에 대해 열심히 배웠구나
고등학교 물리를 열심히 공부했습니다

--------

> 5월 26일

Image Processing
--------
지난 시간까지 렌더링을 했고, 그 이후에 이어서 렌더링의 메인 스트림 테크닉들을
배웠어요. 렌더링의 메인 스트림 테크닉 말고, 쪼잔 쪼잔한 곁가지 테크닉들을
이해하려면, 이미지에 대한 이해가 필요합니다.

그래서 이번시간과 다음시간동안 이미지에 관한 기본적인 공부를 할거구요, 그리고
마지막 시간까지 이미지와 렌더링에 대해 찔끔찔끔 다뤄보고자 합니다.

Alexei Efros의 슬라이드를 쓸것임. 이 슬라이드도 이사람이 만든건 아니고, 이사람도
다른 사람이 만든 슬라이드를 빌려다 쓰고있어요.

이미지 프로세싱에 관련된 내용은, 별로 대단한 내용이 없어서 누구 슬라이드를 보내
내용이 다 비슷비슷해요. 난 그냥 잘만든 친구거를 이메일 한번 보내고 나 이거 좀
쓸게 하고 쓰는거에요. 여러분들도 그렇게 가져다 쓰면 돼요.

### What is an image?
이미지라는것을 어떻게 표현하느냐. 가장 흔하게 생각하는 이미지에 대한 뷰는
Function으로 define 하는거에요. 함수로 정의하면, 이미지의 range가 있고,
range라는것은 픽셀의 범위겠죠.

흑백 이미지이면 이미지를 마치 x, y의 범위가 각각 [0, 1000), x, y에 적절한 값을 넣으면
그레이스케일로 [0, 1]의 값이 나오는 함수로 생각 할 수 있겠죠.

> z = f(x, y)

컬러 이미지면 r, g, b의 세 이미지가 겹쳐져있는 이미지라고 생각할 수 있겠죠

> (r, g, b) = (f(x, y), g(x, y), h(x, y))

### What is a digital image?
근데 우리는 이미지의 x, y 가 연속적인것이 아니라 discrete하죠.

우리는 x, y 값을 넣으면 딱 정해진 r, g, b 의 값이 나오는 디지탈 이미지의 개념이
너무 익숙한데, 이는 과거 비트수를 조금이라도 줄이기 위한 시도였고, 근래에 들어선
HDR과 같이 이것이 부동소수점으로 반환되는, 디지털 이미지의 개념이 희박해지고
있어요.

그리고 최근에 들어선 x와 y의 범위 마저도 discrete 하지 않게 하려고 하죠.
Multi-resolution image, Vector image. 이미지가 해상도에 따라 다른 이미지를 갖게
할 수 있겠죠. 맨눈으로 볼때, 돋보기로 볼때, 현미경으로 볼때 서로 다른 이미지를
갖게 할 수 있지 않을까? 하는 생각이 있었고 이미 JPEG2000 의 표준에 들어가있어요.

예를들어 이미지를 그리면 위치에 따라 색의 변화가 덜한부분은 낮은 resolution으로
저장하고, 위치에 따라 색의 변화가 격렬한 부분은 높은 resolution으로 저장할 수
있겠죠. 그래서 range 마저 discrete 하지 않을 수 있어요.

### Image Processing
어떤 이미지(=함수) `f(x, y)`가 인풋으로 들어가면, 이를 펑터 `t` 에 넘겨서 새
이미지(=함수) `g(x, y)`를 얻어내는것.

> g(x, y) = t(f(x, y))

근데 보통 이미지 프로세싱은 이미지 리졸루션은 고정시키고, x, y 각 픽셀 value들만
바꾸는 경우가 많아요. 그래서 우리는 이 둘을 구분해서 불러요.

##### Image filtering
> g(x) = h(f(x))

그레이스케일, 밝게 만들기, 등.

##### Image warping
> g(x) = f(h(x))

워프 이거 어디서 나온 단어에요? (나) SF 소설이요. 맞아요. 이거의 예시가
뭐가있을까요? 리사이징.

오늘은 필터링만 이야기할거에요. 다음엔 워핑을 이야기할거에요. 둘 다 중요한
이야기에요.

### Point Processing
이미지 필터링중에서 가장 심플한 방법의 이미지 프로세싱을 포인트 프로세싱이라고
불러요.

> g = t(f)

각각의 픽셀을 모두 independent 하게 처리할 수 있는 경우를 포인터 프로세싱이라고
불러요.

흑백 필터링은 보통 포인트 프로세싱이 아니에요. 흑백으로 바꾸다가 루미넌스때문에
컬러이미지를를 흑백으로 만들었더니 감마가 다 날라가서 밝거나 어두운 구분이
안가는 경우가 있어요.

흑백필름을 쓰는 흑백 사진가들은 이 문제를 해결하려고 신기한 필터들을 많이 써요.
가령 사람얼굴을 찍을떄엔 노란 필터를 넣어서, 노란 사람 피부는 밝고 주변은 죽게
만들어요. 풍경 사진가들은 그라데이션 필터를 써서, 사진 윗쪽(하늘)을 죽이고, 사진
중간이나 밑(바닥)은 살리려고 시도해요.

### Basic Point Processing
밝기를 줄여주는 함수.

(그림 피피티 참고. 그래프 사진)

밝기를 선형으로 줄이지 않고, 로그와 익스포넨셜을 써요. 밝기를 줄이면서도 원하는
정보가 클리핑되어 죽지 않게 하기 위함이에요.

(유선 엑스레이 사진)

CT하고 MRI하고 보는 목적이 달라요. CT도 입체로 보이고, MRI도 입체로 보여요. 근데
CT는 보통 단단한 조직, 뼈를 보는데에 쓰여요. MRI은 근육, 혈관, 신경과 같이
soft한 tissue들을 보는데에 쓰여요.

CT는 X-ray를 수백장 찍은것이고, MRI는 방사선을 전혀 쓰지 않아요. MRI는 돈이
문제가 아니라면 찍어도 별 상관이 없고, CT는 가능하면 많이 찍으면 안되요.

의사선생님들은 CT를 찍으라고 하면 기피해요. 그리고 건강검진에서 CT를 찍으라고
하면 의사 수임료를 높이려는 부도덕한 행동이라고 생각해요. 특히 외과의사들은 CT에
민감해요. 난 가끔 의사들과 같이 일을 해야해서 수술실에 들어가는데, 내부에
결정적인 일을 하려고 몸에 철심을 박거나 하는 수술을 할때엔, X-ray를 비디오처럼
틀어요. 그래서 외과의사들은 자기 몸에 계속 X-ray를 노출시키면서 살아요. 그래서
이사람들은 납치마를 입고 수술하고, 가능하면 떨어지려고 해요. 그리고 공포를
갖고있어요. 그래서 CT를 함부로 찍는게 아니래요.

여튼 둘다 찍으면 픽셀 밸류들이 나오는데, 그대로 보여주면 사람이 보기 굉장히
힘들어요. 굉장히 여러 프로세싱을 해서 내가 보고싶은 정보가 잘 드러나게, 보기싫은
정보는 묻히게 만들어요.

(푸리에 스펙트럼)

푸리에 스펙트럼 거의 본적 없죠? 이미지의 하이 프리퀀시 컨텐트와 로우 프리퀀시
컨텐트가 어떻게 퍼져있는지 보는게 푸리에 스펙트럼인데, 이걸 분석한 값을 그대로
출력하면 아무것도 볼 수 없어요. 로그스케일로 압축해서 다이나믹 레인지를 줄여야
사람이 볼 수 있는 정보가 나와요. 이것도 비슷한 문제죠.

### Power-law transformation
> S = cr^r

이거 감마함수 다룰때 봤었죠?

### Image Enhancement
굉장히 자주 하는 일 중 하나가 사진을 쾅 하고 찍었더니 너무 밝게 나와서 포토샵에
넣어서 자동보정 시키는거죠?

여러분이 카메라로 사진을 챡 하고 찍으면 기본적으로 측광이라는 행동을 해서 조리개
사이즈와 셔터 스피드를 자동으로 조정해요. 그래서 사람이 보기 편한 다이나믹
레인지로 이미지를 모아주죠. 근데 그 사람이 보기 편하다는 것의 기준은 뭐에요?

자연계에서 사람이 빛을 볼 때, 사람의 홍채도 스스로 받는 빛의 양을 조절해요.
그래서 사람이 보통 인식하는 빛의 밝기 범위는 얼마 라는게 있어요. 밝은게 1,
어두운게 0이라고 하면 72%프로정도라고 해요.

근데 이러면 문제가 있어요 좀. 내가 이 영상속에 까만색 곰돌이를 안고 사진을 팡
하고 찍었어요. 그리고 똑같은 상황에서 흰색 곰을 안고 사진을 펑 하고 찍었어요.

그러면 카메라가 주는 이미지는 흰색곰도 72% 그레이스케일로, 까만색 곰도 72%
그레이스케일로 줘요. 그게 카메라에요. 그게 사진기에요. 컨트래스트도
마찬가지에요. 저건(피피티) 컨트래스트가 낮죠. 컨트래스트라는거는 어두운부분과
밝은부분의 차이에요. 컨트래스트가 너무 높다고 좋은것도 아니고, 이것도 마찬가지로
우리가 자연계에서 보통 접하는 컨트래스트의 범위는 얼마 라는게 있어요. 그 기준에
따라서 auto correction을 하면 이미지가 우리가 기대하는 컨트래스트로 바뀌죠. 근데
그게 정답일수는 없어요. auto correction을 하다가 까만색 곰이 회색 곰이 되고,
하얀색 곰이 회색곰이 될 수 있죠.

### Example: Gamma correction
우리가 이미 했던 이야기에요. 리니어스케일로 코렉션했더니 별로고, 감마함수로
코렉션했더니 좀더 보기에 좋더라. 패스

### Contrast Stretching
(뿌연 커피콩 이미지)

이렇게 컨트래스트가 안좋은 이미지가 있으면 S자 곡선에 넣어서 컨트래스트를 살릴
수 있어요.

이걸 포인트 프로세싱으로 해결한다고 하면, S자 곡선을 써요. 여러분이 배운
베지에곡선으로 S자 커브 만들어서 촥 하면 됩니다. 이걸 하면 밝은쪽 부분은
원래보다 더 밝아지고, 어두운 부분은 원래보다 더 어두워지죠. 이런 함수를 쓰면
컨트래스트가 높아지게 할 수 있어요.

### Image Histogarms
이미지의 모든 픽셀들을 통계내서, 이 밝기에 해당하는 픽셀이 얼마나 많으냐의
히스토그램(도수 분포표)를 만드는거에요.

어떤 보기 안좋은 이미지를 주고 이것을 밝게 하시오라고 던져주면, 히스토그램을
만지는 사람들은 히스토그램을 보고 모든 밝기 범위에 고루 퍼지도록 컨트래스트를 쫙
펴줘요. 이것도 Point Processing으로 해결할 수 있습니다.

Low contrast 이미지라는거는, 히스토그램이 특정 밝기 범위로 쏠려있는것을 말하고,
High contrast 이미지라는거는 모든 밝기 범위에 고루 퍼진것을 말해요.

어두운 이미지, 밝은 이미지라는것도 히스토그램에 어두운 범위에 모여있고, 밝은
범위에 모여있고 이런걸 말하죠.

##### Cumulative Histogram
도수분포표 대신, 누적도수분포표를 그린것이에요. 곡선의 기울기를 보면 돼요.

> s = T(r)

### Histogram Equalization
히스토그램 이퀄라이저라는게 있는데, 뭘 넣어도 다 비슷한 히스토그램이 나오도록
만드는 알고리즘이에요. 별거 아닌데 이런게 있어요. 거의 대부분의 사진
프로그램에는 히스토그램 이퀄라이저가 들어있죠.

이미지 프로세싱을 할 때, 예를들어 컴퓨터 비젼 알고리즘같은거 돌리면 맨날 나오는
불만이 뭐냐면, 잘 컨트롤 되어있는 조명 하에서는 알고리즘이 잘 작동하는데, 불을
다 꺼버리고 한쪽에서만 후레시를 비췄더니 알고리즘이 안돌아간다 이런거죠. 아주
어둡게 했더니 안돌아가고, 아주 밝게 했더니 안돌아가고.

그런것들을 없애기 위해서 조명 조건이나 이미지를 촬영한 조건에 independent 한
알고리즘에 작동하는 알고리즘을 만들으려고 해요. 그중에서도 컨트래스트를
노말라이즈할때 만드는게 히스토그램 이퀄라이저에요.

컨트래스트는 이게 잘 되는데, 조명같은건 잘 안돼요. 컴퓨터 비전을 들으면 이걸
배울 기회가 있을지도 모르는데. 없을수도 있고

### Neighborhood Processing (filtering)

Image Filtering
--------
필터링에 또 다른 슬라이드가 몇장 더 있는데요.

(살바도르 달리의 그림)

이그림은 창밖으로 지중해를 바라보는 여인의 뒷모습이라는 제목이 붙어있는
그림인데요. 여러분은 내가 말한걸 볼 수 있나요?

이 그림은 멀리서 보면 여인의 누드 대신에 사람 얼굴이 보여요. 이걸 블러링 하면
링컨의 초상화같은게 보여요.

내가 뭐라그랬어요. 내가 보는 리졸루션에 따라서 다른 이미지가 보인다는겁니다.
그냥 크게보이고 작게보이는 차이가 아니라, 아예 다른 컨텐트가 나와요. 사람이
인식할 수 있는 프리퀀시에 한계가 있어서, 너무 하이프리퀀트한 요소는 무시되고,
너무 로우 프리퀀트란 요소도 느낄 수 없어요.

그래서 내가 글자를 딱 쓰면 딱 정해진 거리에서만 글자가 인식되고, 1미터 앞이나
뒤에서 보면 글자를 인식할 수 없는 폰트같은것도 존재해요. 그래서 누가 어깨너머로
글자를 보지 못하게 하는거죠.

### Filtering noise
근데 이 이미지에서 이 블러된 이미지를 어떻게 만들었느냐. 멀리가면 이 블러된
이미지가 보인다고 했는데, 픽셀의 옆에있는 이미지들을 섞어서 블러한거죠. 이건
전형적인 네이버후드 프로세싱이에요. 이건 포인트 프로세싱의 반댓말입니다. 그
픽셀을 프로세싱할 때 그 옆에 있는 값들도 같이 고려하겠다는겁니다.

포인트 프로세싱은 굉장히 제한되어있죠. 할 수 있는게 별게 없어요. 여러분들이
생각하는 특별한 경우를 제외하면 거의 모두 다 네이버후드 프로세싱이라고 봐도
됩니다.

제일 많이쓰이는게 노이즈 없애는거. 카메라 만드는 회사들은 이 노이즈 없애는걸로
지난 15년동안 죽어라고 경쟁했어요. 그래서 지금 노이즈를 없애는 알고리즘은 거의
상승할 수 없을정도로 성능이 상상을 초월합니다. 그래서 지금 모든 회사들의
디노이즈 알고리즘들은 다 성능이 똑같습니다.

우리가 이야기하는 노이즈 필터링은 그 전, 아주 기초적인 레벨을 이야기하는겁니다.

노이즈를 지운다는 말과, 블러링한다는 말은 결코 같은 의미일 수 없는데,
블러링을 한다고 해봅시다.

가우시안 필터는 어떻게하는거에요? 여러분들이 요 픽셀의 값을 결정할때 여기를
센타로 해서 만들어지는 가우시안 디스트리뷰션을 생각해서 그 가우시안 디스트리뷰션
만큼의 가중치와, 주변 픽셀들의 값을 곱하는거죠?

근데 실제 가우시안 펑션은 범위가 무한해요. 그래서 실제 가우시안 필터를 진짜
가우시안 펑션으로 하는 경우는 극히 드물어요. 그래서 어프록시메이션을 해서
쓰는데, 유한한 N*N 범위 안에 가우시안 펑션의 코에피시언트를 곱해서 가우시안
비슷한 어프록시메이션한 값을 넣죠. 제일 흔하게 쓰이는 discrete한 가우시안의
어프록시메이션은, 동전던지기로 나오는 binomial 분포를 써요.

### Mean filtering (median filtering)
또 많이 쓰는게 민 필터에요. 민 필터는 아까 말했던것처럼 영역이 있는데 그 픽셀에
값을 결정할때 이 전체의 값들중에서 중간값을(평균값이 아님) 가져다
쓰겠다는거에요. 왜 이런 필터가 필요할까요?

(칠판에 그림)

노이즈가 예를들어서 이렇게 있으면

(박스 위에 화이트 노이즈 얹은 그래프)

우리는 이걸 노이즈필터하면 이렇게 나오길 원하죠

(박스형 그래프)

근데 간혹가다가 노이즈가 이렇게 쁘아송 분포로 나오지 않고, 피크가 튀는 경우가
있어요. 이걸 가우시안 필터링하면 그 피크가 살아서 영향을 미쳐요. 근데 민 필터를
하면 피크가 무시되죠.

종류가 좀 다르죠.

이거 이름이 민 필터면 안되는데? 피피티에 있는건 민 필터가 맞고, 방금 내가
설명한건 미디엄 필터에요.

### Cross-correlation filtering
노테이션이 좀 지저분하고 복잡하게 생겨있는데, 일반적으로 필터의 사이즈는
홀수크기를 갖죠.

(피피티 참고)

> G = H (x) F

이걸 필터 외에, 커널, 마스크라고도 불러요.

이미지 프로세싱 책이 이렇게 두껍게 있으면 보통 그 책의 반은 이 마스크를 어떻게
디자인할것인지를 다룹니다. 오만갖의 물건을 갔다가 씁니다. 그리고 그 분석기법은
전부다 푸리에 트랜스폼으로 이뤄져요. 내가 이렇게 하면 이걸 푸리에 도메인으로
넘기면 어떻게 보이고, 이렇게 왔다가 갔다가 이렇게 다루고 하는걸 좋아하는 사람은
이걸 해도 되는데요, 저는 좋아하질 못하겠더라구요.

### Mean kernel
저 피크가 튄것의 값은 줄어들긴 줄어드는데, 없어지진 않아요

### Gaussian filtering
요렇게 하면 아까 민 필터한것보단 좀더 부드럽게 나오더라

### Mean vs Gaussian
이 차이가 보여요? 컴퓨터로 보면 보이는데 프로젝터로 보면 하나도 차이가 없네.
헤헤헤헤헤. 근데 컴퓨터로 열심히 보면 조금 차이가 나요.

그래서 그냥 평균내는것보다 가우시안이 조금 더 낫더라.

이걸 가지고 노이즈 리무버링이라고 말하진 않죠. 그래서 가우시안 필터는 노이즈
리무버링하고는 아무상관 없어요.

--------

이미지 프로세싱은 그냥 간단하게만 하고 갈거에요. 근데 다음시간에 배울 이미지
와핑은 이것보다 좀더 복잡해요.

질문 궁금한거 하고싶은얘기

##### 이 PPT는 올려주시나요?
아니오. 알아서 찾아서 보세요. 내가 말했잖아요. 내가 누구껄 가져와서 조금이라도
고치면 내가 이걸 올려는 주겠는데, 전혀 손대지 않았으니 공유할 수 없어요.

또 궁금한거 하고싶은이야기

아마 이 슬라이드를, 원본이, 이 Steve Seitz 라는 사람을 찾아가면 있을거에요.
이사람은 컴터 비전하는사람이에요.

질문 궁금한거 하고싶은얘기.

왜 오늘따라 학생들이 다 지쳐보이지.

(나) 연휴 다음이라서 그래요

(오덕왕) 원래 월요일에 지쳐야되는데 화요일에 지쳐서

하고싶은얘기. 아무거나 궁금한거.

시간도 많이 남았는데 무슨얘기해줄까.

얼마든지 해줄 수 있는데.

뭐가 궁금해요 아니면 뭐가 보고싶어요.

여러분들 궁금한거는 숙제하고 시험범위밖에 없죠.

항상 수업시간에 질문없냐그러면 둘중 하나에요.

##### 요즘 컴퓨터 학계에 동향이 어떻게되는지
야 나보고 두시간 강의하라고

동향이야 있겠죠. 근데 질문을 리즈너블하게 해야지, 스코프가 좁아야죠.

요즘 머신러닝 써가지고 하는거 재밌는거 많잖아요.

(나) waifux2 라고 딥러닝 써서 노이즈 없애는거 있던데

딥러닝 얘기 해줄까요. 딥러닝 배웠나요. 머신러닝 얘기나 해볼까

지금까지 있었던 뉴럴네트워크 방법은 뉴런 하나하나가 굉장히 단순한 일을 했어요.
단순한 일을 하는 뉴런 하나하나가 굉장히 많이 모이면 굉장한 일을 할 수 있을거라는
믿음이 있었어요. 1950년대의 사람들입니다. 뉴런을 2 레이어로 만들어서 웨이트 썸
하서 보내고 다시 되먹임하고, 굉장히 꿈과 희망을 가지고 이만큼 부풀어서 연구를
했는데, 50년대 60년대가 지나고 내분이 일어나서, 노스웨스턴에 있던 한 대학의
교수가 투레이어를 엄청나게 막 당당하게 발표하고 그랬는데, MIT에 한 교수가 저거
엉터리다, 저걸로 풀 수 있는 문제가 너무 좁다 는 이야기를 해요.

그러면서 XOR 이야기가 나와요. 이게 인풋을 보고 Classify 해야되는데, 이 XOR만
하면 되는

1972년에 미국 정부에 AI의 미래는 없다는 리포트가 나오고, 연구비가 전부다
끊깁니다. 그리고 사람들은 AI 하던사람들은 장밋빛을 그리고 사기를 치던 사람들로
취급해요.

근데 80년대가 되면서 레이어를 3개로만 늘려도 좀더 성과가 나오더라 하면서

80, 90년대에 뉴럴네트워크 하던사람들은 아무 희망없는 시기에 적당히 적당히 근근히
연구하던 사람들이에요. 그당시까지는 4레이어, 5레이어, 6레이어를 만들어도
트레이닝 시킬 방법이 없었어요. 근데 2006년에 한 사람이 사이언스 논문에 아주 딥
네트워크를 트레이닝시킬 수 있는 방법을 제시합니다. 그리고 그시점에 웹을 기반으로
해서 트레이닝에 쓸 데이터가 엄청나게 많아집니다. 음성, 이미지, 텍스트, 등 엄청난
양의 데이터가 동원되고 이게 딥 뉴럴 네트워크에 붙는 순간, 갑자기 혁명적인 결과가
나오기 시작했어요.

OCR, 이미지인식 기술 다 쪼금쪼금쪼금 가다가 어느 수준에서 새츄레이션 되었었는데,
딥러닝이 나오면서 갑자기 점프했어요. 2000년대 중반에 시작했어요. 2006년대 중반에
시작해서 지금 몇년만에 세상이 확 뒤집어지고있는중입니다.

그 전까지는 음성인식 10몇년동안 했던 사람들이 결과들 다 비슷비슷했어요.
10몇프로, 20몇프로, 근데 갑자기 그게 80프로 90프로로 뛰고 이미지도 그렇게
되었어요. 딥 뉴럴 네트웤이 빅데이터를 만난 순간 이렇게 된겁니다.

여러분들은 어떻게보면 운이 좋은 사람들이에요. 혁신적인 변화가 일어나는 순간에
여러분은 그 변화를 구경할 수 있는 사람들이거든요.

지금 딥 뉴럴 네트워크가 어느수준이냐면, AI한테 게임하는법을 가르치려고 해요.
입력은 그냥 게임 화면이고, AI는 그걸로 게임하는법을 배워요.

또 굉장히 유명한 스토리중 하나는, 구글에서 자기네 구글 이미지에 있는 이미지를
몽땅 다 떄려넣고 트레이닝을 했어요. 목표는 없었어요. 그냥 몽땅 다 떄려넣고
트레이닝 했는데, 그중에 셀 하나가 고양이가 있는 이미지가 들어가면 activate 되는
cell이 있는거에요.

이걸 grandma cell이라고 해요. 한 셀이 하나의 독립된 판단을 하는경우.

그래서 지금 연구자들은 딥러닝이 사람이 생각하는 방법에 근접해가는것이 아닌가
하는 희망을 갖고있습니다. 그래서 AI 연구자들은 최악의 상황과 최고의 상황을 둘다
지켜봐왔는데, 여러분들은 이 피크로 치닫는 에스컬레이트 하는 상황에 있는겁니다.

요즘 딥 뉴럴 네트워크 하는 사람들은 뭐도 되냐면, 어떤 아이가 광장에서 연을
날리고있어 라는 문장을 쓰면 그 문장에 해당하는 이미지도 반환해줍니다. 그리고
아이가 케잌을 먹는 이미지를 주면 아이가 케잌을 먹고 있어 라는 문장을 제네레이션
하는것도 얼마전에 발표되었습니다.

여기에도 재밌는 스토리가 있는데, 이 연구를 한 사람들이 마음이 급해서 논문을 쓰기
전에 방송에 먼저 알렸더니, 제일 중요한 컨트리뷰션을 한 사람들은 다른 대학
사람인데, 방송사에선 제일 유명한 스탠퍼드 연구진만 조명해서 이게 무슨일이냐 하는
사람들도 있어요.

요즘 제일 핫한 트렌드가 이겁니다. 이걸 좀 지켜봐야합니다. 근데 요즘 이것도
되는것만 되고 안되는건 안되는게 아닌가 합니다.

아까 이야기했던 게임 AI 트레이닝시키는 것도 회사에서 한건데, 그거 데모를 한
직후에 구글에서 그 회사를 통째로 샀어요. 이런일이 비일비재해요.

(박사학위 학생이 창업해서 게임 만들어서 손익분기점 1주일만에 돌파하고 하루에
몇억씩 버는 이야기)

여지껏 나왔던 어떤 영화, 어떤 소설, 어떤 컨텐츠도 단일 컨텐츠가 이렇게 수익을 낸
경우가 없어요.

내가 젊을때도 이걸 경험했어요. 내가 연구실 들어갔을때 머리는 좋은데 연구는 잘
못하는 사람들이 지금 넥슨에 창업주로 들어가서 스포츠카 사서 질릴떄까지 타다가
가족한테 주는걸 취미로 갖는 사람이 있죠. 난 왜 거기에 못껴서

연구를 잘하면 그런걸 잘 못하더라구요.

여러분들이 지금 이 시점에 컴퓨터공학을 전공하는것은 굉장히 행운입니다.

여러분들은 지금 기회가 너무 많아서, 그 기회를 가볍게 여기지 마십시오.

창업을 해도 그렇고, 공부를 해도 그렇고, 말아먹는걸 두려워하지 말고 크게 일을
꾸미십시오. 그 내 박사학위 과정 친구도 5년동안 세번을 말아먹었어요. 여러분들도
이상한데 가서 비실비실하지말고, 일을 크게 꾸미고, 말아먹어도 크게 말아먹고,
실패하면 툭툭 털고 일어나고 그러는겁니다.

###### 그 박사학위 학생 회사가 어디에요?
회사 이름은 기억안나고 이름은 언전링크(?) 실리콘밸리에 있어요. 다섯명 다
한국사람인데, 투자받기 쉬워서 거기에 가있어요.

알겠죠? 말아먹어도 크게 말아먹어라.
