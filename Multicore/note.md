> 3월 4일

### Memory Wall

메모리 성능은 1년에 10%정도밖에 향상이 안됨. 그래서 60년대 말에 Cache라는
해결방법이 나옴, 아주 잘 쓰이고 있음.

연구를 하기위해서는 Practical 한 솔루션을 제시해야돼요.

멀티코어가 나오고 나서는 캐쉬 구조가 달라짐. ILP Wall과 파워 장벽은
멀티코어로극복했지만, 메모리 장벽은 멀티코어로 극복하지 못했지만 클락이 더
빨라지진 않을테니 오케이

### Programming wall

코어의 갯수가 늘어나도 프로그램이 바뀌지 않으면 의미가 없음.

멀티코어의 성능을 충분히 이끌어내려면 소프트웨어를 잘 병렬화시켜서 만들어야함.

멀티코어 붐이 일었을때 수많은 회사들이 있었지만 이제 IBM, SGI 밖에 안남음. 이
회사들이 왜 다 망했느냐? 몇십억짜리 시스템을 다 사놔도 프로그래머를 뽑기가
힘들어. 그래서 다 고철덩어리가 되는거야. 이게 지금까지의 문제

이게 굉장한 난제이다. 어떻게하면 이 장벽을 뛰어넘을 수 있을까?

### Programming model

응용프로그램을 개발할때 프로그래머와 병렬 컴퓨터 간의 인터페이스

여러분들이 프로그래밍 할때 하드웨어보고 하는거 아니잖아. 어떤 가상의 머신 위에서
하잖아? 그게 바로 프로그래밍 모델. 근데 우리 ILP Wall 전력장벽 해결 왜한겨?
성능해결하려고 한거지? 쉽게 프로그래밍 하게만들겠다고 성능을 잃어선 되겠느냐?
안됌. 근데 알다시피 쉽게 만드는거랑 성능을 최적화하는거는 서로 상충해. 쉽게
만드려면 추상화가 많이 필요하거든.

### 병렬 프로그래밍 모델의 종류

* 셰어드 메모리 패러렐 프로그래밍 모델
  - 오픈엠피
  - 피쓰레드
* 메세지 패싱 페러렐 프로그래밍 모델
  - MPI
* 엑셀러레이터 프로그래밍 모델
  - OpenCL
  - SnuCL
  - CUDA
  - OpenMP, OpenACC
* 옛 프로그래밍 모델에 안주하려는 경향이 있는 사용자를 기술발전의 추세에 맞게
    교육하는것이 중요

OpenMP는 굉장히 쉽게 만들어져있지만 실제로 써보면 성능최적화 이끌기 힘들어. 내가
직접 다룰수있는 여지가 적거든. 메세지패싱에선 MPI가 de facto 표준. 성능도
엄청나게 좋고 클러스터에 쓰기 적합하다. 그리고 이제는 Practical하게 쓰이는
가속기에 쓰이는 프로그래밍 모델들.

SnuCL은 OpenCL의 클러스터버전 내(이재진 교수님)가 만들었당. OpenMP 4.0은
엄청나게 많은 회사들이 밀고있고, OpenACC는 네개의 큰 회사가 밀고있다. OpenACC
한번 써봐요 얘 성능이 하나도 안나와. OpenMP는 미국 국립연구소 (로렌스랩,
등등)에서 써서 스탠더드가 됨. 근데 OpenMP 4.0은 스펙만 있고 구현체가 없어 (?)
3~4개월 안에 나옴. CUDA는 많이 쓰죠. 이게 제일 먼저 나옴. CUDA는 엔비디아 사유
프로그램이라 아무나 구현체를 못만듬. 그래서 OpenCL이 거기에 대항해서 나옴.
OpenCL은 GPU 안가리고 다 돌아가는데 CUDA는 엔비디아에만 들어감. 삼성 타이젠 삼성
시계에 들어가는 OpenCL 구현체 우리가 만든거임. OpenCL 로고도 애플이 가지고있음.
애플이 OpenCL 밀고 내부적으로 많이 사용하고있음. 지금 AMD, Intel이 많이
밀고있다. Intel과 nVidia은 원수간의 원수. 요즘 게임할떄 아니면 그래픽카드 써요?
온보드 그래픽카드 사요? 그거 다 CPU 안에 들어있는거. 인텔이랑 AMD가 APU 만들어서
엔비디아가 시장을 많이 잃었어. 그래서 예전에 인텔에서 논문 많이 쓰면 엔비디아
이름도 많이 나오고 그랬는데 요즘은 논문에서 엔비디아 상호도 못쓰게한다.

실제로 기술이 발전을 하면 뭐해? 사용자들이 배우기를 해야지. 옛날거에 안주하면
안돼. 프로그래밍 장벽을 극복하기위해 노력을 하자.

### 본 과목에서 다루는 주제

* 순차컴퓨터 시스템의 구조 및 소프트웨어의 동작원리
* 병렬성
* 병렬 컴퓨터 시스템의 구조 및 소프트웨어의 동작원리
* 가속기의 구조
* 병렬화, 벡터화, 동기화 방법
* 메모리 계층구조에 대한 최적화, 루프 최적화, 기타 최적화
* Ptheads
* OpenMP
* MPI
* OpenCL
* CUDA
* SnuCL

맨처음에 컴퓨터 파워 온 하면 어떤동작이 일어나나? 컴구나 시프나 오에스에서
안배웠나.

여러분 OS에서 베컨트 알고리즘, 데이컨트 알고리즘 배웠죠. 그거 텍스트북 틀렸어요.
그거 돌려봐. 안돌아가. **지금 세상에 나와있는 OS책 다 틀렸어.** 지금 멀티코어
아키텍처에서 그거 돌리면 그거 다 안돌아가. 상호배제할때 쓰는 동기화 방법 그거
실제로 C로 임플리먼트해서 돌려봐. 메모리 컨시스턴시 고려를 안하면 안돌아가.
그런것들 실제로 안되는거 이세상에 아는사람 몇명 안될거야. 30년전에나 잘되던
방법이야.

멀티코어에서도 캐쉬를 잘 다루는거 중요해요. nVidia 2007년도에 CEO가 서울대
방문한거 알아요? 좋은사람같던데 왜그러나 모르겠어. 아무리 회사라도
아카데믹한곳에선 그런짓 하면 안돼.

SnuCL은 OpenCL 같은 스펙에, 클러스터 위에서 돌릴 수 있도록 만든 새 구현체.
코딩을 새로 할 필요가 없다. AMD에서도 홍보해준다.

> Lecture 2

컴퓨터와 기수법
--------

### 컴퓨터

계산기. 내부 구조가 아주 복잡. 보통 블랙박스로 추상화. 추상화라는건 이제 우리가
관심없는건 신경안쓰고 관심있는 특성만 보자.

### 데이터

사전적 정의: 추론 논의, 계산의 기반이 되는 측정이나 통계에 의해 얻어진 사실적
정보

컴퓨터공학에선? 컴퓨터로 처리할 수 있는 형태로 구성된 사실적 정보

요즘 빅데이터 유행하지? 빅데이터에서 중요한게 뭘까. 빅데이터엔 중요한 세가지
특정이 있어요. 3V, 볼륨, 버라이어티, 벨로시티. 이게 중요해. 중요한건 분석방법.
통계를 이용해서 분석하지. 새로운 분석방법은 뭐 소셜베이스 외엔 별로 없고. 이건
새로운게 하나도 없는데 그냥 포장만 새로 한거야.

우리나라에서 빅데이터라고 할만한게 얼마나 많을까? 엑셀에 안들어가면 빅데이터라고
쳐봐. 엑셀에 16만로우까지 안들어가. 우리나라 전국민 건강보험 데이터가
300메가밖에 안돼. 이So

중요한건 데이터가 큰것보다 빠르게 처리하는거야. 데이터가 아무리 많아도
처리하는데에 한달이 걸리면 뭐하나? 처리하는동안 데이터 가치가 다날아가. 이걸
어떻게 빠르게 처리하느냐? 멀티코어야.

### 0과 1을 나타내는 전기신호

명확히 구분되는 두가지의 서로 다른 상태: 0과 1. 0.1볼트 근처는 0, 5볼트 근처는
1. 노이즈가 있어도 쓸 수 있도록.

### 하드웨어와 소프트웨어

* 하드웨어
  - 컴퓨터 시스템의 물리적 구성요소
* 소프트웨어
  - 여러개의 프로그램으로 구성된 집합
* 프로그램
  - 주어진 입력을 가지고 원하는 출력을 얻기위해 무엇을 해야하는지 컴퓨터에게
      지시하여 컴퓨터를 동작시키는 역할을 함

### 순차 컴퓨터 시스템

* 우리가 흔히 알고있는 시스템. 패러렐과 비교하여 이야기할떄 사용하는 용어.
* 하드웨어, OS, 어플리케이션 크게 세 요소로 추상화됨

### Application

* 응용소프트웨어. 줄여서 응용(어플)이라고 부름
* 사용자가 특별한 작업을 수행할때 도움을 주는 음용 프로그램의 집합

### 시스템 소프트웨어

컴퓨터 하드웨어를 운용하고 응용 소프트웨어를 실행하기위한 플랫폼.

ex) OS, CLI, Windows, Compiler, Debugger

### 유틸리티 소프트웨어

시스템 소프트웨어의 일종

컴퓨터 하드웨어와 소프트웨어를 관리하고 튜닝할떄 이용

ex) 백신, 압축프로그램, 파티셔너, 모니터, 어셈블러

얘네는 다 구분이 모호하다. 엄격하게 구분 못지어. 이거 구분하고있는놈들은
할짓없는 놈들이야

### r-진법

위치기반 기수법 (positional number system)

수는 숫자들을 연이어 나열한것으로 표현, 그 표현이 가지는 값은 각 숫자가 가지는
값을 더한것. 각 숫자의 값은 숫자의 위치에 따른 무게값에 따라 결정됨.

소숫점 (radix point)

수라는 개념은 절대적이야. 십진법, 십육진법 이런건 우리가 그 수를 표현하기위해
만든것들일 뿐이야.

### 흔히 사용하는 기수법의 기수와 숫자

이진법
팔진법
십진법
십육진법

여러분 팔진법은 요즘 잘 안쓰죠? 그리고 십육진법은 숫자가 모자라니까 알파벳 (A,
B, C, D, E, F) 을 쓰지.

기수법은 별로 안좋은게 이진수, 십진수, 팔진수 다 같은 숫자 (digit)을 써서 문맥에
따라 모호할떄가 있어. 이럴땐 명확하게 해주지

### Fixed-point repr

소수점이 어떤 위치에 고정되어있다고 가정. 소수점을 컴퓨터 내부에서 표시할 필요가
없음.

### 진수변환

이진수 -> 팔진수, 이진수 -> 16진수는 그냥 세개 네개씩 묶으면 된다.

### 십진 정수 N을 이진 정수로 변환하는 방법
### 십진 소수 N을 이진 소수로 변환하는 방법

### 정수부와 소수부가 조합되어있는경우

각부분을 따로 변환해서 결과를 조합

### 십진수를 8/16진수로 변환하기

십진수를 이진수로 바꾸고, 그걸 8/16진수로 변환.

### Unsigned integer

이진수가 0이나 양의 값을 나타낼 때.

n비트 언사인드 인티저 x의 범위: [0, 2**n)

### Signed integer

부호 붙은 수를 n개의 비트로 인코딩하는 방버

1.  부호붙은 크기 표현
1.  1의 보수
1.  2의 보수
    * 하드웨어 구현이 제일 간단함. 대부분의 컴퓨터가 사용중

옛날엔 1의보수, 부호붙은 크기를 다 썼지만 2의 보수가 제일 좋다. 제일 간단하다 =
트랜지스터가 적다 = 빠르다, 그 공간에 다른일을 할 수 있다.

### 보수

r진법으로 표현된 n개자리수 x의 r의 보수(radix complement, complement) 는

r**n - x (if x != 0)
0        (otherwise)

x의 (r-1)의 보수(diminished radix complement) x` 는

x` = r**(n - 1) - x;

### 보수 구하기

십진수 836의 (10 - 1)의 보수는 10**3 - 1 - 836 = 999 - 836 = 163

이거 쉬운 계산은 그냥 각 자리수를 (r-1) 에서 빼서 다시 조립하면 됨.

x가 0이 아닌경우, x의 (r-1)의 보수에 1을 더하면 x의 r의 보수를 얻을수있음

### 1의 보수 표현 === (2-1)의 보수

r=2일 경우에, (r-1)의 보수를 사용하여 음수를 표현하는것.

ex) 6의 b1의 보수는 (2**4 - 1) - 6 = 15 - 6 = 9
9는 b1001이고 (2-1)의 보수 표현에서 -6을 나타냄
2**3 을 안쓰는데엔 이유가 있음

MSB는 부호비트
1이면 음수, 0이면 양수

단점. 0을 표현하는 방법이 두개가됨.

0000 = +0
1111 = -0

### 2의 보수 표현

현재 대부분의 컴퓨터가 사용중

n비트 이진수로 표현되는 정수 x의 2의 보수

### 2의 보수 표현의 범위와 값

[-2**(n-1), 2**(n-1) - 1]

### (피피티 참고, 도저히 타자로 못치겠는 슬라이드. 피피티 볼것)

### Modular arithmetic, clock arithmetic

Euclidean algorith

두 정수 m과 n(!=0)이 주어졌을때, m = qn + r, (0<=r<|n|) 을 만족하는 유일한 정수
q와 r이 항상 존재함.

이게 우리가 아는 나눗셈하고 어떻게 다르냐? 음수일경우 다름

일반적인 경우: -7을 3으로 나누면 몫은 -2, 나머지는 -1
유클리디안: -7을 3으로 나누면 몫은 -3, 나머지는 2 (항상 양수여야하니까)

### mod

q := floor(x/m), m != 0

r = x mode m = x - mq, m != 0

m은 modulus 라고 불림

*   앞으로 이용할 성질

    ```
    (a+b) mod n = ((a mod n) + (b mod n)) mod n
    ```

보통사람들이 말하는 소프트웨어는 소프트웨어가 아니에요. 그건 SI야. 그건
전공불문이야 아무나 가서 하면 돼. 그건 컴퓨터과학이 필요하지 않아. 그건
소프트웨어 하는게 아냐. 그건 용역하는거야. 컴퓨터공학 하는데에 필요없는것들.
그건 대단할 놀러지가 필요하지 않아.

### 합동관계 (congruence relation)

나머지가 같으면 합동이다.

### 모듈로-m 연산 (modulo-m operation)

모듈러스가 m인 합동관계를 이용한 연산

m개의 수 0, 1, 2, .. , m - 1을 연산에 이용

예) 모듈로-8 덧셈

1 + 4 === 5 (mod 8)
8 + 5 === 5 (mod 8)
7 + 3 === 2 (mod 8)
0 + 8 === 0 (mod 8)

내가 오늘한것들은 중학생한테 가르쳐도 다 할거야. 중요한건 이 숨은뜻을
이해하는거야.

--------

Lecture 03

부울 대수와 조합 논리회로
--------

*   1854년, George Boole
*   두개의 원소를 가진 집합 {0, 1} 을 정의하고, 이 집합에 대해 정의된 세
    논리연산 AND, OR, NOT 을 만듬
*   클라우드 섀넌의 논문에 베이스를 두고있음. 이때 섀년이 쓴 Information
    Theory가 지금 컴퓨터의 근간을 이룸.

### 부울 식

상수 0과 1, 변수, 논리연산자 and or not 을 포함하는 심볼들로 구성된 문자열.
부울식은 귀납적으로 정의됨

1. 심볼은 부울식
1. exp가 부울식이면 ~exp 도 부울식
1. e1, e2가 부울식이면 (e1 && e2), (e1 || e2) 도 부울식

### 곱셈항과 민텀

*   term, 항

    불 식에서 `+` 로 나뉜 각 부분을 항이라고 함

*   literal, 리터럴

    부울 식에 나타나는 변수 자체 (x)나 변수의 부정 (~x)

*   product term, 곱셈항

    리터럴의 AND 연산만으로 구성되어있는 항

*   minterm, 민텀

    n개의 변수를 가진 부울 식에서 각 변수에 대한 리터럴이 '한번씩만' 나타나는
    곱셈항. 한번씩 다 나와야됨

    예를들어 x, y 두 변수에 대해 나올수있는 모든 민텀은

    - ~x * ~y
    - ~x * y
    - x * y
    - x * y

### 부울 대수의 공리, Axiom

Axiom? 무조건 참이라고 믿는 / 가정하는 논리체계의 기반, 바닥.

* 집합 `B = {0, 1}`에 대한 부울 대수는 여섯 개의 공리를 가짐

1.  B에 속한 모든 x와 y에 대하여 x + y 와 x*y 도 B에 속한다.
2.  B에 속한 모든 x에 대해 x + 0 = x, x*1 = x 를 만족하는 서로 다른 원소 0과 1이
존재한다.
3.  B의 속한 모든 x와 y에 대하여 x + y = y + x, x\*y = y*x
4.  배분법칙
5.
6.

### 부울 대수의 정리, Theorem

* 공리를 이용하여 부울 대수에 관한 여러개의 정리를 증명할 수 있음

B에 속한 모든 x, y에 대하여..

1.  x + x = x, x*x = x
2.  x + 1 = 1, x*0 = 0
3.  (x + y)\*x = x, (x*y) + x = x
4.  (x + y) + z = x + (y + z), (x\*y)*z = x\*(y\*z)
5.  ~x 는 유일
6.  ~(~x) = x
7.  ~(x + y) = ~x\*~y, ~(x*y) = ~x + ~y

### 정리 1의 증명

진리표로 증명함.

사실 5번 빼고 다 진리표 쓰면 됨

### 정리 3의 증명

진리표 안쓰고 공리 쓰면 됨

```
  (x + y)*x
= x*(x + y)
= (x + 0)*(x + y)
= x + (0*y)
= x + (y*0)
= x + 0
= x
```

Term rewriting system을 쓰면, 정리 증명을 자동으로 할 수 있다. 프로그램을 짜면
'이 프로그램에서 이 시점은 x는 항상 1이다' 이런것도 Theorem prooving 기계로 함.

### Boolean function

B = {0, 1} 일때, n개의 변수 x1 x2 .. xn 을 가진 부울 식은 부울 함수 f: B^n -> B
를 정의함

n개의 변수를 가진 서로 다른 부울 함수는 총 2^(2^n) 개

### Functional Completness (함수의 완전성)

어떤 논리연산의 집합에 든 연산만으로 서로 다른 모든 부울 함수를 정의할 수 있으면
그 집합은 Functionally Complete 하다고 말함.

* 어떤 불 함수라도 AND, OR, NOT 의 조합으로 정의할 수 있음
* 어떤 불 함수라도 XOR 의 조합으로 정의할 수 있음
* 어떤 불 함수라도 XNOR 의 조합으로 정의할 수 있음
* 어떤 불 함수라도 NOR 의 조합으로 정의할 수 있음
* 어떤 불 함수라도 NAND 의 조합으로 정의할 수 있음

### 진리표를 부울 식으로 변환하기

*   부울 함수를 부울 식으로 쓸수만 있으면 회로로 만드는 과정은 정말 쉽기때문에
    이런 과정이 필요함
*   n개의 리터럴을 가진 민텀과, n개의 변수를 가진 진리표에 존재하는 입력 값의
    조합은 1:1 대응. n개의 변수를 가진 진리표의 한 Cell은 모두 n개의 리터럴을
    가진 민텀으로 표현 가능하다는 이야기
*   민텀은 대응되는 입력 값의 조합에 대해서만 1이 됨.
*   진리표에서 함수의 결과 값이 1이 되는 입력 값의 조합에 대응되는 민텀을 모두
    구하고, 이들을 OR 연산으로 묶으면 진리표를 부울 대수로 만들 수 있음.

* 반 가산기
  * 두개의 입력 비트 x, y를 더하고, 그 결과로 두개의 비트 s와 c를 출력하는
    전자회로

### 부울 식의 간소화

Karnaugh map

### 로직 게이트

부울대수는 논리회로의 수학적 모델링, 로직 게이트는 이것의 물리적인 구현

*   Propagation Delay

    전달 지연

*   게이트 딜레이

    게이트 하나 통과할때마다 1ps정도 작은 딜레이가 생김

    ```
    <@p> 45~65nm에서 온오프 걸리는 시간이 ps
    <@p> 1ㅔㄴ
    <@p> 1ps
    ```

### 기본적인 로직 게이트

이름  | 트랜지스터 수
------|---------
NOT   | 2
OR    | 6
AND   | 6
NOR   | 4
NAND  | 4
XOR   | 14
XNOR  | 12

### 로직 게이트의 함수적 완전성

*   Universal gate

    Universal gate 하나만으로 모든 부울 함수를 구현할 수 있음

### 로직 다이어그램

Schemetic

### Bus

옴니버스에서 나온 말. 동시에 전기신호가 전송되는 두개 이상의 연관된 와이어들로
이루어진 집합. 버스 내 각 와이어가 한 비트의 정보를 전송함

*   Word

    컴퓨터에서 하나의 단위로 취급하여 처리하는 서로 관련된 비트들의 묶음.
    일반적으로 하나의 워드 안에 든 여러개의 비트들을 동시에 처리하도록 컴퓨터
    하드웨어가 구현되어있음

### Tristate buffer

로직게이트는 아니지만 비슷한 역할을 하기때문에 쓰임

함수표(function table)는 진리표를 압축하여 더 간단히 나타낸것

조합 논리회로
--------

Combinational logic circuit

*   로직 게이트들을 와이어로 연결한 회로, 항상 현재의 입력값들에 의해 그 출력
    값이 결정됨.
*   여러개의 입력과 여러개의 출력을 가짐
*   각각의 출력은 하나의 불함수로 표현됨

### 멀티플렉서

*   셀렉터, MUX
*   2^n개의 입력과 n개의 선택 비트가 들어옴, 한개만 선택되어 출력됨
*   2-to-1, 4-to-1, 16-to-1 멀티플렉서

### 디코더

*   Demultiplexer
*   n개의 입력비트에 대해 최대 2^n개의 출력을 가질 수 있음
*   2-to-4, 3-to-8 디코더
*   enable 입력을 가질때도있음

### 디코더를 이용한 MUX 구현

2-to-4 디코더를 이용해 4-to-1 MUX 를 구현할 수 있음

--------

> 3월 11일

조합 논리회로만으로 ALU (기본 계산의 단위) 다 만들수 있음. GPU에도 이 벌겨 아닌
ALU가 수천개씩 들어있음. 하지만 이걸로 메모리는 커버 못함.

순차논리회로는 메모리와 관련이 있음.

책에 그림 자동으로 배치하는 알고리즘이 아직도 난제임

순차 컴퓨터 시스템 제대로 설명하려면 200~300p 나올거임. 그거 하고나면 컨텍스트
스위칭, 컨커런시에 대해 배울거임. 베이컨스 알고리즘 이런거 다 안돌아간다.

컨커런시에 대한 기반이 없으니, 순차컴퓨터 시스템부터 기반을 아주 잘 잡아놔야됨.
근데 이 쉬운 개념을 생각을 안하고 자기것을 못만드니 기본이 안되는거임.

베이컨스 알고리즘 이런거 다 안돌아가요
캐시 끄고해도 안돌아가
논캐시어블 해도 안돌아가
메모리 컨시스턴시가 보장이 안돼서그래
그거 OS 책쓴사람이 몰라서그래

멀티코어시스템을 공부하려면 싱글코어시스템을 잘 알아야돼요
공부하기 얼마나 편해 그지
이것만 보고 배우면 돼요
여러분들은 기니피그여
너 동물이야 아냐
동물이지
포유류 안의 영장류지
knuth

마이크로소프트 워드로 쓴거에요
레이텍으로도 써봤는데
워드가 더 편해요

아래아 한글에서 이미지 프로세싱하는걸 좀 빠르게 해달라고 막 그러고있는데
워드로 쓰고있어요
knuth 이분이 논문 출판할때 마음먹은대로 안돼서 Tex을 개발했어요.
이걸갔다가 쓰기 어려우니까 레이텍이라는걸 만든사람이 Lamport 라는 사람이에요

knuth 이분은 수학관련 논문이면 변하는게 없어요
어떻게 하면 멀티프로세서 시스템에서 여러개의 프로세스가 correct하게 돌아가는
그런걸 이야기한사람이 lamport에요
안돌아간다 이거야
이사람도 이걸 만들어서 사람들을 굉장히 이롭게 했어요
그게 연구에요 연구
연구를 하면 사람에게 practical하게 도움이 되게 해야지

아주 fundamental하게 그런것도 도움이 되는게 많아요
 여러분 물에 대해 얼마나 알아요
 화장품이 뭐냐
 물 + 기름이에요
 왜 이런얘기를 하느냐
 들어보라고 한번
 기름에다가 물을 넣는거하고 물에다가 기름을 넣는거하고
 성질이 달라져요
 이게 뭐겠어요?

기름을 까뜩채워
그리고 여기다가 계면활성제를 넣어요

그리고 물을넣어
그게 여러분 바르는 연고있지?
그거에요

로션같은거는 물에다가 기름활성제를 넣어서 기름을 넣는거야
이게 애멀젼이에요 애멀젼

ㄱㄴ데 왜 이렇게 되는가가 원리가 규명이 안되어있어
그래서 물에다가 기름썪은건 바르면 시원해요
근데 기름에 물 섞은건 바르면 끈

난 이런걸 왜 해봤을까?
그러게요
여러분이 냉각을 하죠
근데 써버를갔다 냉각을 하는데
근데 수냉식으로 쿨링하다가
이거 터지면 어떻게돼요?
정xxxx이가 이거 한순간의 실수로 3000만원 날렸어
물때문에
응?
과냉각을 시키면 어떻게돼요
그러면 공기중에 구름이생겨
그러면 3000만원 날라가는거야
18도 이하로 서버실을 과하게 춥게만들면 안돼
근데 우리는 5도로 했거든

그래서 날라간거야
근데 기름을갔다가 쓰면
기름은 이런 위험이 없는데
열전도성이 5배 나빠요

근데 우리가 기름에다가 물을 섞으면 비전도성이 유지가 되면서 점도가 굉장히 높아지고 열전도성은 물처럼 좋아져

그래서 내가 화학 실험실에 갔다가 이걸 했어
그래서 이게 됐을까 안됐을까
안됐어 (?)
내가 이거 하려고 논문을 많이 읽어서 기계공학과 논문도 많이 읽어봤는데 별거아니더라구
그래서 그냥 기름으로 했어요
기름이 어떤 기름이겠어요?
미네랄 오일이라고
존슨즈 베이비오일
한말에 오만원 주면 사
이거 하면서 실험에 막 얼굴에 발르니까
보습효과가 있어서
피부가 좋아지더라고
음식에도 들어가요
(멀티코어 수업임)
보통은 미네랄오일 있으면 서버를 그냥 거기다가 담궈버리는데
그러면 귀찮아
서버실이 온 기름천지가 된다고
우리가한건 방열판 안에 기름을 흘려서
터져도 문제가 없지
고런 장점이 있지
거의 세계 최초라고 할수있지
(멀티코어 수업임)
내가 이걸 옆 연구소에 많이 홍보했지
이게 많이 좋은데 대신 방열판이 튼튼해야돼
이게 컴퓨터를 잘 몰라도 상식으로 하는거야
연구란게 원래 그래요
옆길로 이야기가 많이 샜네
순차논리회로가 그래서

순차 논리회로
--------

순차논리회로는 클락을 가짐. 현재의 입력값 뿐만 아니라, state를 갖고 이전
입력값에 영향을 받음.

순치 논리회로 = 조합 논리회로 + 메모리

동기 순차 논리회로, 비동기 순차 논리회로로 나뉨

### 클락

일정한 간격으로 rising edge, falling edge가 생김.

### 랫치 & 플립플랍

우리나라 책들이 이게 아주 헷갈리게 써있어.

커뮤니케이션이 반이야.
앞으로 사회 나가면 소통
생각을 한다음에 남한테 설명하는게 반이라고
남 한번 가르쳐봐요 엄청나게 공부 많이해야돼

메모리는 보통 플립플랍으로 구현됨.

*   하나의 플립플랍은 한개의 비트를 저장
    * 두개의 구분 가능한 상태
*   플립플랍은 보통 랫치로 구현함
    * ..

**플립플랍과 랫치의 차이**

### SR Latch

두개의 입력 Set과 Reset, 두개의 출력 Q와 Q\`

`S = 1 && R = 1` 이 아닌이상 항상 `Q\` = ~Q` 를 만족함

S | R | Q
--|---|---
0 | 0 | Q_prev
0 | 1 | 0
1 | 0 | 1
1 | 1 | *undefined*

`S = 1 && R = 1` 이면, Q가 0과 1로 반복적으로 바뀌는 불안정한 상태에 이름. 허나 그 값이 1이 될지 0이 될지 예측할 수 없음

이걸로 1 비트를 저장할 수 있음

### D Latch

데이터를 지정하는 입력 D

새로운 입력을 받아들일지 말지를 제어하는 입력 C

C = 1 일동안 랫치의 출력이 입력 D에 따라 바로 바뀜

No undefined state

C | D | Q
--|---|---
0 | X | Q_prev
1 | 0 | 0
1 | 1 | 1

### D 플립플랍

D 랫치 두개를 달고, 클락을 달아줌. Rising Edge에서 D를 저장

### Master-slave D flipflop

(멋진 time 다이어그램)

D가 무작위로 주어졌을떄
Q_master는 클락이 0일때 (클락이 마스터를 활성화시킬때)만 입력을 받고
최종 Q (=Q\_slave)는 클락이 1일때 (클락이 슬레이브를 활성화시킬때) Q_master의
입력을 반영받음

플립플랍: 클락이 Rising edge 일때의 입력 D를 저장하여, 출력하는것이 플립플랍

랫치: 그냥 마지막 입력을 저장하여 출력하는것이 랫치

### Register

한번 정보를 저장하면, 입력이 바뀌어도 정보가 계속 유지되는 장치.

(그림)

이게 개념적으로 이런식으로 작동한다는거지 실제로 이렇게 만드는건 아님

### 1-bit register

(멋진 time 다이어그램)

Load signal이 1이고, rising edge인순간 그 값을저장함.
Load signal이 0이면, 입력이 뭐가 되든 저장된 값이 유지됨.

### Counter

Rising edge마다 숫자가 1씩 증가하는 N-bit register.

Modulo-4 counter. Program counter

프로그램 카운터가 모에요
컴터가 다음으로 실행할 인스트럭션의 주소가 저장된 레지스터요
모에모에큥
그럼 카운터가 몇씩 늘어요
워드단위로 늘어요 (RISC 기준. 요즘 CISC는 추세랑 안맞아서)
워드가 모에요
컴퓨터가 기본으로 처리하는 정보의 단위요

### State table

입력, 출력, State간의 시간에 따른 관계를 나타냄

modulo-4 counter의 state table은 아래와 같음

### FSM

동기식 순차 논리회로는 FSM과 1:1 대응됨.

### Mealy FSM

출력 함수 H가 현재상태와 입력의 함수일때, 즉 H:S X I -> O

### Moore FSM

출력 함수 H가 현재상태만의 함수일때, 즉, H:S -> O

### FSM의 구현

출력 함수 H와 다음상태를 정의하는 전이함수

### Random Access Memory

컴퓨터에서 주로 쓰는 메모리. 이진 정보가 RAM에 워드 단위로 저장됨.

워드가 액세스되는 순서 없이 워드를 읽거나 쓸때 동일한 시간이 걸리는 메모리를
뜻함. 램 내 워드의 위치는 접근속도에 영향을 미치지 않음

RAM의 용량 또는 크기 = 저장할 수 있는 총 비트의 개수

RAM의 구성
*   워드의 갯수 * 비트로 나타낸 워드의 크기

### RAM Cell

Data\_in, select, write가 입력으로 들어오고 Data_out이 출력으로 나감

RAM 여러개를 CS(Chip Select)비트로 또 동시에 여러개를 조종함.

### 큰 용량의 RAM 구현하기

Word를 냅두고 칩을 늘려도 되고, Word를 늘리고 칩을 냅둬도 됨

## RAM의 액세스

전파지연(propagation delay)때문에 타이밍 관련 이슈가 많음.

1.  Addr 입력을 주면 아웃풋이 나오는데, 데이터가 불안정함. 데이터가 제대로
    출력되기까지 시간이 필요함
1.  유효한 주소를 넣기 시작한 순간부터, 유효한 데이터가 처음 나오기까지의 시간을
    메모리 액세스 시간(Memory Access Time)이라고 함. 보통 60~55ns 걸림
1.  이 이외의 상태에서는 tristate buffer가 끊어진 상태(하이 임피던스) 상태로
    존재함.

쓰기도 비슷함.

### DDR2, DDR3, DDR4

### Assignment

DRAM에서, DDR2, DDR3, DDR4 각각이 무엇을 의미하는지 조사를 해오기. LPDDR3, LPDD4
(Low power, 서너배 비쌈) 이것도 조사해와.

--------

연구는 실용적으로 해야돼

우리나라 대학 50개만 남기고 싹 정리해버려야돼

대학에서 놀면 안되죠? 죽도록 시켜야지 공부를

국민의 세금을 응 그렇게 써서 돼?

내 애들이 잘사는 세상을 만들려면 여러분 교육을 잘 시켜야돼. 내 애들이 아직
어리단말이야.

내가 외과의를 하고싶은데 나이가 들면 못할거같아.

요즘들어 난 땡기는게 그거야
외과 들어가서 수술 한번
손으로 한번

외과 수술을 하려면
눈도 좋아야하고
손도 안떨려야돼
근데 15년 후엔 떨려야할거야


짜릿하잖아
하나 끝내고나면

응급실에 있으면 계속 짜릿하겠지
나: 교수님 혹시 허트로커라는 영화 아시나요

나: 거기 주인공도 그 짜릿함때문에 폭탄해체반을 제대를 못하고 계속 군복무를
하는데요
폭탄해체는 하기싫어
난 고등학교때 우리나라에선 골프 안치겠다고 평생 결심했어

그리고 한국들어와선 평생 골프 손 안대고있어요
골프장 만드는건 우리나라엔 백해무익해
운동하고싶으면 탁구를 치지

확실하게 배워서 간다 이렇게 생각해야돼

이진 정수의 연산
--------

### 이진 정수의 시프트 연산

Logical shift (>>)

Arithmetic shift (>>): 빈공간을 MSB로 채움. 부호비트 보존

### 시프트 연산과 곱셈, 나눗셈

2의 거듭제곱 곱하는걸 시프트로 표현할 수 있음.

부호없는수에 8 곱하고싶으면 그냥 << 3 하면 됨.
2의 보수도 똑같음. -3에 <<3 하면 *8 이랑 똑같음

오른쪽으로 시프트하는것도 나눗셈. /8 하고싶으면 >>3 하면 됨. 근데 유클리디안
디비젼임.

-7을 4로 나누면 -7 = 4\*(-1) - 3이 아니라, -7 = 4*(-2) + 1. 실제로 -7 에서 >>3
하면 -2 나옴. 근데 C에서 나눗셈하면 유클리디안이 아니라 우리가 아는 나눗셈이
나옴.

### C 언어의 시프트 연산

오른쪽시프트와 왼쪽시프트 연산을 지원

C99 표준은 음수에 대한 오른쪽 시프트를 정의하지 않음. 컴파일러 디펜던트임.

### Sign extension

작은 자리수의 2의 보수를 큰 자리수로 늘릴떄, 생기는 빈 공간을 MSB로 채우기. 그게
바로 사인 익스텐션

### Unsigned int의 덧셈

더해YO. 오버플로우 생기면 자르고 오버플로우 비트에 표시하면 돼.

n비트 unsigned int 의 덧셈은 module n**2 연산을 수행하는거랑 같음.

### 2의 보수 표현의 덧셈

그냥 unsigned int라고 생각하고 무식하게 더한다음에 계산 다 하고 2의 보수
표현으로 읽으면 됨.

왜 `1 + 1 = 2` 인가? Peano arithmetic.
http://en.wikipedia.org/wiki/Peano_axioms

##### Overflow

2의 보수는 오버플로우 체크가 조금 특이함. 덧셈을 계산할때 MSB로 들어가는 carry랑
MSB에서 나오는 carry랑 다르면 오버플로우임.

### 전가산기 & 반가산기

반가산기

x,y를 더해서 합 s와 carry 출력

전가산기

x, y, c\_in을 받아서 합 s 왜 c_out 출력

하프애더 하나와 전가산기 n-1개로 n비트 가산기를 만들 수 있음

unsigned int, signed int의 덧셈 하드웨어는 오버플로우 감지만 다르고 다 같음.

### 이진 정수의 뺄셈

Unsigned

걍 무식하게 하면 됨

2의 보수

x - y = x + (-y) = x + y' + 1

반감산기, 전감산기

n비트 adder 살짝 바꾸면 n비트 subtracter 만들수있음 (x - y = x + y' + 1)

### 부호 없는 수의 곱셈

십진수 곱셈이랑 같은 원리로 함.

근데 회로도 그렇게 짜느냐? 망함

시프터랑 덧셈기 여러개로 곱셈기 만들수도 있음.

곱셈. 진리표를 부울 대수로 펴서 연산자 갯수를 제일 줄여서 이걸 해보자.

CPU 만드는건 쉬워
성능이 안좋아서 그렇지
그얘기 해줄까?
지루할거같으니까
에테아라는게 있죠
ETH
아인슈타인 나온데에요
스위스 연방대학
스위스에서 제일 좋은학교인데
여기에 니콜라스 wirth라는 사람이 있어
늙어서 80이 생겼는데
치매끼가 있는거같애
늙어서 치매가 안올라며
담배를 많이펴야돼
치매 걸릴 기회가 없으니 치매를 안걸리시겠죠 교수님
PASCAL 만든사람이야
프로시져 랭귀지 만드는
이거 공로로 튜링 어워드를 만든 사람이에ㅛ
이걸가따 쪼금떠 발전을 시킨게
Oberon 랭귀지를 만들어서 거기선 이제 학생들 만들땐 이걸 쓰고
Oberon OS 도 있어
Oberon 프로세서도 있다고
그래서 거기엔 C랑 C++을 안가르쳐
미친놈들
Oberon에 OOP 개념도 있어
이야기하는 이유가
여러분들 별로 어려운게 아니라고
CPU 디자인하는거
다 할수있어
다만
테이프아웃하고 최적화 하는거
트랜지스터 뭐 수도없이 많이써도 얼마 들지도 않을거고 최적화 안하면 만드는건 쉬워
OS 만들어서 얹고
컴파일러 만들어서 얹고
한명이면 할수있어
엣날에 그런생각을 했는데
학부 1학년 2학년한테
과목을 4개를 연달아서 해서
CPU -> OS -> 컴파일러 다 만드는걸 해서
학생 1인당 1 컴퓨터를 만들게하는걸
생각을했어
다른학교에서 굉장히 2년연속해서 버클리에서 이런식으로 한번 했었어
여러분 이렇게 하면 배우는게 굉장히 많 다고
여러분 이런 경험 한적 있어요?
너 OS 들었니
너 OS 만들어봤어
나: 아니요
OS 안들었어?
아직이요
왜안들었어
아직 들을 나이가 안됐어요
너 15학번이야
13이요
너 몇학년이야
2학년이요
1년 휴학했어요
근데 이건 왜들어
\>ㅅㅇ
(?)

이런건
납땜하지말고
FPGA로 만들면
여러분도 쉽게 CPU 만들수있어요
얼마나 좋아

### 부호 없는 이진수의 나눗셈

십진수의 나눗셈과 원리가 같음

나이브하게 구현하면 아까꺼랑 똑같음 대신 MUX가 좀 많이 들어감. 복잡함..

### 2의 보수의 이진수 나눗셈

```
resut := x / y
```

left, rigth 의 부호를 잘 조작하면 됨.
유클리디안 나눗셈 말고, 우리가 아는 나눗셈은 부호 떼버린다음 나눗셈하고 나중에
다시 부호를 붙이면 됨.

줜내복잡함.

빠르게 나눗셈하기: http://arith.stanford.edu/~hung/papers/asilomar.pdf

시험문제는 어떻게 낼거냐
이걸 구체적으로 물어볼건 아니고
이걸 어떻게 하는가 설명을 시킬거야
그러니 이걸 이해를 해야돼
아까 디비젼 하는 진리표를
논리게이트로 옮긴거뿐이야

--------

> 3월 18일 수요일

부동소수점
--------

### 과학적 표기법
m * b^e

m: mantissa
e: exponent
b: base

### 정규화된 과학적 표기법
m의 범위를 [1, b)로 한정시킴

이렇게하면 0 외의 모든 수는 표현할 수 있음


### 부동 소수점 표현

### IEEE 754
1985년에 제정됨, 2008년에 IEEE754-2008로 개정됨

1.  32, 64, 128비트 - 세가지 이진 부동소수점 기본형식
1.  십진 부동소수점
1.  Extended precision format - 확장 정밀도 포맷의 기준. 80비트짜리

### IEEE 754 이진 부동소수점 표현
* 32: 단정도
* 64: 배정도
* 128: 사배정도

sign 비트 1개
E 비트 w개
F 비트 k개

1+w+k = n

case                     | kind
-------------------------|-----------
E == 00..0, F == 0.00..0 | +-0
E == 00..0, F != 0.00..0 | 서브노멀 값
E != 00..0, E != 11..1   | 정규 값
E == 11..1, F == 0.00..0 | +-INF
E == 11..1, F != 0.00..0 | NaN

### 라운딩
* 어떤 실수는 그 값은 IEEE 754로 정확하게 표현할 수 없음
  * 그 수에 가장 가까우면서 부동소수점 표현으로 표현할 수 있는 값으로 어림잡아 표현
* Rounding: 더 적은 수의 자릿수를 가진 값으로 주어진 수를 어림잡는 작업
* Rounding error, Round-off error: 원래의 값과 라운딩한 값의 차이

* Round to the nearest, ties to even
* Rount to the nearest, ties away from zero
* Round towards +INF, rounding up, ceiling
* Round towards -INF, rounding down, floor
* Round towards -INF, truncation

floor와 truncation의 차이? 음수

70년대엔 1달러가 꽤 큰돈이었는데, 그당시에 책 앞머리에 틀린말 있으면 1달러
이러곤 했음

### 이진수의 라운딩
이진수의 경우도 십진수와 같은 규칙을 적용할 수 있음

표준에 내정된 라운딩 규칙: Round to the nearest, ties to even

### 정규 값
Normal value, Normalized value

E != 00..0, E != 11..1 일때

v = (-1)^s * m * 2^e, 1 <= m < 2

소수부 F의 왼쪽에 암묵적인 1과 그 사이에 소수점이 존재함을 가정

0 ~ 1000 1100 ~ 1011 1111 1010 0100 0000 000

일때

e = E - bias = b10001100 - 127 = 140 - 127 = 13
m = 1 + f =

##### 고정소수점에서 IEEE 754로 바꾸기

```
  103.625
= b1100111.101
= 1 * b1.100111101 * 2^6
=
```

```
  -3.141595 * 10^10
= -1 * b1.110101000010001001010110101011 * 2^32
 (round to nearest even)
= -1 * b1.11010100001000100101011 * 2^32

0 | 0010 0000 | 1110 1010 0001 0001 0010 101
```

### 서브 노멀 값
Subnormal value, Denormalized value

E = 00...0, F != 0.00...0

v = (-1)^s * m * 2^(1-bias), 0 < m < 1

m의 값은 소수부 F의 값을 f라 할 때, m = f

서브노멀 값은 소수부의 바로 왼쪽에 소수점을 가정하나 정규값처럼 암묵적인 1을
가정하지 않음

```
  2^(-149)
= 1 * 0.00000000000000000000001 * 2^(1-127)

0 | 0000 0000 | 0000 0000 0000 0000 0000 001
```

### 오버플로우와 언더플로우
서브노멀 값, 0은 언더플로우로 취급

+INF, -INF는 오버플로우로 취급

### INF
E = 11...1, F = 0.00..0

IEEE 754엔 무한대에 대한 연산도 정의되어있음

n / INT = 0.0
-n * INF = -INT

+INF 는 모든 정규값, 서브노말값보다 큰것로 정의됨
-INT 는 모든 정규값, 서브노말값보다 작은것으로 정의됨

### NaN
Not a Number

E = 11...1, F != 0.00...0

계산의 결과값을 나타낼 수 없을때 사용 (`0/0`. `sqrt(-1)`, ...)

NaN이 들어가는 비교연산은 `NaN != NaN`만 true이고, 그 외엔 무조건 다 false임

### x86 80-bit extended precision
Intel의 80x87 계열의 부동소수점 Coprocessor를 위해 처음 제안되었고, 그 이후 x86
아키텍처의 부동소수점 연산장치에서 계속 사용함

바이어스된 지수의 바이어스는 16383
실제 지수 e는 E-16383 으로 계산됨

얘는 암묵적인 1이 없고, 비트에 1로 표현되어있음

* QNaN
* SNaN
* undefined
* normal values
* subnormal values
* pseudo-denormal values

1 | 100 0000 0010 0001 | 1 | 1101 0100 0010 0010 0101 0110 1010 1100 ...

익셉션이 모야. 트랩이랑 폴트 그거 다 비슷한거야

### 부동소수점 연산

교환법칙 commutativity
결합법칙 associativity

* 실수의 덧셈은 교환법칙과 결합법칙이 성립
* 라운딩때문에 덧셈, 곱셈 결합법칙은 성립 안함

점점 커지는 숫자 여러개를 더할때 작은것먼저 더하는게 나을까 큰것먼저 더하는게
나을까? - 작은거 먼저 더하는게 나음.

### 부동소수점 표현의 덧셈과 뺼셈
* 뺄셈은 음수취해서 덧셈하면 됨
* 먼저 지수가 더 큰수의 소수점에 맞춰서, 두 수의 지수를 일치시킴
* 가수를 더함
* 가장 가까운 짝수로 라운딩

### Round-off error
```
x = (-1)^s * m * 2^e, 1 <= m < 2

|m_r - m| <= 1/2 * 2^(-23)

|x_r - x| / |x| <= 1/2 * 2^(-k)
```

라운드 오프 에러의 상한을 정할 수 있음. 이를 엡실론, 유닛 라운드오프라고 함.

엡실론 다 배웠지
(나) 넹
칼큘러스할때 다 가르치나
(나) 넹
이해했어?
(나) 넹
이해했다고 느낀건 아니고?
(나) 사실 둘이 구분하기 어렵지 않나요
몰라
그거 수학과 3학년도 이해하면 대단한건데

### 부동소수점 표현의 곱셈
곱셈이 더 쉬움 (지수 맞추는 과정이 생략됨)
부호는 곱셈 하고 따로 수행

### 부동소수점 표현의 나눗셈
지수끼리 빼고, 가수끼리 나눠서 수행.

### Fused Multiply-Add
`x*y + z`를 한번에 수행할 수 있음

FMA 연산을 수행하는 특별한 연산장치
* FMA 연산을 위한 머신 인스트럭션을 제공
* 요즘 대부분의 CPU/GPU가 이를 제공
* 컴파일러 옵션 주면 이거 쓸 수 있음

FMA가 유용한 경우

* Dot product
* 행렬곱
* 다항식의 계산 (묶어서)

속도뿐만 아니라, 정확도도 높아짐 (라운딩을 한번만 해서)

### 반올림을 안하고 nearest even으로 간 이유
더 공평해서? 하드웨어를 만들기 쉬워서? 몇년간 논의가 있었긴 했을거임

### 96, 128 비트가 아니라 80비트를 쓴 이유?
80비트로 하면 F가 64비트로 딱 떨어져서 계산하기에 좋았었음

--------

> 3월 23일

암호를갔다가 해독하는 작업인데 어떻게하면 빠르게할 수 있느냐
내가 하는거랑 앨런튜링이 하는거랑 뭐가 다를거같아
앨런 튜링은 암호 해독 체계를 발견한 사람이고
나같은경우는 무식하게 빠르게
예를들면 패스워드를 알아낸다
제일 쉬운방법이 모에요
몽땅 다 트라이해보는거야
그럼 빨라야될거아냐
원래 컴퓨터라는게 뭐하는거에요?
단순 작업을 무식하게 빠르게 하는게 컴퓨터야
AI, 머신러닝
별거있을거같지
별거없어
안그러면 뭐
그게 안돼요
그냥 빠르면 장땡이야
단순 작업을 빠르게 하는거야
예를들어 단백질 구조분석을 한다고 쳐보자
이게 뭔가 대단한게 있을거같지
별거없어
F = ma 계산을 갔다가 초당 수백만번을 하는거야
수백만번이 모야
몇조번을 하는거지
굉장히 간단한거에요
근데 그것때문에 굉장히 특별한 컴퓨터를 만들잖아
원래 이거 다 단백질 구조분석을 하려고 만든건데
잘돼서 그냥 팔고있는거야
뭔가 문제를 풀려그러다가 나온건데
(갑자기 폰노이만 아키텍처로 넘어감)

CPU
--------

어줍잖게 아는게
모르는거보다 더 안좋은거야
알라면 확실히 알아야돼
생각좀해
생각을 하고 정확한 답인가를 보고
니 생각을 논리적으로 argu를 해봐
stored program concept

폰노이만 아키텍처가 뭐가 특별해요? Stored Program Concept야. 문제를 하나 풀고
선을 다시 연결할 필요가 없어. 어디다가 저장을 했다가 다시 불러와서 쓰면 된다
이거지.

'프로그램 내장 방식' 참정확한 번역이 아냐. 참
안타까워요. 우리 나와있는 컴퓨터 90%는 다 쓰레기야. 자기딴에는 뭐 필드에서
지식이 싸였다고 쓰는데 전부 엉터리야.

30년대가 참 많은게 발견된 해야. 그 연도에 처치인코딩이
튜링머신과 1:1 대응되다는게 발견되었다
하버드는 데이터랑 코드 분리된것
람다칼큘러스 한번 배워봐
알만해
너무 수학적으로 가서 문제지
나도 배우고 한번도 안써봤어
실제로는 컴퓨터 구조에 대해 더 잘알고있는게 훨씬 필드에 도움이 돼

### Stored Program Concept

프로그램을 실행시킬때 선을 다시 연결하지 말고, 펀치카드같은데에 프로그램의
정보를 저장해놓으면 알아서 실행을 해주는것.

예전에도 말했지만 이 핸드폰에 들어가는 기술 진짜 아무것도 아냐. 이거는
머라그럴까 어떻게 이미 있는 기술을 어떻게 디자인과 잘 인터그레이션하느냐가 빛을
발한 케이스지. 중요한건 저전력화시키는 하드웨어, 어떻게 유저인터페이스 빠르게
하느냐. 우리나라 삼성엔 그런 기술이 없어.

삼성 부사장 한명 외에
최적화 잘아는사람 아무도 없어
성격이 굉장히 쓰레기같아요
나하고 굉장히 비슷한데
어떻게 그 대기업에서 인간관계를 유지하고 살까 했는데
원래 삼성 60살 넘으면 다 짤리거든
근데 아직도 8년 넘게 삼성에 계셔
IBM에서 컴파일러 하시던분인데
타이젠 만드시는거야

내 자식들이 잘살으려면 너희(대학생)들 전투력을 증가시켜야돼

### Processor, CPU, and Core

* Core
  * Instruction을 실행하는데에 직접적으로 관여하는 하드웨어들을 몽땅 묶어서
    코어라고 부른다.
  * ALU, FPU, Private L1/L2 caches, ...
* Processor or CPU
  * 한개 이상의 코어를 모아, shared resources를 붙여놓은것.
  * 문맥에 따라 Processor는 하나의 코어가 들어있는 칩을 일컫을때가 많다.

### Uncore

A term used by Intel.

코어 안에 들어있지 않은 하드웨어 컴포넌트들 (QPI controllers, L3 cache, ...)

### Techniques to Improve a Single Core

* VLSI 기술이 발전할수록, 칩의 공간이 늘어나서 이것저것 넣을수 있게 되었음.
* On-chip caches
* Instruction pipeline

### Dependences (dependency)

```
디펜던시 깐다
옳게 배운사람들은
Dependences 라는 용어를 써요
무식하게 배운사람들이 Dependency라고 불러요

이트 무라우 (??)라는 무슨 대학 ㅁㄴㅇㄹ 누구의 스승의 누구가 소프트웨어 병렬화의
필요성을 피력할때 처음 dependences라는
용어를 썼어요.

그래서 이걸 써야돼
유식한사람들은
너넨 나한테 배웠으니까 이 용어를 써야돼
그래서 책이랑 논문들을 보면
멀티코어 하는사람들 계보를 알수있어
그리고 Dependency 같은 단어가 들어있으면 리젝시키는거지
ㅎ~ 넝담
(비순차 실행 설명으로 넘어감)
```

순서가 뒤집혀서 실행되면 안되는 어셈 코드들

* Flow (true) dependence
  * 순서를 바꿀 수 없는 디펜던시
* Anti dependence
  *
* Output dependence
  *
* Input dependence

##### Dependence removal

```
t := a + b
c := t + 3
t := 4 + d
f := t + 5
```

이렇게 코드가 있는데, 이름만 약간 바꿔도 인풋 디펜던시/아웃풋 디펜던시가 다
끊어진다.

```
t1 := a  + b
c  := t1 + 3
t  := 4  + d
f  := t  + 5
```

### Pipeline Decode Execute
Stage 5개를 만들어요

IF -> ID -> EX -> MEM -> WB

이걸 한칸씩 밀어서 실행해요

```
IF -> ID -> EX -> MEM -> WB
      IF -> ID -> EX -> MEM -> WB
            IF -> ID -> EX -> MEM -> WB
```

### Pipeline Hazard
* 다음 인스트럭션이 다음 클락 사이클에 실행되지 못하는경우
* Data hazard
* Structural hazard
* Control hazard

### Data hazard

(PPT에 아주 좋은 그림이 있음)

### Resolving Data Hazards

* Stalling the pipeline
* 파이프라인에 거품을 끼워넣어서 일부러 몇사이클을 낭비해서 순서가 원래대로
  돌아올때까지 실행을 늦춤

##### Software

일부러 nop 을 끼워넣음

##### Hardware

* Transparent register file
  * Write-back을 두단계로 만들어서
* (그 외의 방법 PPT에)

##### Structural Hazards

* 두 코드에서 동시에 서로 다른 메모리에 액세스해야할경우

##### Control Hazards

분기명령으로 인해 이 뒤에 실행할 예정이었던 코드들이 다 무의미해질경우.

### Branch Prediction

의외로 잘통한다.

* For문 돌떄 쓰는 조건문. For문이 긴 for문이면 조건문 결과가 거의 항상 비슷하게
  난다.

소프트웨어 소프트웨어 하는데 하드웨어 없으면 소프트웨어 성능 절대 못뽑아요.

### Out of order execution (OoO)

IF -> ID -> Resevation station -> EX / EX / ... / EX -> Reorder buffer -> WB

### Tomasulo's Algorithm

IBM 360/91

* Single issue

* In-order issue
* Out-of-order executiokn
* Out-of-order dispatch
*

이재진교수님이
Out-of-order exec 만든사람한테
이것들 용어의 정의가 너무 모호해서
가르치는데 힘들다고
저거 만든사람한테
막 얘기했더니
그사람이
꼬마들 가르치는데 그거 명확할필요없다
이랬다고함

보통 전기 많이 쓰면 안되는 ARM7 ARM9같은 애들은 그냥 in-order-exec 함.

그리고
SNUVM 만든 이야기가 나온다
내가 이거 만드느라 ARM 레퍼런스를 수도없이 읽고
집에안가고 그래서 막 집에서 쫓겨나고 그랬어
이거 기억땜에 내가 이제 ARM은 편해요

### Issuing and Dispatching an Instrucion

### Precise Exception
익셉션도 순서를갔다가 우리가 보존을 해줘야된다는거야. 페이지폴트가 났다고쳐봐.
그러면 실행 도중에 인터럽트가 걸린건데, Page를 갔다가 OS에서 가져오든지 새로
할당하든지 할텐데, 우리가 out-of-order exec를 했기때문에 폴트가 원래보다 더 먼저
일어날 수 있어.

그래서 폴트가 나기 전엔 명령어를 전부 실행하고, 순서를 정확하게 보존해줘야돼.

### Retirement (Graduation)
Reorder buffer에서 instruction이 사라지는경우.

* Instruction이 커밋을 했거나 (폴트, ..) (the result is made permanent)
* Instruction이 없어졌거나 (without making permanent change)

### Superscalar Processors
Vector Processor는 아니지만, 여러개의 값(스칼라)를 동시에 처리해서 슈퍼스칼라
프로세서.

OoO 할때엔 issue를 하나밖에 안했었음. 하나씩 차례대로 이슈를 했었음. 하나의
이슈로는 안됨. 이슈를 여러개를 동시에 할 수 있으면 더 빠를거임.

Instruction Fetch랑 Decode unit을 여러개를 둠.

Dynamically issue multiple instructions in each clock cycle
* 이슈할때도 인오더로 이슈한거랑, 아웃오브오더로 이슈하는거랑 나뉘는데,
    out-of-order issue가 더 우수함

ILP(Instruction Level Parallelism), 한번에 몇개의 명령어가 동시에 처리될 수
있는가, 한번에 몇개의 명령어가 동시에 이슈될 수 있는가.

보통 동시에 실행시키는 명령어 갯수가 2.8개로 멈춰있어서 ILP가 일정 이상 발전을
안하고있음.

우리의 현실. 프로그램상의 디펜던스때문에 이슈를 동시에 할수가 없음. 하드웨어를
아무리 잘 만들어놔도 소프트웨어가 익스플로잇을 못하면 그게 안됨.

그런 문제를 어디서볼 수 있을까? 여기(갤럭시 스맛폰)에서 볼 수 있지.

### VLIW Processors

Very Long Instrucion Word

디펜던시가 없는 인스트럭션들을 하나의 긴 인스트럭션으로 만들어주는거임.
하드웨어가 다이나믹하게 스케줄링을 안해줘도 알아서 고정된 갯수의 여러
인스트럭션들이 동시에 fetch, decode, issue, execute됨.

프린터 안에 VLIW 프로세서가 많이있음. 아이태니엄에도 이런거 들어있음. 처절하게
망했죠?

Static instrucion scheduling by a compiler

삼성이랑 엘지에 컴퓨터 아키텍처 할 줄 아는사람이 몇명이나 있을것같나? 10년전까진
0명이었어. 디자인 오토메이션은 이거랑 전혀 상관없는데 자꾸 이걸 건들라그래. 근데
삼성이랑 엘지엔 디자인 오토메이션(캐드)만지는사람밖에 없어.

우리나라 삼성에 컴파일러 만지는사람이 몇명이나 있을것같아? 0. 러시아에 외주나
주고앉아있고. 상무가 쥐뿔도 모르는놈이 나 불러서 자기자랑이나 하고 3.5억 주고
외주한걸 잘했다고 자랑이나 하고있더라고. 인간같지도 않은놈이 안짤리고 잘
살아있고. 아직도 우리나라는 기술을 잘하는사람이 아니라 인간관계 좋은사람이 더
잘나가.

우근이가 할수있는걸 왜 삼성이 안할까? 자신감이 없어서그래. 잘못건드렸다가 돈
시간만 날리고 망할까봐 그러는거지.

컴파일러 아키텍처 이거 다 맞물려있는거야. 밑에 시스템 이해 못하면 소프트웨어
백날 만들어봤자 아무 쓸모 없어.

--------

> 3월 25일 (지각)

원래 프로세서 만들떄엔 타겟하는 어플리케이션이 무엇인지가 있어야해. 이런식으로
캐시 폴리시같은거 어떻게 정할지 모르겠을경우엔, 어플리케이션을 돌려보면
아는거야. 응용이 중요하다는거야. 삼성에서 프로세서를 만든다 하면 이걸 왜
만드는가 이런게 중요한거야.

### Non-Blocking/Lockup-Free Caches
이게 무슨소리냐. 둘이 같은소리인데

우리가 어떤 주소에 있는 데이터를 리퀘스트했는게 이걸 미스했어. 그러면 이걸
가져와야겠지? 근데 메모리까지 가져오기엔 너무 바쁘단말야. 메모리 레이턴시가
있잖아. 캐쉬에서 메인 메모리까지 가서 가져오는데 시간이 너무 기니까 하드웨어를
좀 더 둬서, 여러개의 미스를 동시에 처리할 수 있는/미스 패널티를 줄이는
하드웨어를 더 두자는거야.

MSHRs : Miss Status/Information Holding Registers

캐시가 미스되어 메인 메모리에서 정보를 가져오는중에도, 다른 캐쉬를 계속 줄수있는
캐쉬

### Cache Performance Metrics
캐시의 성능을 재는 세 기준

* Miss Rate
  * 미스가 얼마나 잘나느냐
* Hit Time
  * 캐시가 히트했을때, 얼마나 빨리 갔다주느냐
* Miss Penalty
  * 캐시가 미스되었을때, 얼마나 늦게 갔다주느냐

가상 메모리
--------
버추얼 메모리가 처음으로 생긴데가 어디냐. 이거 중요하냐 안중요하냐. 중요해. 야단
안맞으려면.

내가 Mutix 연구를 하다가 MIT에서 발표를하다가 이걸 MIT에서 처음 했다고 잘못
발표를 하다가, 뒤에 앉아계시던 노인이 너 그거 확실하냐고 하시는거야.  아틀라스
시스템 - 맨체스터 대학에서 처음 만든거다. 이러시면서 저녁먹고 좀 얘기좀 하재.
스티브 퍼버, 암 시스템 만든 70넘은 노인이야. 근데 내가 이거 틀려서 저녁먹으면서
한시간동안 계속 야단맞았어.

--------

> 3월 30일

지금 현재 머신러닝같은건 다 패키지화되있어요
서포트 베타머신
뉴럴네트웍
중요한건 속도야
그걸 누가하느냐
우리가 하는거야
말만 버즈홀
기초가 되는 기술이 쌓여있어야 할수있다고
근데 그걸 참 모르는거야
빅데이터 별거있어요 이름 그냥 가져다 붙인거야

미국에서 왓슨연구소 그런데는 맨날 속도만 신경쓰고있는데 우리는 분석하는법이나
배우고있어요. 아예 접근부터가 글러먹은거야. 이게 변하지못하면 우리는 남
따라갈수밖에 없어. 맨날 미국 뒤꽁무니나 쫓게되어있는거야.

새로운걸 해야돼. 새로운거 뭐 SnuCL 이런걸 해야지 (?) 게임회사 우리나라에 만개가
넘어. 거기에 또 들어가는놈들은 바보야. 새로워야돼

분산시스템은 코어 스크레인이죠. 근데 우리는 하나의 시스템 안에서 멀티코어를
쓰는거야. 하둡같은거 실제로 만든게 분산시스템을 위해서 만들었어요. 이게
스트리밍도 안돼고 그냥 Batch로 하도록 하둡을 만들어놨는데, 하둡을 어떻게 하면
슈퍼컴퓨터에서 빠르게 Real time processing 할 수있게 하느냐 이런거에요.

난 그런게 싫어
이론화한놈들이 이름 신기한거 다 붙여놨는데
BSB모델 RAM 모델
그거다 별것도 아닌건데 그거 이름붙여가지고 튜링어워드 받았다고
내가 진짜 우스워서
그사람 멀티코어에 발표한 논문 보면 쓰레기야 쓰레기
아무것도 모르는놈이말야
중요한건 옛날에 뭘 했느냐가 아니라
지금 뭘 하고있느냐야
내가 왜 이런소리를 하냐
시간이 좀 지나면 느낄수 있어요
나악우우우웅

가상 메모리
--------
가상 메모리 자체는 소프트웨어에서 하는거에요. 하드웨어가 아니라. OS가 해주죠.
가상메모리 구현도 하드웨어로 할수 있을지도 몰라. 구현을 하드웨어로 하는가
소프트웨어로 하는가는 장단점이 있지.

### Virtual Memory
운영체제에 의한, 메모리의 추상화

프로세스가 모에요. 실행되고있는 프로그램을 관리하기위해 운영체제가 프로세스라고
이름을 붙여준거야. PCD라고 해서 프로세스에 대한 정보가 한 자료구조 안에
들어있지.

주소 공간이라는 용어를 쓰는데, 프로세스가 가진 메모리의 범위를 주소공간이라고
그래요. 두 프로세스를 실행시킨다고 쳐봐. 주소공간이 같아요 틀려요? 달라요.
프로세스마다 다른 주소공간을 준단말야. 이게 Virtual Memory의 역할이야.

또 하나의 역할? 실제로 갖고있는 메모리보다 더 많은 메모리를 쓸 수 있게 함.

```
CPU -> 캐쉬 -> 버추얼 메모리 -> 캐쉬 -> 메인메모리 -> 보조저장소
```

어쨌든간에 우리가 소프트웨어로 이걸 한다그랬는데, 얘가 하는 역할이 무엇이냐.

### MMU and Pages
Memory management unit

가상메모리의 어디가 피지컬메모리의 어디에 해당하느냐, 이걸 운영체제가 해줘요. 북
키핑을 해줘야겠지? 이걸 페이지 테이블에 해요.

메모리가 32비트라고 치면, 앞의 12비트는 페이지 안에서의 offset이라고 치고 나머지
20비트를 page라고 봐도 된다고.

우리가 왜 캐쉬를 사용해요. 캐쉬를 사용하는 이유가 뭐야. 코스트를 줄이면서
빠른속도로 메모리를 액세스하기위해. 근데 주소가 올때마다 페이지테이블 룩어블
한다고 쳐봐. 이게 좋아요 나빠요? 나쁘지. 그리고 페이지 테이블 룩업할때 또 연산을
해야돼. 이 테이블이 어디에 해당하는지. 그럼 좋아 싫어? 싫지. 그래서 이걸
하드웨어로 계산하기위해 MMU라는걸 둬. 이게 거의 대부분의 CPU에 들어가있어.

### Page Tables
페이지테이블을 기록하는데에 뭐가 필요할까. 이게 실제 RAM에 올라가있는지, 이게
피지컬 메모리의 어느영역에 매핑되는지 이런 정보를 적어야겠지.

페이징, 디맨드 페이징, 스와핑

### Address Translation
버추얼 페이지의 세 타입

* Unallocated
* Cached
* Uncached

### Page Hit/Fault
버추얼메모리가 가서 MMU한테 갔어

커널이 뭐야
커널의 데피니션이 뭐야
오에스 들었다매
커널이 뭐야
잘한다
큰일이다 큰일
가장 기본적인걸 모르니까
모르는거야 어렴풋이 알겠는데 대답을 못하는거야
커널이 뭐야
커널이라는거는
OS에서 항상 메모리에 상주를 하면서 안쫓겨나가요
항상 OS에 상주해있는부분을 커널이라고 정의해
(스왑아웃 되지 않는부분)

### Page Replacement Policies
* LRU
* FIFO
* Second chance
* Clock
  * 이 페이지가 한번이라도 참조 되었나 안되었나를 저장함
    * 페이지가 처음 로딩되었을경우 `R=0`
    * 페이지가 레퍼런스 되었었을경우 `R=1`
  * 그리고 페이지들의 서큘러 리스트를 메모리에 저장함
    * 리스트를 순회하면서 `R=0`인애들을 스왑아웃해버림

### Translation Lookaside Buffer (TLB)
컴구 들은사람은 이거 알거야. 이것도 MMU 안에 들어있는건데

```
<@김젼> TLB 뭔지 모르겠당
<@김젼> 호에에에
<@sgm> TLB 모름?
<@sgm> 시프에서도 했는데
<@김젼> 지각해서
<@김젼> ._.
<@p> translation lookaside buffer
<@sgm> virtual memory address를 physical address로 바꿔야 되는데
<@p> 가상주소-물리주소 변환하는거
<@p> 캐시
<@김젼> 오홍
<@sgm> 이 정보가 메모리에 있어버리면
<@sgm> 저것도 메모리 보게 되니까
<@sgm> 오버헤드가 큼
<@김젼> 그래서 따로 캐쉬를 두는건가
<@sgm> 그래서 따로 캐시 둔 거
<@sgm> ㅇㅇ
<@김젼> 오홍
```

Small, virtually addressed cache where each line holds a block consisting of a
single PTE. 보통 Full associate cache로 만듬. 보통 메모리 실행할때 시퀀셜로
접근했던 메모리를 또 접근하니까 로컬리티가 높아서.

Micro-TLB

리눅스에서 하나의 페이지는 4kb에요.
페이지 크기가 크면좋겠어 작으면 좋겠어?
이게 장단점이 있어
페이지 크기가 작으면 테이블 룩업을 자주해야돼
TLB 미스가 자주뜨겠지?
페이지 크기가 크면 어때
2메가라고 쳐보자
2메가 페이지면 페이지폴트가 한번만 나면 좋은데
2kb면 페이지폴트가 512번 일어나야지
리눅스를 보면 휴즈 페이지라 그래서
페이지 크기를 크게 줄 수 있어
이러면 페이지 폴트 나는 퍼포먼스가 어떨까
꼴랑 2% ~ 3% 밖에 성능이 안좋아져
실제 실험 안해봤지 여러분?
이건 해봐야 아는거냐
큰 페이지가 좋은지 작은 페이지가 좋은지
시퀀셜하게 메모리 쭈욱 접근할때엔 큰 페이지가 좋겠지
근데 TLB랑 microTLB 성능이 워낙 좋으니까
성능이득이 별로 없는거야
근데 미디어쪽은 보통 메모리액세스가 시퀀셜해서
큰 페이지를 쓰기도 해요

리눅스같은경우에
버추얼메모리 끄는 옵션이 있어
MMU가 1:1 매핑을 하도록 바뀌어
보통 미사일이나 비행기에서 이런거를 써
왜 이런걸 쓰느냐
얘네들은 계산 시간이 들쭉날쭉하면 안돼
비행기나 미사일이 날아가는동안
미세조정을 하는데
이 계산을 하면 정확히 몇초후에 결과가 돌아와야한다
이 계산시간을 고려해서 조정을 한단말야

### Caches and Virtual Memory
캐시가 버추얼메모리를 쓸것이냐 피지컬 메모리를 쓸것이냐

Virtually addressed cache: faster, 하지만 보안 이슈가 있음. OS가 컨텍스트
스위치할때 캐쉬를 비워줘야됨. 컨텍스트가 무엇이냐. 이 프로세스가 돌다가 나중에
다시 돌기위해 Save해야하는 정보들 (PC, 레지스터, 스택, ...)

Physically addressed cache: 물리메모리를 캐싱함. Slower but no OS intervention

1.  Virtually indexed, virtually tagged
    * 캐시 미스가 났을때만 주소공간 변환이 일어남
    * TLB가 critial path에 있지 않음
1.  Virtually indexed, physically tagged
    * 보통 실제로 쓰임
    * 피지컬 인덱스 캐쉬보다 빠르고, 버추얼만으로 한건 프로세스간 구분이
      안되는데 이건 됨
    * TLB가 critial path에 있지 않음
    * ARM에선 보통 이걸 씀
1.  Physically indexed, virtually tagged
    * NEVER USED
    * No OS intervention for cache management
    * TLB is in the critical path
    * TLB 트랜슬레이션 한 다음에 캐쉬 액세스를 하기때문에 퍼포먼스가 느려짐.
      아무도 안쓰는 방법
1.  Physically indexed, physically tagged
    * TLB is in the critial path
    * No OS intervention for cache management

병렬성
--------
슈퍼컴퓨터를 ARM으로 만드는걸 내가 밀어놨는데. 펀딩이 될지 안될지 모르겠어.
대만같은 회사에선 요만한 공간에 프로세서 수십개 박아넣는 마이크로서버가 잘
되고있어. 우리나라에는 ARM쪽 생태계가 좀 잘 되어있는데 이게 펀딩이 아니면
우리나라는 운이 없는거야. 그나마 우리나라에서 잘되어있는게 ARM쪽인데
여기에서마저도 선전할 기회를 놓치면 우리나라가 운이 안좋은거야.

### Types of Parallelism
* ILP
* Task parallelism
* Data parallelism

### Task Parallelism
Banquet을 준비하는데, 네개 전채요리를 준비하는데, 서로 다른 종류의 job을 서로
네명이 나눠서 넷이 각각 준비하는거야.

요게 태스크 패러렐리즘

동시에 다른종류의 job을 실행하는것. 이게 제일 이상적인 패러렐리즘이야.
오버헤드가 아몰타이즈드 된거야. 그러나 실제로 찾아보면 이런것이 적용되는
어플리케이션이 별로 많지 않아.

### Data Parallelism
이건 가장 성공적이었고, 자동으로 할 수도 있는것

Loop-level parallelism이라고도 함. 루프를 도는데 각 이터레이션간에 디펜던스가
없으면 이걸 동시에 할 수도 있지

```c
for (i = 0; i < N; ++i) {
  c[i] = a[i] + b[i];
}
```

OpenMP같은건 디펜던스가 없으면 앞에 뭐 하나 붙이면 알아서 병렬화돼. pthread는
어때? 손으로 스레드를 만들어야하지.

예전에 C++이 C로 변환된다음 어셈블리가 나갔잖아? 그런거처럼 OpenMP도 pthread로
변환된다음 가던 시절이 있었어

### SIMD
A single program counter

CPU에서의 SIMD는 벡터 오퍼레이션이라고 하는데, GPU의 SIMD랑 좀 다름

### SPMD
Single Program Multiple Data

똑같은 프로그램을 여러 데이터에 다양하게 적용시키는것. 근데 이걸 하려면
프로그램을 켤때 내가 어느부분을 계산해야하는지를 계산해야하지? 이게 바로
패럴라이제이션 오버헤드

MIMD는 굉장히 고리타분한 용어이니 쓰지 않겠다. 이런 용어가 있다는것만 알아둬

SPMD라는 용어는 언제 썼을까? 60년대 말에 IBM에서 처음 썼어. 난 이걸 항상
레퍼런스하는데, 다른사람들은 이 용어는 알면서 이 논문도 레퍼런스 안하고 이
용어가 어디서 생겼는지도 몰라.

소프트웨어 파이프라이닝. HP에 있던 밥 라우라는 사람이 만든게 하나가 있고, 스태틱
싱글 어사인먼트 폼이라고 해서, 프로그램 트랜스포메이션이라고 하는게 있는데 이게
컴파일러계에서 아주 중요한 변화거든? 근데 사람들은 이 두 엄청나게 큰 변화가 누가
만든건지 몰라. 소프트웨어 파이프라이닝은 아는데 다 스탠포드 교수가 만든줄 알고,
프로그램 트랜스포메이션 논문을 보면 저자가 네명인데 정작 중요한사람은 빠져있어.
그래서 이사람들 다 뭐하느냐? (누군가 치킨집이라고 말함) (수업 마비) 실제로
치킨집 차린건 아니고 비슷한건데, 농사짓고있어.

--------

멀티스레디드 아키텍처, 캐시 코히어런스, GPU 아키텍처
--------

Control flow = 실행 순서를 바꾼다. 브랜치 넘버

인스트럭션 사이클 = Fetch Decode Execution Writeback

OS가 하나다, 와 OS 인스턴스가 하나다라는 뜻은 달라

```
<@김젼> 그건 페치 디코드 익스큐션 인스턴스가 여러개다,
<@김젼> 프로그램 카운터가 여러개다
<@김젼> 멀티코어 수업에서
<@김젼> 처음으로 멀티코어를 만져서 그런지
<@김젼> 이렇게 한 슬라이드 오래하는거 처음이다
<@김젼> 수퍼스칼라 프로세서가 뭐하는거에요
<@p> 히익
<@김젼> 여러개의 펑셔널 유닛을 둬서 ILP를 둬서 수행을 여러개를 하는거지
<@unused> HINSTANCE hInstance;
<@김젼> 근데 ILP를 하더라도 인스트럭션이 하나의 스레드에서만 오기때문에
<@김젼> 하나의 스레드면 평균 ILP가 3이라고 했지
<@unused> typedef HINSTANCE HMODULE;
<@김젼> 펑션 유닛이 4개 5개 있어도 다 논단말야
<@p> 노잼..
<@김젼> 노니까 여러개의 스레드를 동시에 돌리면서 여러개의 스레드에서
인스트럭션을 가져오자는거야
<@김젼> 이게 기본이야
<@김젼> 멀티스레디드 맨 처음 제시한사람이
<@김젼> 조얄 해머 (??) 이름 뭐지
<@김젼> 유니버설 오브 워싱턴 박사과정이랑 쓴건데
<@김젼> 크레딧은 지도교수가 받았는데
<@김젼> 지도교수는 아무것도 한게없어
<@김젼> 사람들은 다 수잔 누구(지도교수)가 한줄 알아
<@김젼> 조얄 해머(??)는 인더스트리에 있던사람이야
<@김젼> 딘 트루센이라는 친구에요 이친구가 나랑 커리어를 같이 시적하고 샌델(?)
교수인데
<@김젼> 그사람이 이거 논문을 사이멀테이너스 멀티스레드라고 발표하고
<@김젼> IBM 파워피씨에 처음 적용하고
<@김젼> 인텔에서 이걸 가짜로 베껴서 하이퍼스레딩이라고 발표하고
<@김젼> 파워피씨에 비해 아주 안좋았는데 이제 좋아졌지
```

### Thread-level Parallelism
여러 실행 스레드를 사용해, 명시적으로 병렬 실행을 함.

### Issue Width of Superscalar Processors
동시에 이슈할 수 있는 갯수

### Superscalar Processors
하드웨어적으로는 아무것도 할게없고 소프트웨어적으로 컨텍스트 스위칭하면서
도는거. 모든 명령어가 항상 동시에 최대로 병렬화되어 이슈될 수 없지.

* Vertical waste (completely empty)
* Horizontal waste (partially filled)

### Vertical Multithreading
Vertical 하게 빈 공간에 다른 스레드를 넣자. 근데 아직도 Horizontal waste는 있음

* 스케줄링
  * fine-grained multithreading: 사이클 단위로 컨텍스트 스위칭
  * Coarse-grained multithreading: 컨텍스트 스위치하거나 캐시미스나거나 해서
      시간낭비되는동안 다른거 실행하기

### Simultaneous Multithreading (SMT)
인텔에서 하이퍼스레딩이라고 부르는것.

스레드가 하이퍼스레딩하는건 OS는 못봐요. OS는 로지컬스레드만 보는거고, 피지컬
스레드는 못봐. 만약에 코어 하나가 하이퍼스레드를 4개 한다 치면, OS는 코어가 4개
있는걸로밖에 안보여.

하이퍼스레딩의 단점.

* 데이터레벨 페러렐리즘을 할경우, 비슷한 명령어를 계속 실행할텐데, 이미 포화된
  ILP가 더 포화될 수 없어서 별 도움이 안됨. 그래서 실제로 인텔 하이퍼스레딩이
  성능이 별로 안좋음
* 캐쉬 로컬리티가 떨어져서 안좋음

```
특허
존나 쓸떼없어
우리나라 연구소에서 누구네보다 특허 많이냈다
백날 특허냈다고 해도 아무 쓰잘떼기없어
내가 정부에서 9년짜리 프로젝트를 하는데
3년마다 맨날 듣는소리가 왜 특허가 없냐고 그래
그럼 난 가서
국민들 세금이 아까워서 특허 못내겠습니다 그래
난 오픈소스로 푸는게 훨씬 가치있는거라고 생각한다그랬어
그래서 나중에 심사위원이 부르더니
그거 대드는거라고 그랬어
내가보기엔 특허라는건 없어져야해
나도 어쩔수없이 특허를 내놓고 이용을 하지만
요즘 특허내는거 보면 다 말도안되는거밖에 없어
어떻게 아이콘 가장자리 동그란거에 특허가 걸려있어
그레이엄 벨
저녁먹고 특허청가느라 2시간 늦어서 특허를 못얻었어
특허 낸다고 중국에서 짝퉁 못만드는줄아나
신문에서 특허 많이 낸다고 자랑하는데 그거 하나도 국익에 도움이 안돼
MIT는 바보냐 특허 하나도 안내는데
그거 변리사 좋은일 시켜준다고 안하는거야 돈아까워서
```

내가 왜 자꾸 용어를갔다가 중요하게 여기냐면, 여러분들한테 아키텍처 레퍼런스
메뉴얼 읽으라고 시키면 읽기 힘들어. 그것도 못읽으면서 컴공 졸업하면 웃기는거지.
뭐했냐 이거야.

### Homogeneous Multicores
캐쉬, 펑셔널 유닛, 프로세서 스테이트

* 셰어드 캐쉬
* Multiple processor state (하이퍼스레딩)

인텔같은애들은 자기네 시뮬레이터가 있어. 그건 오픈을 안해요. 자기네 프로세서
디자인할떄 쓰는거라

Cache Coherence Problem
--------
캐쉬 일관성이라고 흔히 번역되지만, 메모리 일관성(메모리 컨시스턴시)랑 용어가
겹쳐. 근데 저 둘은 전혀 다른 문제임

* 우린 캐쉬가 항상 최신값을 리턴하기를 기대함
* 근데 멀티코어에선 한 캐쉬에 뭘 쓰면 반대쪽 캐쉬엔 그게 반영이 안됨

유니프로세서서 시절에도 이 문제는 있었음. 다이렉트 메모리 액세스는 뭐에요. RAM을
안거지고 바로 I/O로 가는거지.

해결책

* 작업 하기 전, 후 매번 캐쉬를 비움
* DMA가 일어나는 영역 자체를 uncacheable로 만듬

캐쉬 코히어런스 문제 해결책

* Invalidate based protocol: 공유되는 캐쉬 값을 쓸때, 캐쉬 라인에서 아예 그
    캐쉬를 지워버림. 그럼 다른 캐쉬에서 그 값에 접근하게될때엔 캐시미스가 남
* Update based protocol: 공유되는 캐쉬 값을 쓸때, 다른 코어들에게 업데이트된
    캐쉬 값을 업데이트시켜줌.

각자 장단점이 있음.

소프트웨어로 할수도 있고 하드웨어로 할수도 있음

* 소프트웨어기반
  * 컴파일러/런타임
  * 하드웨어 지원
  * 근데 하드웨어에 대한 완벽한 정보가 필요함 (얼라이어싱, 페러렐리즘, 등..)

이걸 굳이 스태틱하게 하려는 놈들이 있는데 난 왜 그렇게 하려는지 이해가 안가.

하드웨어로 해도 북키핑 하려고 할라그러면 이것도 코스트가 많이 들어가. 그러니까
그냥 아무것도 하지말고, 소프트웨어에 맡기고 런타임에 해결하자.

#### 여러분은 세계에서 다섯손가락 안에 들어가는 메모리 컨시스턴시의 권위자의 강연을 듣고있습니다
왜웃어 임마
너 죽을라고
캐쉬 코히어런스는 내가 권위자가 아냐

Modify, share, invalidate. MSI, MESI(인텔), MOESI(암드) 등 여러 캐쉬 코히어런스
프로토콜이 있다. 여러분은 신경 안써도 돼요 하드웨어가 알아서 다 해줘

* Coherence misses
  * Invalidate할때 메모리에서 가져오는거

* Shared cache를 쓰면 이 문제가 사라짐

### Snooping

캐쉬 컨트롤러들이 캐쉬라인을 훔쳐보고(Snoop), 인밸리데이트하거나 바뀐 값을 다른
캐쉬들에 업데이트시켜주는 일련의 과정을 스누핑이라고 부름

### Coherence and Write-through Caches
Write-through 캐쉬에도 다른 코히어런스 문제가 있음

```
동시에 쓴다
동시에 쓴다 하는데
동시가 뭔지 알어요?
네슬 램버트
시퀀셜 컨시스턴시
얘네 논문쓸때
레퍼런스에
클락의 동시성 논문에
특수상대성 논문 들어있어
```

### False Sharing
한 캐쉬에서 RAM에 write-through할때, 그 메모리를 잡고있는 캐쉬를 전부
invalidate해야됨. 그래서 이건 진정한 sharing이 아님. 이거떔에 퍼포먼스
데그리데이션이 많음.

Update based protocol에선 이런일이 없음. 근데 Invalidate based protocol에서는
일어나지.

C volatile은 실제 메모리장벽을 전혀 안쌓아줌. 내 박사논문이 이거야

--------

> 4월 6일

GPU 아키텍처
--------
GPU 아키텍처들은 밑에단 공개가 잘 안되어있어. 이유가 뭘까? 이유가 자주 바뀌기
떄문이 맞아. 근데 왜 이걸 공개를 안할까? 밑에 레벨을 공개를 해놓으면 그걸
이용해서 소프트웨어를 만들어버려. 그럼 다음 아키텍처로 넘어가면 그게 돌아가?
안돌아가. 그래서 굉장히 하이레벨로 개발하도록 강제를 하는거야.

그래서 이쪽 알아내는게 굉장히 힘들어요. 캐쉬 어떻게되어있고 이런거 다 역공학으로
알아내야돼. 그래서 세계 그 어느 누구보다도 우리 학생들이 더 잘 알고있어. 이게
경험과 피나는 노력을 통해서 아는거야. 그런걸 아는게 왜 중요할거같애. 시스템을
알아야 좋은 소프트웨어를 만들 수 있어서 그래.

지금 삼성에서도 모바일용 GPU 만들고있죠. 근데 디자인을 미국 연구소에서
주도하고있으니까 답답한거야. 우리 학생들한테 맡기면 6개월정도면 만들텐데.

너네도 다 똑같애. 다 할 수 있어. 자기의 능력을 의심하지마. 다 우리가 똑같이 할
수 있는거에요.

### Rendering
렌더링이 뭐에요? "Process of generating an image from a 3D model"

2차원에서, 모든 폴리곤은 전부 삼각형으로 나눌수 있죠. 이렇게 삼각형으로 잘게
쪼개 모델링해서 처리를 하는거야. 고게 3D 모델링이고 고걸로 이미지를 만드는게
렌더링

### Rendering pipeline
1.  Vertex processing
1.  Geometry processing
1.  Rasterization
1.  Pixel processing
1.  Output merging

하드웨어로 만들어버리면 속도는 빠른데 뭐가 안좋아? 범용성이 떨어지지

### Shaders
GPU를 그래픽스만 처리할 수 있는 기계로 만들지말고, 범용 기계장치로 만들자. 그
GPU에 올리는 프로그램을 셰이더라고 부르고, 이게 돌아가는 코어를 셰이더 코어라고
부른다.

### General purpose CPU
보통 CPU는 실제 엑스큐션에 필요한 레지스터보다 그 외의 레지스터가 훨~ 씬 많음.
성능 높이려고.

### Shader cores
* Very simple programmable
* No architecture components that make a single instruction stream run fast
* Logical graphics pipeline
  * Vertex shader, Geometry shader, Fragment shader, etc

### GPU 아키텍처
아키텍처를 디자인할때엔 뭐가 중요하다고? 실제 어플리케이션을 봐야돼. 어떻게
쓰일지. GPU는 코어간의 디펜던스가 없어. 그리고 삼각형이랑 픽셀이 수백만개야.

"Massivly parallel processing"

```
<@sg126> 파이프라이닝도 하고 스케쥴링도 함
<@sg126> 근데 파이프라이닝도 하고 스케쥴링도 하는거 맞음
<@김젼> 그렇군
<@sg126> 내가 스냅드래곤 개발자한테 직접 들음
<@김젼> 어떤 스케쥴링을 하지?
<@sg126> 그림을 쪼개서 타일을 만들고
<@sg126> 타일별로 어떤 타일을 어느 타이밍에 어떤 명령어를 컨슘할지
<@sg126> 내부적으로 스케쥴링함
<@sg126> 그래서 메모리 타이트한 상황에서 잘못쓰면 메모리할당을 못해서 그림을 못 그리는데
<@sg126> 그게 타일별로 나타남
<@김젼> 그러쿤
<@sg126> 타일 크기는 드라이버제작자가 설정해서 줬는데 어쨌든 파워오브2로 줬던거 같고
```

### Exploting Massive Parallelism
각 픽셀마다 같은 오퍼레이션만 적용한다.

SIMT: Single Instruction Multiple Thread

* Single Fetch/Decode logic
* Multiple ALU & Context
* shared context data

인스트럭션 하나를 카피해서 여럿한테 돌림.

### Executing Branches
한 브랜치 실행하는동안 다른 브랜치는 그냥 멈춰버림.

* Conditional execution in a warp
* Hardware automatically handles divergence

### Hardware Context Switch
* To avoid stalls caused by high latency operations
* A single SM can run more than one warp

L1 캐쉬 액세스하는데 서너사이클 걸림. 근데 메모리 액세스하는데엔 30사이클
넘게걸림. 이런걸 High latency operation 이라고 부르면 됨.

### Multiple Streaming Multiprocessors

### 전반적인 구조
스칼라 프로세서, 로드 스토어 유닛이 아주 많다. 이것들 네개당 SFU(스페셜 펑셔널
유닛)이 드문드문있고, 얘네들이 모두 하나의 L1 캐쉬, 셰어드 메모리를 공유하고 그
밖에 L2 캐쉬 있고 글로벌 메모리가 있음.

### GPU Summary
* Data parallelism
* Hardware context switch to tolerate high latencies

메모리 컨시스턴시
--------
캐시 코히어런스와의 차이점.

컴파일러는 inter-thread 디펜던시를 따지지 않음. 이게 문제임. 컴파일러와
아키텍처가 OoE 하면서 리오더링을 할 수 있고, 이게 네트워크로 연결된 롱 레이턴시
멀티프로세스 시스템에서 실행되면 메모리 레이턴스때문에 메모리에 도달하는 순서가
바뀔 수 있음. 여러가지 이유때문에 리오더링이 발생할 수 있음.

어떻게 리오더링이 안되게 해야할까? 리오더링이 발생하면 안되는 지점을 명시적으로
지정해햐아한다.

캐쉬 코히어런스는 하나의 메모리 로케이션을 액세스하는 문제임. 근데 메모리
컨시스턴시는 메모리를 액세스하는 순서의 문제임.

### Memory consistency models
상대적으로 메모리 액세스가 일어나는 순서 자체가 어떤 순서로 일어나야 되느냐 에
대한 제약사항을 말함.

일단 셰어드 메모리, 싱글 프로세서를 가정하고 배우자.

한 업데이트에 대한 메모리가 언제 다른 프로세서에게 보일까?

1.  프로그래머에게 있어서 프로그래밍을 얼마나 공격적으로 할 수 있는가의 기준이 됨.
1.  얼마나 많은 액세스가 리오더 될 수 있느냐를 결정할 수 있는 기준이 된다.

대표적으로 네가지 메모리 컨시스턴시 모델이 있고, 이걸 쪼금씩 쪼끔씩 고쳐서
쓰는거임.

* Sequential consistency (Correctness criteria)
* Relaxed memory consistency models
  * Processor consistenty
  * Weak ordering
  * Release consistency
  * ...

복잡할수록 틀린거임.

### Sequential Consistency
멀티스레디드 프로그램 P의 실행결과는, P를 일렬로 늘여세워서 만든 싱글스레드
프로그램의 실행결과와 같아야함.

A total order between operations is defined (atomic operations).

컨시스턴시에 있어 제일 강력한 컨스트레인트.

### Program Order
Order in which operations appear in source code

* 어셈블리 코드로의, 소스코드의 자명한 변환
* At most one memory operation per instruction

하지만 컴파일러에 최적화될 수 있기때문에, 실제로 실행되는 순서와는 다름.

### Reasoning Based on SC

### SC Violation
내가 업데이트한것이 업데이트가 느리게되어서 생기는 문제.

### Relaxed Memory Consistency Models
인스트럭션 사이에 Fence Instruction을 집어넣음. 그 펜스 인스트럭션 범위를
넘어서는 리오더링이 못일어나게함.

### Performed with respect to ...

### Processor Consistency (PC)
Write buffer가 뭐게. write를 시퀀셜하게 죽 하는데 하나씩 메모리에 가면 시간이
무지 오래걸리지? 그렇게 하지 말고 write buffer에 모았다가 한번에 보내면 메모리
트랜잭션 하나로 여러 write를 할 수 있지. 근데 이 write buffer를 하려면 프로세스
컨시스턴시가 필요해.

write 버퍼를 하드웨어에 넣으려다보니 만들어진거임.

근데 이거 거의 안쓰여.

Read is allowd to perform with respect to any other processor, all previous read
must be performed

이게 무슨뜻이냐면

> read -> read (다른 메모리 로케이션 접근할때)

가 지켜져야한다는 뜻임.

Before a write is allowed to perform with respect to any other processor all
prvious accesses must be performed

> read -> write
> write -> write
> ~~write -> read~~ (relaxed)

라는 뜻임

86~88년에 쓰임.

##### Relaxing write -> read order
Processor consistent 하지만 not sequentiall consistent 할 수 있는 상황이 있음.

### Weak Ordering
Relax all program order. 하지만 Synchronization operation들 사이의 시퀀셜
컨시스턴시는 지켜줘야하고, 싱크로나이제이션 오퍼레이션 전후로는 모든 메모리
I/O가 끝나야함.

이러한 특징때문에, 프로세서 하나에선 싱크 오퍼레이션은 항상 하나에만 일어남.

IBM PowerPC가 위크 오더링을 따름.

### Release Consistency
Releax all program orders, but not w.r.t. sync operations

Two separate synchronization operations

* Acquire: A read operation such as lock
* Release: A write operation such as unlock

Acquire가 나오고 뒤에 read, write가 나오면 어콰이어 앞으로 못감.

Release가 나오고 앞에 read, write가 나오면 릴리즈 뒤로 못감.

Acquire, release 싱크 오퍼레이션들끼리는 모두 시퀀셜리 컨시스턴스 (혹은 프로세서
컨시스턴트) 근데 프로세서 컨시스턴시보다 시퀀셜 컨시스턴시가 더 나옴.

91년도에 나온거임. x86에서 쓰는거임.

메모리 컨시스턴시 모델이 왜나왔어. 리오더링을 하면 우리가 원하는 결과가
안나오기때문에 그런거지.

--------

> 4월 13일

고성능 컴퓨팅 시스템
--------

### SMP
Symmetric Multiprocessor

* 크로스바 스위치
  * M개의 입력을 N개의 출력에 연결하는 스위치
  * 스위치가 MxN 매트릭스의 형태로 배열됨

North bridge는 보통 빠른애들이 들어있는곳, 하드디스크같은 I/O에 관련된 애들이
South bridge에 들어있음. 근데 요즘은 North bridge는 그냥 CPU 안에 넣음

요즘 PC는 더 나은 연결기술로 프로세서와 메인 메모리를 연결함

* HyperTransport
* QuickPath
* Interconnect

* NUMA
  * 프로세서 위치에 따라 메모리 액세스 속도가 다름
* UMA
  * 같음

1.  Private 캐쉬 갖고있음
1.  프로세스가 독립적인 프로그램 실행 가능
1.  멀티스레드일경우, 코어당 스레드 하나씩 줄 수 있음

### 클러스터
돈없으면 1G 이더넷 쓰고 돈 있으면 10G, 돈 더있으면 인피니맨드, 4TG, 이런거 쓰지

각 노드를 인터커넥션 네트워크로 붙임.

### 인터커넥션 네트워크
이더냇

* 1기가빗 이더넷
* 10기가빗
* 40기가빗
* 100기가빗 (인피티밴드)

인피니밴드. 레인당 전송속도로 아래로 나눔

* SDR
* DDR
* QDR
* FDR
* EDR

천둥은 QDR 쓰고있어. 애플리케이션 종류에 따라 FDR이랑 QDR이 큰 차이 안날 수
있어.

### 클러스터의 장점
*   한 노드에 장애가 생겼을때, 다른 노드가 작업을 이어받아 서비스가 계속될 수
    있으므로 가용성이 좋음
*   단일컴퓨터보다 비용대비 성능과 안정성이 좋음

### Top500에서 클러스터의 추세
(피피티 참고)

2005년까지 375개로 늘다가, 2010년에 이르러선 500개 이상으로 발전 안함

### 이종 클러스터
범용 CPU와 GPU나, 인텔 제온파이등의 하드웨어 가속기를 붙인것.

같은 비용으로 고성능 및 저전력소모를 달성하기 쉬움

### MPP
* Massively Parallel Processors
* 아주 많은 수의 프로세서를 사용하여 한 개의 프로그램을 병렬적으로 처리하는 과정

MPP와 클러스터의 차이점은? 클러스터는 각 노드는 독립적인 컴퓨터로 작동함

나는 MPP와 클러스터를 별로 구분하지 않는데, 보통 MPP라고 하면 특정한 회사에서
MPP를 위해 특별히 맞춤형으로 설계하고 개발한 독점적인 권리가 있는 (proprietary)
시스템을 이야기함

병렬화 패턴
--------

```
<@김젼> 제일 행복한 시절이
<@김젼> 군대가있었을떄였어
<@김젼> 밥먹여줘
<@김젼> 운동시켜줘
<@김젼> 군대 괜찮아
<@김젼> 그리고 군대갔다온놈들이 정신을 잘차려
<@김젼> 제일 저 개차반이
<@김젼> 카이스트에서 학부..
<@김젼> 아 이런말하면 안된다
<@김젼> 그러니까 사람 사는 세상을 겪어보는게 제일 중요한거야
<@김젼> 세상이 얼마나 무섭다는걸 알고
<@김젼> 세상에서 살아남으려면 어떻게 해야되는지
<@김젼> 살아보면 별로 잔인한 세상은 아닌데
<@갤럭갤럭> 저게 무슨 소리야
<@김젼> 생각하고 다를떄도 많고
<@갤럭갤럭> .....
<@김젼> 군대를 갔다오면 세상이 많이 달라보여요
<@김젼> 군대갔다온 학생들이 성실해요
<@김젼> 삶에 계기가 있어야돼
<@p> 역시 꼰대(?)
<@김젼> 요즘 옛날처럼 가서 뚜들겨 맞고 안그러잖아
<@김젼> 내가 이러니까 군대 가고싶지?
<@김젼> 너 병특아니냐? (유재성 가리키며)
<@p> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> 병특이 군대냐
<@sg126> 이재진교수님?
<@김젼> 방위정도는 되어야
```

```
<@김젼> 대학원 커트라인이 올라가고있어요
<@김젼> 매년 10점씩 올라가고있어
<@김젼> 영어도 텝스 830/990 받아야돼
<@김젼> 그게 어렵냐
<@p> ㅠㅠ
<@sg126> 교수님 텝스점수 물어봐줘
<@김젼> (재성이형) 교수님이 한번 직접 해보시면 어떠신가요
<@김젼> 내기할까?
<@sg126> ㅋㅋㅋㅋㅋ
<@김젼> 그게 안해서 그런거야 안해서
<@p> 쉬웠으면 조켔다..
<@김젼> 고시촌 가봐
<@kcm1700^멘붕> 어그로 끌기 연습하시나
<@김젼> 츄리닝에 슬리퍼 찍찍 끌고 편의점에서 맥주 마시는놈들 많잖아
<@김젼> 근데 서울대 들어올 정신으로 딱 1년 2년 하면 못할일 없어
<@sg126> 나도 이번 수업은 뭘 모르는 학부생들의 헛소리를 들으러 왔다
<@김젼> 2년만 정신차리고 하면 못할게 없잖아
<@김젼> 너네 시험은 잘보잖아
<@김젼> 불만있어
<@김젼> 사실이잖아 사실
<@김젼> 타고난거에요 다
<@김젼> 공부잘하는것도 타고나는거고
<@김젼> 외모도 타고난거야
<@김젼> 부들부들
<@sg126> 근데 딱 2년 하면 다들 잘할것 같음
<@wook> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@wook> 유재성ㅋㅋ
<@sg126> 근데 2년 할 시간이 안 나는거지
<@김젼> 여러분들도 타고났기때문에 공부하려고 더 노력할거 없단말야
<@김젼> 여러분들은 공부 잘하는걸로 타고났어요
<@wook> 부들부들
<@김젼> 84학번중에 공일오비 알아?
<@김젼> (무슨 가수이야기인거같다)
<@김젼> 걔 잘생겨서 가수하다가 그만두고 미국으로 박사학위하러갔어
<@김젼> 근데 여러분들은 희망이 없다
<@김젼> 그러니 공부만해
<@p> 015B
<@김젼> 그러고 보면
<@김젼> 별로 좋은 세상이 아니다 그지
<@김젼> 공부만 해야된다 안그래
<@김젼> 사는 방법은 여러가지가 있어요
<@김젼> 재밋어
<@김젼> 여러가지 재밌는거 많으니까
<@김젼> 무서워하지말고 진로를 바꿔
<@김젼> 근데 구관이 명관이라고
<@김젼> 원래 하던게 좋을때가 많아
<@sg126> 교수님들의 공통적인 의견인것 같음
<@김젼> 진보적 조언과 보수적 조언을 동시에 하신다
<@sg126> 너희는 공부는 타고났는데 그외는 아니니까 포기해
<@p> 모순이네
<@김젼> 역시 이재진교수님
<@김젼> 내가 요즘
<@sg126> 공부나해
<@김젼> 일본 미드를 보는데 말야
<@김젼> (JC) 일본 미드가 아니라 일드요
<@김젼> 내가 요즘 일드를 보는데 말야
<@김젼> 거기 의사가 참 많이 나와
<@김젼> 꿈을 좀 생각을 해봐
<@레디스쨩> 일본 mid
<@김젼> 이제 설계할때가 된거잖아
<@김젼> 4학년 3학년 된거면
<@김젼> 계획을 한번 잡아봐요
<@레디스쨩> 2학년 있는데요
<@김젼> 내가 조금전에 말한대로 하면 안돼
<@Gallen> zzzzzzzzzzzzzzzzzzzzzzzz
<@Gallen> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> 여러분 오기전에
<@김젼> 30분 되기 전에
<@김젼> 쿠팡에서
<@김젼> 하는걸 보고있었어
<@김젼> Joke:
<@김젼> 쿠팡은
<@김젼> 비즈니스모델로 장사하는 회사야
<@김젼> 여긴 비즈니스모델이고
<@김젼> 아이디어야
<@김젼> 이런거 할거면
<@김젼> 컴퓨터공학 하지말고 단거하라고
<@김젼> 인문학적 상상력이라는 말 하는놈들
<@wook> ㄷㄷㄷㄷㄷㄷ
<@김젼> 난 그 입을 찢어버리고싶어
<@김젼> 인문학적 상상력 필요없어
<@wook> 파이어의 냄새가..
<@김젼> 교양과목 들어본사람 손 들어봐 =
<@김젼> 그거 도움 되드나?
<@김젼> 인문학적 소양 늘어 나드나?
<@김젼> 우리 박사과정 학생들도 교양수업 들어요
<@김젼> 그거 듣는거 보면
<@Gallen> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> 누구 들어와서 몇마디 하다 나가
<@갤럭갤럭> 방ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ윜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> 시간낭비야
<@김젼> 역사를 봐봐
<@Gallen> 군대 갔다오면 성실해진다니...
<@갤럭갤럭> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ시발ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> 우리 큰애가 역사하겠다고
<@p> 인문한적 상상력ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@Gallen> 방위 출신이...
<@갤럭갤럭> 저거 웃기려고 한 말이겠지?
<@김젼> 열한살이지만
<@김젼> 갤럭갤럭: 농담 맞음
<@Gallen> 우리 아빠가 뻘소리하는거 보는거 같군 ..
<@갤럭갤럭> 입을 찢어버렼ㅋㅋㅋㅋㅋㅌㅋㅋㅋㅋㅋㅋ
<@Gallen> (역시 방위)
<@갤럭갤럭> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> 앞으로 10년 20년 후에는
<@김젼> 우리나라 잘살게 될거야
<@김젼> 이제 우리나라는
<@김젼> 잘사는게 아니ㅏㄹ
<@Gallen> 무슨 개소리얔ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> 어떻게 하면 행복하게 살지를
<@김젼> 고민해야돼
<@Gallen> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> 근데 우리나라 보면
<@김젼> 요원해
<@김젼> 우리나라 인문학 보면
<@김젼> 베트남 수준이야
<@김젼> 역사를 봐
<@김젼> 동북공정 하는거 가서 보면
<@김젼> 일본 사학자들이 우리나라 사학자들보다
<@김젼> 대변을 더 잘해줘요
<@김젼> 베트남이 우리나라하고
<@김젼> 문화가
<@Nemo> 015B 정석원씨 말하는거겠군
<@김젼> 중국보다 더 매치가 잘되고
<@김젼> 가까워요
<@김젼> 난 베트남이 굉장히 좋아
<@김젼> (사고의 흐름)
<@김젼> 사람들이 순박하고 순수해 굉장히
<@김젼> ARM
<@김젼> 싱가포르에서 왔지
<@김젼> 싱가폴 친구도 좋아
<@김젼> 난 싱가폴 친구도 있는데
<@김젼> 김홍톈 교수라고 알아? (싱가폴 학생 가리키며)
<@김젼> 이름이 김홍이고 성이 톈이었는데
<@김젼> 미국에서 같이 취직하다가 사업한다고 싱가폴 돌아간 친구인데
<@김젼> 어쩄든
<@김젼> 커리어 패스가 어떻게 될지 잘 고민해봐요
<@김젼> 컴퓨터공학은여러분이 앞으로 컴공을 하지 않더라도
<@김젼> 좋은 트레이닝이야
<@김젼> 요즘 수명이 늘어서 100살까진 살거야
<@김젼> 그걸갔다가 대비를 해야돼
<@레디스쨩> 100살까지 개발
<@Gallen> 한 나라 사람들을 뭉뚱그려서 순박하고 순수하다고 말할 수 있다닠ㅋㅋㅋㅋㅋㅋㅋㅋㅋ ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> 40~50대 되어서도 공부를 해야돼
<@sg126> 교육학과 14학번이 발표하는 영화 아일랜드에 대한 발표라니
<@Gallen> 아이고 ......
<@sg126> 뭘할지 두근두근
<@김젼> 회사의 정년은
<@레디스쨩> 김젼 100살까지 개발할거같다
<@갤럭갤럭> 100살까지 개발이라니
<@김젼> 없어질거야
<@Joke> ㄷㄷㄷ
<@갤럭갤럭> 어휴
<@김젼> 회사에서 짤릴게 무서우면
<@김젼> 니회사를 해
<@김젼> 우리나라에서 기술로 벤처한다는 회사가 거의 없어요
<@김젼> 기껏해야 요기야 배달의 민족
<@sg126> 다른건 모르겠고 경상도 사람이군
<@김젼> 그게 벤처냐
<@김젼> 아효..
<@김젼> 한심하기 짝이없어
<@김젼> 국내에서 놀면 안돼
<@김젼> 여러분 저기저 ???중에 마이스너 들어봤어요?
<@김젼> C++ 프로그래밍 하는걸로 학교에서 하다가
<@김젼> 뭔얘기하는거지
<@unused> 와 지금
<@김젼> ???
<@김젼> 뭔진 모르겠지만 C++ 코딩하던 친구가 창업해서 700억 벌었다는듯
<@김젼> 뭐 하여튼 그런것도 있고 돈이 많다고 꼭 행복한것도 아냐
<@김젼> 돈이 많으면 편리한거지
<@김젼> 돈이 많으면 편리할거같애 안편리할거같애
<@레디스쨩> 어 왜 하이라잇 울렸지
<@Joke> 쿠팡은 비즈니스모델로 장사하는 회사야 ~~~ 이 부분이 그러니까 이런거 할거면 컴공말고 다른거 하라는말?
<@김젼> 음
<@김젼> 그냥 이재진교수님 사고의 흐름을 말씀하시는ㄷ
<@김젼> 데
<@Gallen> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> 그 길에
<@김젼> 쿠팡이 있었을뿐
<@김젼> 마음담지 마세요 (????)
<@Joke> ㅋ
<@Joke> 아니 마음 담는게 아니라
<@Gallen> 그냥 쿠팡이 걸어가다가 차에 치임
<@Gallen> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> 우리 와이프가 운전기사를 한대는데
<@김젼> 내가 겁이나
<@김젼> 그래서 우리 고성능 컴퓨터 시스템
<@Joke> 저 위에 쓴말이 무슨말인지 잘 이해가 안가섴ㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> 그쪽으로 들어가서
<@김젼> (뜬금없이 수업시작)
```

### 콘트롤 디펜던스
`P`를 실행한 결과가 `Q`의 실행을 결정하면, `Q`가 `P`에 컨트롤 디펜던스가 있다고
함.

### 데이터 디펜던스
우리가 배운거. 플로우 디펜던스, 안티 디펜던스, 아웃풋 디펜던스

```
<@김젼> 천둥 7억 들었는데
<@김젼> sg126: 네
<@김젼> 애틀리에서 300억 들여도
<@김젼> 내가 천둥 7억 만든것처럼 못했어
<@sg126> 그거면 NUMA인지 아닌지 엄청 중요함
<@김젼> 국세가 철~철 낭비되고있어
<@김젼> 내가 뒤에서 욕하는거 봤어?
<@sg126> 애틀리는 어디지?
<@김젼> 난 앞에서 당당하게 욕해
<@김젼> 조직을 상대하는사람들은 조직의 쓴맛을 보게 되어있어
<@김젼> 근데 나는 개인이잖아
<@김젼> 근데 나는 가서 아무말이나 다해
<@김젼> 내가 팽당하더라도
<@김젼> 내가 팽 왜당해
<@김젼> 서울대 정교수인데 팽 왜당해
<@김젼> 그래서 난 우리나라 잘되라고 가서 아무말이나 다해
<@레디스쨩> 와
<@레디스쨩> 재미있게 사신다
<@Gallen> 조직의 쓴맛ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@Gallen> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@Gallen> 아 웃겨 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@sg126> 그러면 일단 교수부터 해야겠군
<@갤럭갤럭> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@갤럭갤럭> 서울대 정교숰ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> TCP/IP 레이어가 어떤 레이어에있어요?
<@김젼> (나) OSI 트랜스퍼 레이어요?
<@김젼> TCP/IP 레이어에있지 (쑻)
<@김젼> (나)
<@kcm1700^멘붕> ..
<@p> 당연히 TCP/IP레이어는 TCP/IP레이어에 있지
<@레디스쨩> TCP/IP레이어에 있지
<@레디스쨩> 지금 데이터통신 하고있는데
<@레디스쨩> OSI 7계층은 요즘 안쓴다고 쓰지 말래
<@레디스쨩> 5계층짜리 쓰래
<@p> ㅇㅇ
<@김젼> 나도 듣긴했음
```

```
<@김젼> 천둥
<@p> osi data link + physical을 network access로 묶고
<@김젼> Top 500 안에 들어가는 컴퓨터인데
<@김젼> 유례없이 저렴해요
<@김젼> 7억밖에 안들었어
<@p> session presentation application을 application으로 묶는거 같긴하던데
<@p> 그래도 뭔가 다르겠지
<@김젼> 그 우리랑 경쟁한애들이
<@김젼> 300억이었는데
<@김젼> 걔네들이
<@sg126> 아직도 500위 안인가?
<@김젼> 아무도 경쟁할수 없을거라고 생각하고 그따위로 했다가
<@김젼> 우리가 7억으로 해버리니까
<@김젼> 완전 망한거야
<@김젼> 올해가 걔네 360억인가 370억인가 쓰는 마지막 해인데
<@김젼> 결과는 잘 나올런지 모르겠어
<@김젼> MPP
<@김젼> KISTI라고 우리나라에서 슈퍼컴 만드는 기관이 있어
<@김젼> 근데 걔네들은 자꾸 MPP랑 클러스터를 구분하는거야
<@김젼> 자기가 연구를 안하니까
<@김젼> 자기가 무슨소리를 하는지 모르는거야
<@p> MPP가 뭐고 클러스터가ㅣ 뭐지
<@김젼> 서울대 출신도 거기있는데 아유 말도하지마
<@김젼> 거기 직장으로는 좋아 놀고먹으면서 월급 잘받지
<@김젼> 쿠팡같은데보다 좋을거야
<@p> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@kcm1700^멘붕> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> 정년도 있기떄문에 좋아
<@sg126> 근데 국가기관이 적절히 놀고먹기 좋을것 같음
<@p> ㅇㅇ
<@김젼> 거기도 연구 잘하는사람 있고 괜찮은사람 있긴한데 정말 극소수야
<@김젼> 연구소 안에서
<@김젼> 연구원이
<@김젼> 원장이 되고싶어하고 이런걸 하면 안돼
<@김젼> 그러면 거긴 연구소가 아니라
<@김젼> 정치판이 돼
<@김젼> 서울대 출신들 봐봐
<@김젼> 서울대 출신 연구자들 아마 좋은자리에 별로 없을걸
<@김젼> 그렇게 순수하게 연구 좋아하는 사람들은
<@김젼> 연구소에서 연구 엄청하다가
<@김젼> 팽당해
<@김젼> 우리 제자도 한명 거기 병특으로 가있는데
<@김젼> 병특이 연구 다한다는 소문이 있어요
<@sg126> 그건 그냥 평범한 회사네
<@Joke> 원래 이재진 교수님 의식의 흐름기법으로 이야기함?
<@Joke> 이야기가 왜이렇게 튀엌ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> 이건 숙제인데
<@김젼> 검사는 안하고
<@김젼> 그냥 여러분이 혼자 하는거야
<@김젼> 근데 혼자하는거라고 소홀히했다가는
<@김젼> 정우근이 꼴날거야
<@김젼> 여러분 수준정도 되면 그냥 읽고 공부하면 돼요
<@Joke> 헐
<@김젼> 그리고 공부를 해놓으세요 수요일날 pthread 숙제가 나갈테니
```

### Loop-carried dependence
루프 순서를 바꿀 수 없는 디펜던스

### 병렬화의 조건
* 프로그램이 존재하는 모든 데이터/컨트롤 디펜던스를 모두 보존하면서
* 스테이트먼트 또는 인스트럭션의 실행 순서를 바꾸어도
* 프로그램의 의미가 변하지 않을경우

### 매트릭스와 벡터의 곱
디펜던스를 따져서 병렬화 해보자

스레드별로 일을 많이 줄수록 아몰타이즈되서 일의 양이 코얼스됨.

```
<@김젼> 제일 좋은건
<@김젼> 알고리즘 레벨 병렬화
<@sg126> 으음? 뭘 해도 그냥 디펜던스 1단계있는거 아닌가?
<@김젼> 근데 그게 안되는 경우가 많아
<@김젼> 그냥 이미 코드가 주어졌는데
<@김젼> 그걸 병렬화 하는 경우가 많아
<@김젼> 생각 없이 코드만 보고도 병렬화 할 수 있어야해
<@김젼> 쩐다
<@kcm1700^멘붕> ㄷㄷ
<@김젼> 네트웍 쪽에서 패킷 셰이더라고 그래서 GPU로 TCP/IP 패킷 처리를 병렬화하는 경우가 있어
<@김젼> ??!?!?!!??!?!!
<@김젼> 카이스트에서 쓴거야
<@김젼> 내가 이야기했나?
<@김젼> 남의꺼 아무것도 아니라고 하면
<@김젼> 좀
<@김젼> 그렇지만
<@김젼> 이거 정말
<@김젼> 아무것도 아닌거야
<@김젼> 트리비얼한거야
<@김젼> 틀 이 비 헐 (실제로 네글자로 끊어서 말하심)
<@김젼> 모두가 다 아는걸 그냥 Apply만 한거야
<@김젼> 그것처럼
<@김젼> 이것도 굉장히 쉬운거에요
<@김젼> 이 행하고 이열 곱해서 얘 만드는거는 독립적으로 계산이 가능하지
<@김젼> 얘 결과를 이용하는게 아니잖아
```

### Reduction
대표적인 병렬 컴퓨팅 패턴중 하나.

어떤 연산을 이용해 여러 개의 값을 모아 하나의 값을 생성하는 과정.

`+`, `*`, `min`, `max`, 등 의 연산에 해당됨.

* 교환법칙, 결합법칙이 성립하고 항등원을 가지는 연산

### Parallel Reduction
분할정복하면 N번 순차연산할걸 병렬로 log2(N) 번으로 할 수 있음

보통 트리구조로 만듬

### Scan
i에 있는 원소가, 0~i에 대해 주어진 연산을 적용하여 얻어진 결과일경우. 결합법칙이 성립해야함.

대표적인 병렬 컴퓨팅 패턴

Parallel scan을 적용하여 log2(N)번 덧셈 스텝만으로 이 패턴도 병렬화 할 수 있음.

패러렐라이제이션 오버헤드를 항상 생각하도록. 이런것들은 엘러멘트가 훨씬 클떄만
유효함.

다학식 계산, 점화식 계산, 소팅, 히스토그램(도수분포표) 그리는데에 씀

Reduction과 Scan의 특징. 디펜던시가 있지만, 부분적으로 병렬화시킨것.

난 따로 배운게 없어. 그냥 이거 배워서 한거야.

내가 대학원에서 들었던 학부과목중에 컨커런트 프로그래밍 수업이 있었는데, 리덕션
하면 로그스텝으로 나오잖아.

다이닝 필로소퍼 알지? 그거 비슷한거 (슬리핑 바버) 풀었는데 난 그게 이미 있는줄
모르고 독자적인 방법으로 풀었는데 얼마나 자랑스러웠는지 몰라. 까먹었지만. 혼자
하면 다 자기께 되는거야.

### MapReduce
Google에서 발표한 대용량 데이터 처리를 위한 일종의 프로그래밍 모델.

하둡이 맵리듀스만 하려고 만든거라 굉장히 더러워. 뭐 하나 임프루브 하려고 하면
전체를 다 고쳐써야돼.

예시) 모음과 자음 세는 프로그램 만들기.

매퍼, 리듀서가 따로 있음.

--------

예전엔 포트란 어셈블리 코드젠이 C보다 더 좋아서 포트란 썼는데 이젠 그럴필요 없음

```
<@김젼> 진짜
<@김젼> 프로그래머는
<@김젼> 어떤 프로그래머?
<@김젼> 어셈블리 프로그래머
```

--------

> 4월 20일

### Non-blocking Single-Producer and Single-Consumer

### 병렬화 시 고려할 점
병렬화할때 애몰타이즈드

* 프로그램에 든 병렬성의 양
  * Amdahl의 법칙
  * 순차실행을 할 수 밖에 없는 부분에 의해 Speedup의 한계가 결정된다
* Locality
  * 될 수 있으면 로컬 데이터를 이용하여 계산하는 것이 좋음 (캐쉬를 잘 이용하도록)
  * 스레드나 프로세스 간 데이터의 이동에 시간이 걸림

로컬 데이터를 이용하면 파워컨슈밍도 줄어들음

* Load balance
* 병렬화 오버헤드
  * 스레드/프로세스 시작비용
  * 통신비용
  * 동기화 비용
  * 병렬화를 위한 가외의 계산 (로우바운드 어퍼바운드 계산하는거)


```
<@김젼> 자연스럽게
<@김젼> 짤린 부사장 얘기로 넘어옴
<@에이린> 1가지를 포함한 10가지야.
<@에이린> (?)
<@김젼> 클라우드 사업을 하고있다고 한다
<@**> 헐 삼성?
<@김젼> 아이펀팩토리인가 (?)
<@김젼> 네
<@김젼> 삼성
<@**> 헐 그분 짤림????
<@김젼> 몰라유
<@김젼> 음
<@김젼> 삼성 아닌거같음
<@김젼> 방금 뭔가 얼버무려서 못들었는데
<@Gallen> hoeee
<@Gallen> hoe
<@김젼> 호잇
<@김젼> (?)
<@김젼> 내가 그런거 보면 답답해요
<@김젼> 겁을 내요 겁을
<@김젼> KT 클라우드 사업하는데 거기서 KT에서 개발한거 하나도 없어
<@김젼> 다 오픈소스 그냥 인스톨해서 하는거야
<@김젼> 내가 OS같은거 만들어야된다 별거아니다 그러면 진짜 별거 아닌거야
<@김젼> SKT는 양자 퀀텀 커뮤니케이션가지고 뭐 좀 되는거같애
<@김젼> 여러분 훌륭한 선배가 거기 들어가있어
<@김젼> 눈빛을 보면 알아
<@김젼> 거짓말을 안해
<@김젼> 컴퓨터 하다가 물리학 하는 친구인데
<@김젼> 뭐가 나오는거야
<@김젼> 똑똑한 친구들이 가니까
<@김젼> 인력이 제일 중요해요
<@김젼> 그러니까 그거는 뭐 요새 사람 구하는거 붙어있대
<@김젼> 못봤어요? 퀀텀 랩이라고 그래가지고
<@김젼> 퀀텀컴퓨팅쪽은 내가 보면 그짓말이 너무 많아
<@김젼> 검증이된건 소인수분해 딱 하나야
<@김젼> 나머지는 될지안될지 아무도 몰라
<@찬민> 헐
<@김젼> 연구를 해야될 주제에요
<@김젼> 근데 되는것처럼 이야기하는게 너무 많고
<@찬민> sqrt(n) 타임에 N개 테스팅하는 건 유명한데
<@김젼> 거기거짓말하는놈들이 너무 많아
<@김젼> 문귀환이 잘 알거든
<@김젼> 어디 신문이나 외국신문 베껴가지고
<@김젼> 7대 중점 연구과제 이러는거 내가 보고
<@김젼> 우스워가지고
<@김젼> 인문학가지고 결합을 해가지고
<@찬민> Grover's algorithm 신기한뎅 ㅠㅠ
<@김젼> 정신이 이상한놈들이야
<@김젼> 경영진들 거기 삼성보며는
<@김젼> 문과쪽이 70프로야
<@김젼> 난 그거 웃기는게 현업에서 배워서 하면 되는거야
<@김젼> 절대로 자기가 그거 학부에 전공했다고 써먹는게 아니라고
<@김젼> 인문학쪽은 학교와 현장의 괴리가 진짜 심해요
<@김젼> ㄱ여영학 배우면 경영 잘할거같지
<@김젼> 첫째 학교다니면서 배우는게 없고
<@김젼> 학교 다니면서 술마시는거밖에 안배워
<@김젼> (문) 교수님은요?
<@김젼> 난 공부열심히했지 임마
<@김젼> 내가 1학년 2학년때엔
<@**> 문귀환ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> 들어가자마자 시험거부 수업거부좀 해서
<@sg126> ㅋㅋㅋㅋㅋㅋ
<@김젼> 내가 그떄 안그랬으면 계속 물리학했겠지
<@김젼> 왜 여기(컴공)왔겠냐
<@김젼> 물리학도 계속 하고싶은데 지금 할라면 좀 늦었고
<@김젼> 그떈 내가 공부를 좋아했는데 공부할 여건이 안됐어 (민주화시댸)
<@김젼> 그떈 컴퓨터 하는사람이 별로 없었어
<@김젼> 포트란같은건 내가 중학교떄부터 익혀서
<@김젼> 자유자재로 다뤘다고
<@김젼> (좌중) 캬
<@김젼> 진짜야
<@김젼> 내가 프로그래밍 그거 강사 등록해서
<@김젼> 교수들 가르치고 그랬다고
<@김젼> 수학과 교수님들하고 같이 듣고 그랬다고
<@김젼> 그때 실업계 고등학교에서 컴퓨터 하는데가 생길락말락했는데
<@김젼> 거기 인문계애가 컴터 가르치는거 보고
<@김젼> 너 왜 공부잘하는애가 컴퓨터하고있냐고 교수들이 그랬더라
<@김젼> 근데 난 이게(컴퓨터가)재밌어
<@김젼> 운명을 거부할수가 없어
<@김젼> (좌중) 하하
<@김젼> 내가 컴퓨터 맨날 엄청싫어했거든
<@김젼> 이거 해서 뭐하냐 맨날 그랬는데
<@김젼> 이게 실제로 연구해보면 학부에서 시험보는거랑 달라요
<@sg126> 어째 교수님의 잡담은 매번 자기자랑으로 끝나는거 같다
<@김젼> 예전에 싫어하는것들 다 내가 하고있지
<@김젼> 예전에 0101 계산하는거 다 귀찮다그랬는데 이제 맨날 내가 하는거지
<@김젼> 하다보니 직업이 돼브렀어
<@김젼> 근데 재밌어
<@김젼> 재밌는걸 해야지
<@김젼> 공부하기 싫으면 재밌는걸 해야지
<@김젼> 찐빵 만드는 아이디어가 있으면 찐빵 만들어
<@p> 문귀환ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> 공부할필요 없어
<@김젼> 공부 안한놈들이 득세하는 세상이야
<@김젼> 중퇴해
<@김젼> 바뀔거에요 이제
<@김젼> 이 사회가 바뀔거에요
<@김젼> 천천히 바뀌어요
<@김젼> 안바뀌는거같지만
<@김젼> 쪼끔씩쪼끔씩 바뀌고있으니
<@김젼> 조급해하지말고 자기가 좋아하는거 하면 다 보답받게 되어있어
<@김젼> 근데 내가 보장할수는 없고
<@sgm> ㅋㅋㅋㅋㅋ
<@김젼> 어떤 조건하에서 노력하면 ㅗ답을 받을까요?
<@p> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> 이 조건이 뭐겠어
<@김젼> 요령을 알아야돼
<@sgm> 빠져나갈 구석을 만드시는군
<@김젼> 공부를 하더라고 무조건 책상머리에 앉아있는게 되는게 아니라고
<@김젼> 요령을 가르쳐주는사람이 누구야?
<@김젼> 나같이 훌륭한 서울대 교수라고
<@김젼> (한명이 빵터짐)
<@김젼> 어떤 세키야
<@김젼> 진짜야
<@김젼> 내가 가르치는건 요령밖에 없어
<@김젼> (문귀환인거같음)
<@김젼> 그럴라면 좋은사람 만나야돼
<@김젼> 원래 지도교수랑 다 학생이 비슷해져
<@김젼> 머리가 빠져
<@김젼> 내 지도교수가 대머리거든
<@김젼> 근데 그 학생ㄴ들 보면 다 대머리야
<@sgm> ㅋㅋㅋㅋㅋㅋㅋ
<@**> 좀있으면 우군이에게
<@**> 우근이에게*
<@김젼> 너(정우근)이 대머리 될거야
<@찬민> ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ
<@**> 화살이 날아가겠군
<@김젼> 병렬화 할떄 고려해야하는게
<@찬민> 너무나도 정확한 예측
<@김젼> 애몰타이즈드 된다고 했죠? (자연스럽게 수업으로 넘어감)
<@김젼> 암달의 법칙
<@sg126> 오늘의 멀티코어수업도 잘 들었습니다
<@**> 그러게 나중에 로그 넣을 때 제 닉은 빼 주세요[?]
<@김젼> 로캘리티를 이용한 최적화
<@김젼> 히익
<@김젼> 인피니밴드
```

### 삽질
구덩이가 작으면 병렬화 안하는게 더 나음

```
<@김젼> 내 Ph. D 첫 연구가 이거야
<@김젼> 병렬화 오버헤드를 에스티메이션 해서
<@김젼> 오버헤드가 더 크면 그냥 순차실행으로 펴는거
<@김젼> 문제는 이걸 실행하기 전에 예상해서 해야돼
<@김젼> 존나 어려워
<@김젼> 캐시프리딕션을 비롯해서 예측할수있는게 아무것도 없어
<@김젼> 자랑하는게 아니고
<@김젼> 두달만에 내가 뭔가를 발견을 해서
<@김젼> 요게 요렇게 되야합니다 하랬더니
<@김젼> 컴파일러에 임플리먼트하래
<@김젼> 근데 그당시 상용것보다 더 성능이 안좋았던 컴파일러가
<@Backspe> 에거교수님이 어디서 박사받았지
<@김젼> 그게 DARPA 프로젝트였거든
<@김젼> 그쪽은 펀딩은 두세배가 돼
<@Backspe> 박사 받다?
<@김젼> 왜냐면 걔네는 자주국방하거든
<@김젼> 우리는 자주국방 포기했거든?
<@김젼> 진짜야
<@**> Backspe: 우리 연구실
<@김젼> 전두환이가 80년대에 집권하면서 모든걸 미국에서 사겠다고 했어
<@김젼> 그 좋았던 ADD
<@김젼> 거기 탑들 많았어
<@김젼> 지금 다 어딨어
<@김젼> 정년퇴임을 갓 앞둔 교수님들
<@김젼> 정년퇴임을 앞뒀는데 탑인 교수님들 보면
<@김젼> 다 ADD 출신이야
<@김젼> 지방 출장가는데 다 비행기타고가
<@김젼> 월급도 대기업 두세배 받고
<@김젼> 근데 지금은 개판이지
<@김젼> 월급은 대기업 70프로고
<@Backspe> 에거교수님도 대머리!
<@p> **: 대머리?
<@**> ㅜㅜㅜㅜㅜ
<@김젼> 석사학위를 받는사람이 더 있었어
<@김젼> 내가 숙제 다했었어
<@갤럭갤럭> 에거 교수님도 대머맄ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> 나한테 이득 있느냐?
<@김젼> 읎어
<@김젼> 그리고 하는일이
<@김젼> 차닦는거야
<@갤럭갤럭> 왠지 머리 빠질 얼굴론 안 보였는데(?)
<@김젼> 바가지 이만한데에 물한통 있으면
<@김젼> 5분안에 세차할수있어요
<@김젼> 집에가기전에 맨날 열대정도 닦았는데
<@김젼> 요새는 그게 잘 안되네
<@갤럭갤럭> 근데 재진리 젊지 않나
<@김젼> (자기 군생활 이야기 말하는거임)
<@김젼> 그래서 DARPA 프로젝트에서 이런것도 많이해요
<@김젼> 여기서 나온 프로덕트가 상용화된게 많아
<@김젼> 병렬쪽 물건들은 다 군대에서 나온거야
<@김젼> CDC6600도 어디서 나온거에요?
<@김젼> 컨트롤 데이터 코퍼레이션의
<@김젼> 미 해군에서 부탁을 해서
<@김젼> 만든거라고
<@**> 오 CDC 6600
<@김젼> 열배 더 큰 컴터가 필요하다 이래서
<@김젼> 그게 우리나라 과학기술 발전에 큰 도움이 되는데
<@김젼> 문제는 우리나라는 그런식으로 드라이브가 안된다는거
<@**> 주: 세계 최초의 슈퍼컴퓨터
<@김젼> 여러분 잘하는거
<@김젼> 삽질 (수업이야기임)
<@p> 맞는 이야기긴한데
<@김젼> 지름이 50 깊이가 50인 구덩이를 판다
<@김젼> 한사람이 삽질하는경우
<@김젼> 여러명이 삽질하는 겨웅
<@김젼> 워뜬게 빠를거같애?
<@**> 삽이 초록색이겠군
<@김젼> 이경우는
<@김젼> 혼자 파는게
<@김젼> 더 빠른데
<@김젼> 한명이 혼자 나설때까지
<@김젼> 시간이 걸려
<@김젼> 이거랑 똑같애
<@김젼> 근데 이렇게 생각하자
<@김젼> 지름이 3미터 깊이가 1.5미터다
<@김젼> 이럴경우는 여럿이 파는게 더 빠르지?
<@김젼> 코디네이팅을 해줘야돼
<@김젼> 행렬 계산을 한다고 쳐봐
<@김젼> 행렬을 오른쪽 반 삼각형을 계산하는데
<@김젼> 위에부터 하면
<@김젼> 밑에쪽은 엘레먼트가 하나인데 윗쪽은 네개이지
<@김젼> s/네개/N개
<@김젼> 아 맞아 그래서 아까 그 컴파일러
<@김젼> 국방성 프로젝트를 했는데
<@김젼> SGI보다 성능이 안좋았던게
<@김젼> 내가 손대서 그것보다 좋아져서
<@김젼> 2주만에 고걸 임플리멘트 했으니까
<@김젼> 지금 얘기하는건 모두 사실이에요
<@김젼> 그리고 한달정도 더 팠어요
<@김젼> 그때는 오퍼레이션의 수 루프의 바운드
<@김젼> 이런것만 따져서 해도 잘 디텍트가 됐는데
<@김젼> 한달정도 더 파보니까 문제가 있드라
<@김젼> 정확하게 하는데엔
<@김젼> 그래서 포기했어
<@김젼> 그리고 주제를 바꿨지
<@김젼> 메모리컨시스턴시 이쪽으로
<@**> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> 일을 했으니까 내 경력에 넣어놓긴 했지
<@김젼> 그떄 그거 두달 일하고 논문을 안썼는데
<@김젼> 서울대 와서야 논문을 썼어
<@김젼> (수업하던도중)
<@김젼> 아 가물가물하다
Changhee Jung, Daeseob Lim, Jaejin Lee, and SangYong Han. Adaptive Execution
Techniques for SMT Multiprocessor Architectures,
PPoPP '05: Proceedings of the ACM SIGPLAN Symposium on Principles and Practice
of Parallel Programming, pp. 236—246, Chicago, Illinois, USA,
June 2005
```

### 확장성
Scalability

* 더 많은 프로세서가 있으면 성능이 향상됨
* 프로세서 수가 증가할수록 병렬화 오버헤드가 증가
* Weak scalability vs Strong scalability
  * 일의 양을 놔두고 프로세서 수를 늘리면 리니어하게 속도가 증가
  * 일의 양이랑 프로세서의 수를 같이 늘리면 속도가 안늘어남

네개 프로세스를 돌렸는데 스피드업이 다섯배인경우. 이게 가능할까? 가능함.

1.  병렬화시키면 private cache의 크기가 늘어나니까.
1.  알고리즘에 따라 운좋으면 그럴 수 있음. (소팅)

동기화를 위한 하드웨어 지원
--------

### Deadlock and Livelock
Deadlock: 일이 아무것도 더이상 진행되지 못하는 상태. 락이랑 아무상관 없다.

Livelock: Possible execution sequence는 있는데, 그걸 찾지를 못하는 상태. State가
뭐라그랬어요? 레지스터의 값, 메모리의 값. State는 계속 바뀌는데 진행이 안되는
상태. Resource starvation의 특별한 형태.

### 데드락의 네가지 필요조건
아래 네개중에 하나라도 깨지면 데드락이 아님

1.  상호배제
2.  Hold and wait
3.  No preemption
4.  Circular wait

### Mutual exclusion problem
모든 스레드는 아래 네 영역을 오가면서 무한루프를 돈다

* Non-critical section
* Pre-protocol
* Critical section
* Post-protocol

아래와 같은 조건이 필요함

* Mutual exclusion
* Deadlock-freedom
* Starvation-freedom
* ~

### Dekker's Algorithm
Busy-wait으로 critical section 구현함.

메모리 컨시스턴시때문에 안됨.

### Bakery Algorithm
순번표 뽑은대로 크리티컬 섹션에 들어감.

* Not very practical
* N 스레드

### Hardware support for Mutual Exclusion
* Atomic read, write 연산이 됨
* Read와 Write가 interleave하면 소프트웨어로 상호배제하기 너무 힘듬

### Atomic ops
* Fetch-and-store
  * a.k.a. Atomic swap
* Test-and-set
  * True면 True 반환
  * False면 True로 세팅하고, False 반환
* Fetch-and-add
  * 메모리 로케이션과 값을 받아서, 그 메모리 로케이션에 있는 값을 받은 값으로
    더해주고 옛 값을 반환함
* Read-modify-write
  * 메모리 로케이션과 펑션을 받음, 메모리 로케이션의 값에 그 함수를 실행하고, 옛
    값을 반환
* Compare-and-swap
  * 메모리 로케이션과 두 값을 받고, 같으면 뉴 밸류를 스토어하고 참 반환, 아니면
    거짓 반환

### Test-and-set으로 뮤텍스 구현하기

```
<@김젼> Knuth
<@김젼> 78년도에 포트란 프로그램들이 있는데 그 전에 나온 논문들은 머릿속으로 생각해서 이렇게 하면 최적화되지 않을까 해서 논문을 썼는데
<@김젼> Knuth는 실제로 돌아다니는 포트란 프로그램들을 모아서 여기에 이거 적용하고 이거 적용하면 이렇게 빨라진다고 하고 논문을 냄
<@김젼> 최초의 실험 컴퓨터과학 논문으로 인정받음
<@김젼> 그 이후로 실제로 임플리먼트해서 숫자로 증명되지 않는 논문은 안나옴
<@김젼> 후진적인 분야가 있고 선진화된 분야가 있어요 (?)
<@김젼> 이렇게 프랙티컬하게 쓰이는쪽이 내가보기엔 선진화된 분야에요
<@김젼> 백날 안쓰이는 논문 내봐야
<@김젼> 저 열대우림 훼손하는거야
<@Gallen> 열대우림 훼손ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@김젼> 남들이 안읽어돈 ㅗㄴ문을 써야하는 이유가 뭐겠어요?
<@김젼> 대학원생 교육하기 위해서야
<@김젼> 고때는 유용해
<@김젼> 근데 프랙티컬하게 쓰이는걸 생각하면
<@김젼> 논문 쓰는것도 프랙티컬하게 쓰이려고 하는거야
<@김젼> 이사람도 큰 컨트리뷰션을 많이했어요
<@김젼> 레이텍만들지
<@김젼> 볼륨 네권짜리 그거 만들지
<@김젼> 내가 크누쓰하고 같이 웃는 이야기를 말했는데
<@김젼> 미국에 가서 네스터한테 막 얘기했는데
<@김젼> 얘가 (물리학자임) 컴퓨터과학은 학문으로 안보인다 이얘기를 했더니
<@김젼> 크누쓰가
<@김젼> (잘 못들음)
<@김젼> 그런식으로 학문이 생기는거에요
<@김젼> 컴퓨터가 생긴지 얼마나됐어요?
<@김젼> 60년정도 되었다고 보면 되겠다
<@김젼> 전자공학 전기공학하고 달라요
<@김젼> 아까 여러분이 잘못생각할까봐 다시얘기하는건데
<@김젼> 이론쪽이 중요하지 않다는게 아니에요
<@김젼> 굉장히 중요해요
<@김젼> 숄티스트패스니 이런게 다 어디서 나온거야
<@김젼> 다익스트라같은 사람이 만든거야
<@김젼> 크누쓰는 이론도 하고 실험도 하고
<@김젼> 컴퓨터쪽에 여러가지로 큰 영향을 미친 사람이에요
<@김젼> 나 원래 이론하던 사람이에요
<@김젼> 이론 하다가 실험하는사람이에요
<@김젼> 크누쓰처럼 똑똑한 사람이라고
<@김젼> 원래 내 논문에 보면 실험하는거 하나도 없어요
<@김젼> 시스템 하면서 이론만으로 박사 받았다고
<@김젼> 그럼 쓰레기라고 그러지
<@김젼> 메모리 컨시스턴시 내가 아주 간단하게 정리한 논문이 있거든
<@김젼> 아주 간단하게 정리를 해서 퍼블리쉬를 한게 있어요
<@김젼> 그게 내 박사논문 안에 들어가있음
<@김젼> 인텔에서 그걸 레퍼런스 했으니까
<@김젼> 요샌 안그러는데 70 80년대에는 나 보면 도움이 많이 되었다는 이야기 많이 해요
```

### Spinlocks

(시험에 나옴)

확률적으로 재수없으면 한 스레드가 계속 통과 못할 수 있음.

인텔 아키텍처 레퍼런스에서 권장하는 방법

### Mutual Exclusion using Exchange
Atomic Exchange로 뮤텍스 구현하기

--------

> 4월 22일

### Matrix Multiplication
순서에 따라 달라지는 미스율

### Strip Mining

### Tiling
시프에서 질리도록 한거

### Tiling for Matrix Multiply
매트릭스 곱을 여러개로 쪼갤 수 있음

원래 캐시미스는 `N^2/m + N^3` 인데, `2N^3/(Bm)`로 변함. `N`은 매트릭스 크기,
`m`은 캐쉬라인 크기, `B`는 블럭 크기, 이때 `B` 바이트가 전부 캐쉬에 올라갈 수
있다고 가정.

```
세계에서 다섯손가락 안에 들어가는사람이 헤매잖아
실험을 해봐야되지 않겠냐

내가 대학다닐때엔 웹 브라우저가 모자익이 전부였는데
요즘은 어려운문제 내면 다 나와서 애들이 스스로 공부를 안해
```

--------

> 5월 6일 (지각)

당당히 들어오네?

### Source-to-Source Translation Techniques
* CPU쪽 소스는 소스 투 소스 변환을 함
* GPU쪽 소스는 독자적인 컴파일러를 써서 컴파일

4~5년 내에 gcc는 모멘텀을 완전히 잃고 llvm으로 넘어올것임

### For CPUs
`__kernel` 붙은 코드를 그냥 시퀀셜하게 붙여버리면 CPU 코드가 나옴. 근데 배리어가
있으면 안됨. 이걸 어떻게 구현할까?

* AMD: 셋점프 롱점프를 씀. 이거 배운사람 손들어봐. (손) 느그 어디서 배웠어?
  (시프요) 그게 다 피가되고 살이되는거야.
* 우리: 셋점프 롱점프가 느려서 안씀. 그당시엔 셋점프/롱점프를 안써서 5배정도
  빨랐는데 AMD에서 개선을 많이 해서 AMD가 우리꺼보다 두배 빠름

### Context Switching between Work-items
셋점프/롱점프를 쓰는 라이트웨이트 컨텍스트 스위칭

### Work-item Coalescing [PACT '10]
* 컨텍스트 스위칭을 피하고싶음
* Source-to-source translater

이 방법을 쓰면 Goto만 안 쓸경우 트랜스포메이션이 다 됨. 근데 이렇게 하면 문제가
하나 있음

(Control flow graph)

배리어 전후로 지역변수를 공유하면, 배리어 전후로 지역변수 상태가
사라져버리기때문에, 별도로 지역변수를 저장해줘야됨.

##### 왜 SnuCL 상용화 안해요
```
<@지현> 야임마
<@지현> 우리가 연구를 누구돈으로해?
<@지현> 나랏돈이요
<@Gallen> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@지현> 내가 외국에 팔면 양심에 안찔려
<@지현> 근데 이걸 사기업에 팔면 돼안돼?
<@지현> 우리나라에서 쓰면 되지
<@지현> 근데 오픈소스 해놨으니까
<@지현> 오픈소스 한거 상용화해도 되잖아
<@지현> 그럼 아무런 양심에 거리낄게 없잖아
<@지현> 상용화 당연히 해야지
<@지현> 참고로 내가 물어본거 아님
```

### SnuCL Runtime
* Host node
  * Host thread
  * Command scheduler thread
* Compute node
  * Command handler thread
  * Device threads
  * CU thread (CPU only)

호스트 하나 - 여러 노드, 이런 구조를 쓰지말고 계산 노드별로 호스트를 각자 다
돌리고 호스트끼리 통신을 시키면 코스트가 많이 절약됨.

Cross-device virtual memory. 여러 컴퓨터에 퍼져있는 메모리를 하나의 RAM처럼
쓰자.

Loop level parallelism, 디펜던스 추적 등등은 80-90년대에 연구가 완전히 끝나서
요즘 자동적으로 되게 잘됨.

소프트웨어쪽이 강한 세 대학
* Rice
* 일리노이 - kuck
* 스탠퍼드

인텔에서 나온 패러렐스튜디오니 뭐니 다 쿡한테서 나온거야.

penCL쪽에선 우리 연구실이 제일 앞서있어
그 누구도 우리를 따라올 수 없어

##### Q: 교수님 컴파일러하징낳으셨어요 왜 일로 넘어왔어요
느그 컴파일러가 파싱하는 그런게 컴파일러인줄 아냐
그건 80년대에 다 끝났어
루프레벨 페러렐리즘 이렇게 빠른 바이너리 뽑아내는게 과제야
그거 하려면 OS 시스템프로그래밍 해야하지
다 멀티코어랑 맞닿아있는거야

### Dynamic Scheduling
CPU 클러스터가 GPU 클러스터에 비해 갖는 장점
다이나믹 스케쥴링
로드에 맞춰서 알아서 스케줄링이 됨
먼저 끝난놈한테 일 더 밀어주기
로드밸런싱
GPU는 그게 안됨
포트란을 능가하는 언어가 없어요
과연?
C99가 나왔는데도?
돌려보면 포트란이 제일 빨라
근데 이걸 쓰면 포트란보다 더 빠른경우가 있어

### Buffer Space Allocation

### Lateset Copy of a Buffer Object

### Buffer Reads and Writes

### Consistency Management
버퍼에서 서로 쓰는 부분이 겹치지 않는 두 job은 Enqueue할때 merge 시켜버릴 수 있음.

* Compare and merge. 근데 이건 오버헤드가 너무 큼.
* SnuCL은 그냥 이거 serialize시켜서 GPU1 먼저 돌리고 그 뒤에 GPU2를 돌림. 실제로
  이걸 돌려보면 오버헤드가 많이 줄어듬.

### 포트란이 빠른가?
```
C99에 리스트릭 되어있으니 이론적으론 두 언어 코드젠 같은거 아닌가요?
참고로 수업 끝났음
대답은
일단 난(교수님은) C99에 그런거 추가된지 몰랐고
사용자는 멍청해
포트란이 실제로 빨라서 쓴다기보단
그냥 익숙해서 쓰는거야
멀티코어분야에서 포트란 많이써요
많이쓴다는 이야기를 하니까 내가 미친거같은데
포트란 고리타분하잖아
그래안그래
(누군가) 재밌는거같은데
뭐가재밌어 난 하나도 재미없구만
이제는 C/C++쪽으로 바뀌고있어요
중요한건 실제로 많이 쓰기떄문에 연구를 할수밖에 없어
```

### 뻥셔널
```
뻥셔널랭귀지쪽
사람이 안쓴다고
이게 아무리 이상적으로 좋아도
전혀 쓸 필요가 없어
막 나오고
새로운 언어 막 나오지
근데 많이 써야될거아냐
폼잡으려고 만드나?
SnuCL 왜만들었어?
이것도 언어야
근데 왜만들었겠어
있던걸 Improve 시키기위해 만든거지
새로운 언어 만드는건 쉬워요
근데 이미 많이 쓰는 C 포트란 개선시키는거
그런건 진짜 어려운거ㅇ
디펜던스 리졸브 하고싶다그랬지
뻥셔널랭귀지 쓰면 돼
그동네엔 디펜던시가 아예 없어.
(문이 이상한소리 계속 함)
디펜던시 안생기게 못짠다니까;;;
사람이
시퀀셜하게 생각을 하면
디펜던스 없이 C로 계산 못해
가져와봐
내가 10만원 줄게
못해
그게 안되기때문에 계속 디펜던시 어날러시스 이걸 계속 한거잖아
폴리해드럴 모델
이런거 나오고
90년대에 완전히 끝난분야야
여기
헤테로지니어스 컴퓨팅 여긴
미국이랑 우리하고 3년전에 같이 시작한거야
그래서 충분히 우리가 격파할 수 있어.
(문이 여전히 이상한소리 지속함)
당연하지
디펜던스 없애는것보다 그냥 사람들이 짜는 멍청한 코드를 효율적으로 돌려주는게 더 중요해
그래서 내가 이런걸 가르치는거고
필드 나와봐
별의별걸 다 병렬화시킬 수 있어
근데 사람이 없어서 문제야
사람들은 바보야
안하던놈들이 책보고 배워서 하고있어
우근이 갔다 놓으면은
근데 군대가야되니까 어떡하냐?

이론적으로는 굉장히 깨끗하고 나이스한 분야가
뻥셔널 랭귀지에요
근데 내가 지도교수 만나고 했는데
난 거기서 나왔어
난 뻥셔널랭귀지쪽
철저하게 반대야
엔지니어링이라는건
실제로 쓰여야돼
그냥 이미 있는 C 포트란 개선시키는게
훨씬 힘들어
더러운걸 깨끗하게 만드는걸 만드는게 훨씬 힘들어
한글 왜만들었어
사람들이 쓰는 언문에 사맞은 글자를 만든거잖아
대중을 위해 만든거잖아
새로운 언어 만드는건 쉬워
내가 ML쪽으로
우리나라에서 제일 많이 한사람일거야
근데 내가 알아
사람 머리속에서 돌아가는거랑
매치가 안돼
재밌긴 재밌지
내가 왜 스칼라를 안가르치겠어
해스켈
오타쿠
나도 한때 오타쿠였어
한떄 발들였다가 빠져나왔다고
Java를 많이 쓰는 이유가
C++이랑 닮아서 그런거잖아
```

--------

> 5월 11일

SnuCL
--------
### Matrix Multiplication Example
1.  1 OS, 1 GPU
2.  1 OS, n GPU
3.  Cluster, n GPU
    * OpenCL + MPU
    * SnuCL
    * SnuCL with collective communication extensions

```
SnuCL
MPI에있는 몇몇 커맨드들은
SnuCL에 있는 몇몇놈들하고 1:1 대응됨

왜 엔비디아 안쓰냐구요?
CUDA 밀어서 싫어하시든데
SnuCL
버퍼를 할당하면
알아서 클러스터에 흩어져서 할당됨
SnuCL API에는 노드가 겉에 드러나지 않음

OpenCL 시맨틱을 해치지 않고 클러스터링할 수 있음
clEnqueueAlltoAllBuffer
매트릭스 곱 예제
OpenCL + MPI 대신 SnuCL

SnuCL with collective communication extensions
갑자기
출석부르는중
굿바이 노휘래

SnuCL 수업자료에
숙제 4번
답이 써져있음
게이득
에
C에서
함수 파라미터에
a[asd][asd][asd] 이런거 쓰면
한 차원만 컴파일타임에 체크되고 나머지가 **로 바뀌는거던가 아니면
하나만 *로 변신하고 나머지 둘이 컴파일타임에 체크되는건가?
전자 아닌가?
C를 안써서 모름
<*> 한 차원만 *로 변신하고
그렇군요
<*> 나머지는 컴파일타임에
아
a[x][y][z] 할때
x*dim*dim + y*dim + z
하려고
그러는거였구나

평화롭게
행렬곱 하는데
OpenCL도 CUDA처럼
이차원 인덱싱이 될텐데
피피티엔 일차원으로 들어가있군
<@Unused_home> 참고: C99 가변길이 배열이면 두번째 첨자 이상도 런타임에 계산될 수 있음

GPU에
2차원 인덱싱 쓰면1
1차원 인덱싱 하고 손으로 x*dim + y 하는것보다
성능상에 잇점이 좀 더 있나
하드웨어로 더 해주나
<*> 똑같음
똑같군요
그럼 별로 상관없군
<*> *dim을 안 쳐도 돼서 내 손가락이 덜 아프다는 장점이 있지 [?]
<@지현> 오홍
<@지현> 똑같아서 예제에 그냥 1차원으로 쓴거군
<@sgkim> 그러게 gpu라면 n 차원 메모리모델에대한 최적화도 지원해줬으면 좋겠다
<@지현> 전 최적화를 해서 그런거 하는줄 알았음
<*> n차원 서포트하는 image라는 것도 있음
<*> clCreateImage로 만드는거
<@p> ㅇㅇ 손가락이 덜아프지..
<@sgkim> 아 그걸로 만들면 n차원에 대해 최적화해줌?
<*> 기본 데이터 타입이 element 4개짜리 벡터이고
<*> 사실 2차원에 대해서 딱히 최적화해주거나 하진 않지만
<@sgkim> 왠지 rgba일것같다
<@p> ㅋ
<*> 대신 예를 들어서 3.5, 2.2에 접근한다 그러면
<*> 자동으로 interpolation을 해주거나
<@p> 멋지당
<*> 등등의걸 할 수는 있지
<*> rgba 맞음
<@지현> 으흠
<@p> 흐음
호스트에 메모리 할당 하고
GPU에 바인딩하고
커맨드 enqueue 하는거까지
숙제 4번 정답을
완전히 가르쳐주셨군
GPU 여러개에 작업 분산하기
계산에 필요한 데이터를 각 GPU에 복제해줘야해서
오버헤드가 생김
커널은 똑같이 사용하고
디멘션을 조작
코드가
마치
여러개의 OpenCL 인스턴스를 초기화하는것처럼
변함
여러 GPU로 한 컨텍스트를 만들고
디바이스마다 커맨드큐를각각 만들고
디바이스마다 버퍼를 각각 초기화
버퍼를 만들떄엔 디바이스에 안붙어있음
사용할떄 lazy하게 바인딩됨
커널 코드는 하나인데
커널마다 아규먼트를 다른걸 줘야돼서
커널오브젝트도 디바이스마다 여러개 만들어야됨
서로 다른 버퍼를 넘겨줘야 하니까
음흠
각 커맨드큐에 인큐를 하고
각 커맨드큐에서 팝
끗
1 OS 멀티플 GPU에 대해 하는법을 배웠음
클러스터링
클러스터 + 멀티플 GPU에 대해 하는법
OpenGL + MPI로 하면
각 노드마다 MPI 호스트가 다 돌아야됨
MPI 그켬
도대체 난 고1때 C 처음 배우고 이걸 어떻게했지
못읽겠다
<sgkim> 히이익
<sgkim> 고1때 이걸 어떻게 했지?
성적이 걸려있으면 할수밖에 없음 (?)
교수가
잘 몰라서
너무 어려운걸 줬었음
SnuCL
1 OS 멀티플 GPU에 썼던 코드를
그대로 실행하면 됨
collective communication extensions을 쓰면
최적화를 좀 더 할 수 있음
for문 돌면서 각 디바이스별로 write buffer를 매번 호출하던걸
익스텒션 쓰면
빠르게할 수 있음
매트릭스 곱은 거의 fully parallel인데
32GPU를 써도
스피드업이 5배정도밖에 안나옴
순차실행 포션이 거의 없는데도 그럼
계산에 필요한 정보 디바이스별로 복사하느라
시간이 다지나감
되게 좋네
SnuCL for CPU
디바이스 타입을 CPU로 바꾸면 CPU 클러스터에 계산하는게 됨
사람들은
좋은 벤치마크 코드가 있어야
그걸 보고 움직인다.
이론적으로 좋다보다는
실제로 이걸 돌려보면 더 좋다 가 증명되어야됨
NPB-SER-C
나사에서 CFD라고 해서 유체역학 계산하는 벤치마크 스윗이 있음
그걸 SnuCL로 돌려보자
이정도면
OpenCL 2.0 3.0 만들떄
크로노스 그룹에 이것좀 고려해달라고
제안할 수 있는거 아닌가
<@sgkim> 그거 크로노스에 제안하는게 아니라
<@sgkim> 그냥 익스텐션 문서 써가지고 올리면
<@sgkim> 크로노스가 원하면 가져가고 아니면 익스텐션으로 남고
<@sgkim> 그런 시스템 아닌가
글쿤
벤치마크 해보았다
호스트 제온 CPU*2
계산노드 제온 CPU*2 + GTX 480*4
피지컬 코어가 12개인데
하나는 호스트랑 통신하는데에 예약하고
11개만 계산에 쓰고
나머지 있는 장비를 전부 쉬지않고 돌렸음
SnuCL
다이나믹 스케줄링이 가능해서
미세하게 좀더 빠름
<@wook> 멋잇다
12코어 * 8 노드니까
96코어인데
스피드업이 70
N-Body의 경우는
헤테로지니어스 클러스터에서 정말 유리한테
CPU에서 했을때보다 9500배 빨라짐
<@sgkim> 문학과대중문화 수업에서
Nvidia는
<@sgkim> 영화 향수 가지고
이렇게 GPU에서 잘나오는 결과만
열심히 홍보함
지피유에 했더니 만배 좋아졌어요
<@sgkim> 비윤리적인 행동의 결과로 얻은 예술작품을 예술이라고 할수 있는지
근데 이런식으로 GPU에서만 빨라지는 어플리케이션은
30% 정도밖에 안됨
<@sgkim> 에대한 물음을 하는데
나머지 70%는 어따 하냐
CPU 제온파이
<@sgkim> 뭐 어때 예술작품이라고 해도
FPGA
NBody는 9500배 빨라졌는데
나스 벤치마크는 리소스 왕창 쏟아부었는데
16배밖에 안빨라짐
엔비디아 AMD 이런애들은
이렇게 성능 안나오는 벤치마크는
공개를 안함
우리는 안되는것도 다 이야기를 한다
CPU랑 GPU를 동시에 쓰면
로드밸런싱이 문제
CPU에 1을 주고 GPU에 9를 주면 보통 밸런스가 맞더라
근데 이 비율오
비율도
<@sgkim> 그 CPU랑 GPU가 코어수를 말하는거임?
어플리케이션에 따라 다 다름
에이 설마요
<@wook> adaptive load-aware scheduling 같은거 누가 만들거같은데
<@sgkim> 아니면 일반적인 상용 CPU랑 GPU가 있을때 잡의 수를 말하는거임?
프로세서/디바이스 마다 말하는거 아닐ㄹ까요
퍼포먼스 에스티메이션은 어렵다
클러스터 두개가 있는데
한쪽은 AMD 한쪽은 Nvidia
<@sgkim> adaptive load-aware scheduling은 어떻게 하는거지?
서로 다른 연산능력을 가진 불균형한 클러스텅
터에
일을 어떻게 나눠준다는
Open Question임
이거 어렵지 않다고 막 함부로 논문쓰는놈들 보면 다 거짓말이야
슈퍼컴 전체 노드를
한번에 뿅 하고 사는게 아니라서
풀면 좋은 문제임
프로파일링을 해보면
분산시킬 수 있지
근데 그건 다 계산 끝난 뒤잖아
이번엔
CPU만 있는 클러스터에서 SnuCL을 돌려보자
Collective 커뮤니케이션 vs P2P
P2P 커뮤니케이션은
코어숫자가 250이 넘으면
성능이 급격하게 떨어짐
MPI-fortran vs SnuCL
코어 숫자가 많아지니까 지기 시작함
<@kcm^노예> ㄷㄷ
(SnuCL이 짐)
SnuCL이 지금 오버헤드를 갖고있는 부분이
작은 커널을 아주 잘게 여러번 많이 호출할때
커널 런치하는 코드가 보틀넥임
MPI-fortran은
커널 런치하고 리모트에서 실행하는 과정이 없음
그래서
지금은 이걸 해결한 버전을
소스를 공개한거임
<*> 할거임 아님? [?]
해결 했대유
GPU에서 잘되는 SnuCL 어플리케이션이
<*> ㅇㅇ 해결은 했고
CPU에 돌려도 SnuCL에서 잘됨
<*> 소스를 공개한게 아니고 공개할거라고 [?]
근데 작은 커널을 아주 잘게 호출하는건
그런 일이 아님
데이터 카피가 왔다갔다 엄청 잦거나
메모리액세스가 복잡한 프로그램이
GPU에서 약함
CFD
유체역학
이거 엔비디아 AMD에서 절대 시도도 안함
안되니까
<@kcm^노예> Computational Fluid Dynamics라는 것이 있구나
<@sgkim> 천둥엄마가 공개 안했다고 하는데 천둥아빠가 했다고 하네
<@sgkim> 아빠가 자식에 관심이 없네
걍 말 잘못하신듯
아까 앞에도 아직 릴리즈 안했다고 하셨음
<@Gallen> '평소에 애한테 관심이나 있어?'
히익
<@sgkim> 원래 애아빠들이 애가 몇학년인지도 모르고 그럼
<@sgkim> 입학했던건 기억하는데 벌써 졸업이야?
<@Gallen> '내가 밖에서 놀아?'
<@sgkim> 해결했던건 기억하는데 아직 공개 안했어?
처음엔
AMD반 엔비디아 반 샀다가
AMD께 10배 빠르니까
엔비디아 물건은 사지도않음
영업하는 인간들이
유저가 모른다고
사기를 너무 많이 친다
해도해도 너무하네
숫자로는 더 나은데
직접 써보면 AMD께 훨씬 좋잖아
<@sgkim> 엥? 정말 amd가 엔비디아보다 빠름?
그렇대는데요
<@sgkim> 연산에 한해서만인가?
그럴듯
게임이야 뭐
<@sgkim> 같은 가격으로 놓고봐서 그런가?
그것도 그럴듯
<@sgkim> 같은 라인이 아니라?
<@sgkim> 그럴듯
<@sgkim> 은 천둥엄마에게 물어보면 알겠지
<@sgkim> *:
```
```
다음챕터
컴파일러가 해주지 않는 최적화에 대해 배워보자
<*> 컨텍스트가
<*> 암호 애플리케이션 얘기하던 거 아님 ?
그냥
정부 암드 반 엔비디아 반 샀다가
<*> AMD께 10배 빠르다니까 엔비디아 물건은 사지도않음 의 주어가 있을 거 아냐 [?]
엔비디아 안샀다는 이야기를 하셨는데
정부가
그게 암호 연산이었군
<@kcm^노예> 오오 컴파일러가 해주지 않는 최적화
-O2 켜세요
이런이야기 하심
자주실행되고 일반적인 케이스 먼저 최적화하고
먼저 돌아가게 짜고 후에 최적화하기
파레토의 법칙
20%의 코드가 80%의 실행시간을 먹음
제일 중요하고 제일 좋은 옵티마이징은
알고리즘레벨 최적화
나(교수님)는 코드레벨 최적화의 전문가에요
근데 알고리즘 레벨은
문제 도메인에 관한 지식이 있어야해
LOC가 10k 20k쯤 가면 난 이게 뭔지 몰라
알필요도 없고
Peephole optimization
Local code opt.
Global code opt.
베이직 블락 안에서/넘어서 최적화
Intra procedural
Program level - Inter procedural
링크타임 코드 생성기술
<*> 뭔가 유익한 수업이고 멀티코어 컴퓨팅도 하기는 하지만
컴파일러가 Global code opt (.o 파일 하나)에 대한 최적화임
<*> 수업 제목이 멀티코어 컴퓨팅이 아니어야 할 거 같군[?]
제일 중요한것
<@wook> JJLee 201
<*> Computing on Modern Architectures 같은 느낌의 수업이네
<@wook> !
최적화 한 결과가 원래 프로그램과 같은 시맨틱을 유지해야함
Basic Block이란?
실행이 끊기지 않는 statement들의 묶음
Basic block 찾는법
첫번쨰 명령어를 찾고 leader라고 정의함
브랜치의 타겟이 되는 놈도 leader
conditional/unconditional jump 바로 다음에 오는놈도 leader
그리고 leader와 leader의 사이를 블락으로 정의함
Control Flow Graph!
<@sgkim> 오오 컴파일러시간에 했던거다
<@sgkim> 내가 컴파일러 플젝에 저거 구현하려다 망했는데
unused variable 찾기
언유
register allocation
Data flow analysis
Constant folding
Constant propagation
<@sgkim> 마지막 2개 뭐지?
a = 4 + 2 + 8 + constant_variable; 이런거 미리 계산시키는게  콘스턴트 폴딩
x = 24; x += 24; 이런거 x = 48 이렇게 상수 추적해서 퍼트리는게
프로페게이션
<@sgkim> 오호 2개가 이름이 달랐군
<@sgkim> 감사
<@kcm^노예> 자주 쓰는 컴파일러들 저런 기본적인 추론을 참 잘하던데..
<@sgkim> 하지만 브랜치 들어가면 다 깨지고
<@kcm^노예> 으헝헝 ㅠㅠ
constexpr (?)
<*> x = 24; x = x + 24; ==(constant propagation)==> x = 24; x = 24 + 24; ==(constant folding)==> x = 24; x = 48;
캬
훌륭한 g 조교님
<*> 낫미
PPT엔 좀 모호하게 쓰여있었는데
지금
<*> 저는 조교가 아니에요
<*> 여러분들의 조교는 군대에 갈 거랍니다
<*> [?]
pthread OpenCL SnuCL OpenMP MPI
죄다 체험학습하게 생겼군
OpenACC 안나와서 다행이다
여러분이 배우지 않은 개념이
함수형에서 나온
future라는 개념이 있는데
>> 아무도 안써요 <<
<@lambdaChan> <hint>:1:11:
<@lambdaChan>     parse error (possibly incorrect indentation or mismatched brackets)
여러분 몰라도 돼
아무도 안씁니다
쓸데없는데에 시간낭비하는거야
"그거 알아도 아무 쓰잘뗴기 없어"
내가 한군데도 쓰는거 본적이 없어
X10
<@kcm^노예> 무러ㅏ고요
<@kcm^노예> future 아무도 안 쓴다고요?
IBM에서 만든 페러렐 랭귀지인데
그것도 썬한테 주고 해서 랭귀지 만들었는데
아무도 그 세개 만든거 쓰는사람이 없어
IBM X10은 약간 쓸라고도 하는데
<@sgkim> 뭐여
썬하고 크레이한테 준건
돈낭비한거야
<@sgkim> 이재진교수님 이상한 사람이네
<@kcm^노예> future 안 쓴다고 한 건 망했
만들어놔봤자 쓰는사람도 없고
그걸 왜하냐고
빨리
<@sgkim> 내가 아는 퓨처랑 다른거겠지
쓰는 근거를 대주세요
수업이 끝나기 전에
<@sgkim> 전에도 말했지만
반박으
프로그래밍 이디엄 말고
병렬화 모델
<@sgkim> 병렬화모델은
<@sgkim> 퓨쳐쓴다고 오버헤드가 없으니까
<@sgkim> 근데 가독성이 오히려 뛰어나고 앱스트랙션도 뛰어나니까
<@sgkim> 그냥 쓰는거지
<@sgkim> 사실 제로오버헤드는 거짓말이지만
<*> 스칼라 누가씀? <- 도발
컴파일링 병렬화
컴파일링은 나눠서 하면 되는데
링크는 좀 힘들어요
머지소트하듯이 분할정복하면 좀 되긴함
<@sgkim> 사실 제로오버헤드는 아니라서
<@sgkim> 병렬화지점이 바틀넥이 되거나 단순히 쓰레드풀정도 쓰는걸로 만족할 수 없다면
<@sgkim> 안 쓰는게 맞지
```

Optimization
--------
* 자주 실행되고, average case부터 먼저 최적화해야됨
* Production compilers

--------

> 5월 18일

OpenMP
========
이재진교수님 대신
gw형이 들어옴
필기한다
이재진 교수님께서 출자을 가셨어요
일요일 오후 8시에 수업을 하기는 싫죠?
OpenMP MPI

Pthread OpenMP는
셰어드 메모리 모델
MPI는
독립적인 주소공간에서 쓰는 모델

Process가 뭐에요
하나의 단일 버추얼 메모리를 가지는 단위를 프로세스라고 부르죠
OpenMP는 하나의 프로세스 안에서 여러개의 스레드

OpenMP
쉽게 병렬화 하자
3.0 -> 4.0의 차이
GPU도 지원하자
OpenACC
최종적인 목표
나중에 OpenMP의 스펙에
OpenACC을 포함시키는게 목표였다
근데 잘 안돼서
OpenMP 4.0에 이르러서는
완전히 갈라서
완전히 갈라섬
OpenMP 실행 모델
fork / join 모델을 따름
Preforked thread
코어 숫자만큼 스레드를 만들어둠.

`#pragma omp ~`

gcc의 경우 `-fopenmp` 옵션을 넣어줘야됨.

이 코드에
디펜던스가 있냐 없냐
판별하는 문제가 엄청 어렵다
ZIV SIV
30년전부터
아직까지도 엄청 심플한 loop 안에서만 되고 그렇다
프로그래머가 잘 가이드를 해줘야됨
지금 여러분들이 gcc 쓰는거에도
컴파일러가 자동 병렬화 해주는 옵션이 있긴 하다
간단한 포문 쓰고 디펜던스가 없으면 병렬화가 된다
근데 약간만 코드가 길어지고
안에서 함수호출이라도 하면
컴파일러가 지레 겁먹고 시퀀셜로 돌려버린다
이 #pragma omp 붙이는거 좀 자동으로 해주면 안되냐
어려운 문제임

```
#ifdef _OPENMP
#include <omp.h>
#endif
```

### Hello World in OpenMP
```
블라블라
```

preforked thread 수는 코어 수랑 항상 같아야한다?

항상 그렇지는 않다. 로지컬 코어 수랑 맞출것인지, 피지컬 코어 수랑 맞출것인지도
고민해야함. (하이퍼 스레딩이 후지게 만들어져있다던가..) 아니면 메모리 대역폭에
한계가 있으면 딱 그만큼만 만드는게 이득, 아니면 스레드 하나당 데이터를 4메가
쓰는데 L3캐쉬가 24MB다 이러면 자제한다던가 이런 최적화를 해줘야됨.

변수에 `#pragma omp private(var)` 걸면, 그 변수는 스레드들마다 shared 되지 않고
각각 따로 가지며, 병렬화되는 부분으로 들어가면 그 변수가 원래 갖던 값은 다
날아감. 나갈때도 다 날아감.

### if/private/shared clauses
1.  `if`: 이게 참이면 병렬로 하고, 거짓이면 시리얼로 실행하라
2.  `private`
3.  `shared`
4.  `firstprivate`: 병렬화 부분 밖에 있던 변수의 값을 병렬화 부분 안으로 가져올 수
    있음.
5.  `lastprivate`

### Work Sharing Constructs
스레드마다 다른 코드를 실행하고싶다.

### Loop Construct
컴파일러에서 분석할 수 있는 단순한 for문의 경우, for문의 각 이터레이션이 병렬로
돌도록 자동으로 분석해줌.

```c
#pragma omp parallel
{
  #pragma omp for
  for () {
    /* ... */
  }
}
```
```c
#pragma omp parallel for
{
  for () {
    /* ... */
  }
}
```

### `nowait`
워크셰어링 컨스트럭트들은 끝나는 부분에 배리어가 들어감. 예시로 주어진
코드의경우 포문 맨 뒤에 스레드들이 모두 끝나는걸 기다리는 실행이 하나
들어가는데, 일찍 끝난 스레드는 옆 스레드 안기다리고 다음실행으로 바로 넘어가도
상관 없을경우에는 `#pragma omp for nowait`를 넣어주면 바로 넘어감.

### Thread Scheduling Clause
정적 스케줄링, 다이나믹 스케줄링
```
schedule(static [, chunk_size])
schedule(dynamic [, chunk_size])
```
이론적으로는 다이나믹 스케줄링이 제일 좋지만, 작업을 계속 나눠주는 오버헤드가
있음. 청크사이즈로 이걸 줄일 수 있음.
```
schedule(guided [, chunk_size])
```
처음에는 청크를 1000개 넘기고, 다음엔 100개만 주고, 다음엔 30개만 주고, 등등
OpenMP가 이를 알아서 해줌. 알고리즘이 복잡함
```
schedule(auto)
```
니가가라 하와이

### Sections Construct
Non-iterative work-sharing construct. 태스크 페러렐리즘.

### Single Construct
쓰레드중에 아무나 한녀석만 골라서 걔만 실행하도록 한다.
```c
#pragma omp parallel
{
  #pragma omp single
  {
    /* ... */
  }
}
```
디버그를 한다, 프린트를 한다, 파일에 쓴다, 등...


### 질문
Q: 왜 디폴트가 스태틱 스케줄링?

for문 안에서 도는 인스트럭션 숫자에 따라 다르다.

Q: OpenMP 옵션을 켜서 빌드한 프로그램은 항상 백그라운드로 워커 스레드가
자고있나?

그건 OpenMP 마음. 언제 나타나고 언제 사라지는가는 조절할 수 없다.

Q: 우리는 3.0 배운거져?

네. 사실 거의 대부분 1.0 2.0 기능들임.

--------

> 5월 20일

```
지현	OpenMP 누가 만든건지 알아요?
p	자유방임
지현	내 지도교수가 만든거야.
지현	크레이 포트란 만들어서
지현	OpenMP가 그게 근간이 됐어
지현	2008년도에 우리학교도 왔어
지현	느이들은 모르겠지
지현	지난 수업 다 잘 이해 됐어요?
지현	모르는거 있음 물어봐
지현	그분 나이가 65.. 넘었구나
지현	67정도
지현	미국은 마음대로 정년퇴임 할 수 있어요
지현	100살까지 해도 돼
지현	근데 부끄러워서 그냥 퇴임해
지현	일을 안하니까
지현	물가인상률이 3프로 된다 하면
지현	월급을 안올려주는데
지현	물가가 오르니까
지현	그러면 월급이 점점 깎이는거랑 똑같지
지현	미국은 학과장 파워가 쎼지
지현	근데 우리학교는 안그래
지현	돌아가면서 하니까
지현	미국에서 제일 월급 잘받는 연구분야가 어디겠어요?
지현	우리나라는 다 똑같애
지현	미국은 분야별로 다 월급이 다르지
지현	제일 못받는데가 영문학
지현	그 다음이 음악
지현	고등학교 교사보다 교수가 월급이 적어
지현	내가 그때 받을떄가 9만불정도 받았는데
Gallen	히이
Gallen	9만불...!
p	나도 9만불 받고 싶다
지현	MIT에선
**	지금보다 더 많이 받으시는군
지현	데이터베이스를
지현	CS로 생각 안해.
지현	근데 스탠퍼드는 DB 되게 쎼거든
**	하지만 주식투자를 했다가 닷컴버블때 다 날리셨다고 합니다 [?]
지현	MIT엔 그래픽스도 없어
지현	근데 스탠퍼드는 그래픽스도 쎼거든
지현	학교별로 다 특색이 있어
Gallen	앗 그의 정치적으로 민감한 이야기...!
지현	마찬가지로
Gallen	정치적 까지는 아닌가
Gallen	꿀잼이다 여하튼
지현	하버드엔 음악이 없고
지현	음악사밖에 없지
지현	음악으로 박사를 받는다는게
지현	기준을 내릴 수 있나?
지현	비틀즈가 박사학위 받았나?
지현	작곡은 이론이라 할게 많을 수 있지
지현	피아노같은거를 박사를 받는다 이러면
p	주식ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
지현	음악사로 받아야지 퍼포먼스로 받을 수가 없어
지현	근데 우리는 다 줘
지현	계량화 하는걸 참 좋아하지
지현	점수로 사람 능력을 평가할 수 있나?
지현	여러분 중간고사 점수로 내가 여러분 평생을 좌우하도록 한번 만들어봐?
지현	1점 차이가 뭐그래 중요한데?
지현	학점 1.7하고 4.3하고 뭐가 그래 차이나나
지현	하나도 차이가 없다 이말이야
지현	자꾸 그런걸 너무 좋아해
지현	그렇게 만들면 객관적이고 공평하다고 생각하지
지현	그렇지 않아
p	차이나는거 같아여...(?)
지현	그걸로 메져해서 뭐해
지현	학점하고 연구하고는 별로 상관이 없어요
지현	그게 참 웃기는거야
지현	점수로 사람을 평가한다는게
지현	학점이 높으면 성실성이 담보가 되긴 하지
지현	성실하면 점수는 잘 나오니까
지현	학점이 모지란사람들은
지현	내가 멍청한게 아니라
지현	내가 불성실했다고 생각하면 되지
Gallen	저는 이다지도 불성실했군요
Gallen	교수님 ㅠㅠㅠㅠ
지현	OpenMP쪽에 질문 없어요?
지현	OpenCL 은 어렵다고 생각하지 말고
지현	기계적으로 해줘야하는 작업이 많다고 생각해
지현	OpenCL은 최적화의 여지가 더 많지
지현	ease of programming과 고성능은 tradeoff관계에 있지
지현	둘다 쉽게 만들어야지
지현	Rust!
지현	방금 순간
지현	ease하고 빠른 프로그래밍 모델
지현	잘나온건 하나밖에 없죠? 라고 물어보셔서
지현	Rust 라고 대답할뻔
지현	SnuCL (?)
지현	아이패드가 여러분을 기다리고있어
지현	신경좀 써봐
**	아이패드...????
**	아 플젝 1등 상품으로 아이패드 줌?
지현	네
지현	HEVC
지현	HEVC가 왜 필요해요?
지현	(나) 해상도도 더 높고 컬러뎁스도 더 높은 영상이 보고싶어서요
지현	앞으로 티비가 UHD로 표준화될거니까 하는거지?
지현	그거 디코더로 OpenCL을 쓰는데
지현	스마트 티비 안에 하드웨어로 디코딩하는 코덱을 넣고있어요
지현	근데 아직까지 실시간 성능이 안나온다고
지현	그래서 나한테 물어봐서
지현	하드웨어 코덱이랑 CPU를 같이써봐라 고 대답했지
지현	근데 아직 걔네 스마트티비가
지현	CPU랑 하드웨어 코덱을 통합해서 쓰는 환경이 없어
지현	그래서 로드밸런싱을 하드웨어랑 CPU에 동시에 못하고있지
지현	하면 성능이 더 나오지 않겠느냐 하고 전화를 끊었는데
sgkim	계산화학실습왔는데
sgkim	ssh 클라이언트있어서 좋아라했는데
지현	OpenMP 4.0
지현	강원이가 OpenMP 스탠더드에 관한 이야기를 해줬어요?
sgkim	인코딩 설정이 안 된다
지현	OpenMP OpenACC
지현	OpenMP는 국립연구소에서 보통 밀어요
지현	로스알람머스에서 뭐했어요
지현	맨하탄 프로젝트했잖아
지현	원자탄 만들었잖아
지현	얘네가 지금 원폭실험 할수 있어요 없어요
지현	없어
지현	금지됐어
지현	북한으 ㄴ하겠지
지현	시뮬레이션 하겠찌
지현	컴퓨터로 하는데 계산이 워낙 많이 필요해서
지현	얘네들이 OpenMP를 자신의 필요에 의해 리드를 해요
지현	그리고 얘네들이 리드한 기술이 밑으로 내려와서 핸드폰에 들어가고 하는거지
지현	그래서 OpenCL을 쓰는거야
지현	CUDA는 못써
지현	컴패터빌리티때문에
지현	싸움을 시작하면
지현	죽여야지
**	ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
지현	CUDA를 쓸라면
지현	암드가 완전히 망하던가
지현	아니면 엔비디아가 완전히 망하던가
지현	해야돼
지현	캐드 어때
지현	오토캐드를 그냥 뿌리잖아
지현	해서 학생들은 너도나도 오토캐드를 쓰지
지현	그리고 그사람들이 전부 회사로 올라가면
지현	오토캐드 경쟁품을 못쓰지
지현	OpenACC도 똑같아
지현	OpenMP가 평정해버렸어
지현	옛날부터 온갖회사가 다 저기로 들어가있었지
지현	OpenACC는 고사할거야
지현	OpenMP 4.0 내가 어제 디렉티브를 들여다봤는데
지현	너무 복잡해졌어
지현	간단한게 OpenMP의 특색이었는데
지현	특히 문귀환이 같은 애들한텐 안좋을거야
지현	복잡하면
**	ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
지현	(문) 네
지현	얘네는 아직 싸우는 중이야
지현	근데 아마 OpenMP가 이길거에요
지현	커뮤니티의 차이때문에
p	ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
지현	내가 OpenMP 4.0을 SnuCL로 트랜슬레이션 하는 계획을 한번 잡았었는데
지현	아니 실수
지현	OpenACC를 SnuCL로 트랜슬레이션 할라그랬는데
지현	이 히스토리를 보고
지현	OpenMP로 방향성을 바꿨어
지현	역사를 배워야하는 이유가 뭐에요
지현	(나) 같은 실수를 반복하지 않기 위해서요
지현	같은 실수를 반복한적 있나?
지현	(나) 많아요
지현	과거로부터 배우기 때문이지
지현	쉅시작
지현	워크셰어링 컨스트럭 배웠어요?
지현	패러렐 뽀
지현	패러렐 쎅쎤
지현	임플리싯 배리어
지현	노웨이트
지현	OpenMP도 메모리 컨시스턴시 문제가 읶어요
지현	패러렐 섹션이 끝나는 부분에서
지현	여기서 배리어를 쳐줘야되는데
지현	노웨이트 하면 배리어 없으면 그냥 내려가지
지현	그러면 메모리가 업데이트 안되어있겠지
지현	스펙에 있는 시맨틱이 그래
지현	고런거 코딩할때 주의해야지
지현	스레드 스케줄링 디폴트가 뭐에요?
지현	스태틱 스케줄링이지
지현	사이클릭 스케줄링도 있고
지현	청크 스케줄링도 있고
지현	갱 스케줄링도 있지
지현	갱 스케줄링은 20년전에 나온 방법인데
sgkim	화실 수업왔는데
sgkim	조교님이 귀여운데 목소리가 작다
sgkim	그래서 뭐라고 하는지 모르겠어서 안 들음
지현	조교가 나가토를 닮았나보군
지현	오
지현	OpenMP
지현	다른 기능은 다 시큰둥했는데
지현	Reduction은 굉장히 편하겠다
지현	인텔 실크
Gallen	앗 버그 못잡고 있었는데
Gallen	잡히겠다
Gallen	><
지현	https://software.intel.com/en-us/intel-cilk-plus
지현	><
Gallen	출근한 지 6시간 반만에 ><
Gallen	쥐잡는 냥이가 된 기분이군
지현	찤
지현	스레드풀을
지현	윈도우는
지현	스레드풀을 OS에서 제공하는데
지현	리눅스는 그런거 없나
지현	yield가 모야
sgkim	없을걸
지현	호혿
sgkim	근데 윈도우 스레드풀은 뭘 더 해줌?
지현	그냥 스레드풀을 줘요
지현	뭔가 더 해주는게 있나
지현	윈도우 7 기준으론 특별한거 없었던거같은데
지현	어떻게 보면 라이브러리임
지현	https://msdn.microsoft.com/ko-kr/library/windows/desktop/ms686766(v=vs.85).aspx
sgkim	스레드풀이라는 개념이 막 내 손으로 스레드만들고 이런 수준에서 필요한 게념인가?
sgkim	태스크같은 개념이 들어가야 필요해지는거 아닌가?
지현	그렇죠
sgkim	그러면 피쓰레드에 없는거 맞을듯
지현	ㅇㅅㅇ
지현	헐
지현	원래 OpenMP가 어디에 정의되었겠어요?
지현	(나) 포트란이요
지현	원래 MPI가 어디에 정의되었겠어요?
지현	(나) 포트란이요
지현	내가 스탠퍼드에서 가서 처음 한일이
지현	포트란으로 만들어진걸 C++로 래핑하는거였어요
지현	쉬웠을거같아요 어려웠을거같아요?
지현	(나) 짜증났을것같아요
지현	래퍼에서
지현	포트란이랑 C++이랑
지현	메모리 레이아웃 맞춰주고
지현	죽도록 테스트하고 그랬지
지현	또 MPI가 그때는 처음 나온지 얼마 안돼서
지현	사람들이 많이 쓸라고 하는 그런 순간이었고
지현	PVM이라고 들어봤어요?
지현	http://en.wikipedia.org/wiki/Parallel_Virtual_Machine
지현	이건 완전히 죽고 MPI만 남아있는거죠
지현	MPI는 de facto std에요
지현	노드 안에선 OpenMP를 쓰고
지현	노드간 통신을 할떄엔 MPI를 쓰지
지현	OpenCL도 마찬가지지
지현	OpenMP를 SnuCL처럼 만들면 어떨거같아요?
지현	(나) 너무 추상화레벨이 높아서 별로일것같아요
지현	누가 시도를 해봤는데
지현	프랙티컬하게 쓸 수 없어
지현	하지만 SunCL은 프랙티컬하게 쓸 수 있지
지현	여러부
지현	이 프로그램 안에 버그없는거 증명할 수 없는거
지현	이 프로그램 안에 버그 없는거 증명하는문제
지현	언디사이디드 문제이지
지현	pthread OpenMP SnuCL 이런거 다 갖고
지현	한학기를 가르칠수 있어
지현	C만 갖고도 한학기 수업을 할 수 있지
지현	문귀환이
지현	하드 트롤링 시전
지현	앞에
지현	락 언락 상호배제 다나왔는데
지현	갑자기 뮤텍스 없냐고 물어봄
지현	자다가 봉창두들기는 소리하네라고 하심
**	ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
wook	;;;
wook	계피 말고 시나몬
지현	이건
지현	록언록을 익스플리싯하게 쓰는게 아니라서
지현	데드락을 걱정 안해도 돼
지현	sdfasdfjlskdafjsd
지현	문이
지현	자꾸 이상한
지현	소리함
지현	아토믹 쓰면
지현	느려진다니까?
지현	이재진교수님 차근차근 대답하심
**	모든걸 atomic쓰면
**	안전하니까 좋다
**	같은 얘기라도 했나 [?]
지현	...
지현	지금 무슨얘기 하고있는건지
지현	모르겠다
지현	OpenMP Memory Consistency
sgkim	록언록 익스플리싯하게 안 써서 데드락 걱정 안해도 되는간 무슨 말임?
지현	OpenMP 메모리 컨시스턴시가 왜 중요하겠어요?
지현	내 박사논문이거든
지현	오오
지현	OpenMP로 프로듀서 컨슈머 구현
**	내가 교수님 박사논문을 다 읽었지
지현	캬
지현	교수님마스터
지현	교수라이브
지현	빌트인펑션 있는거
지현	봤어요 안봤어요
지현	(나) 있다고 말만해주고 보진 않았어요
지현	그럼 오늘도 말만 할게
지현	알테라 FPGA
지현	거긴 원래 하드웨어하던애들이 있는곳이고
지현	몇안되는 소프트웨어 하는애들도
지현	거길 떠나서
지현	완전 엉망이야
지현	그래서 우근이가 훨씬 좋은걸 만들어서 내놓을거야
지현	내가 알테라에서 나온 논문을 세번을 리젝시켰어
지현	논문이 아냐 논문이 아냐
지현	FPGA가 워낙 희귀한 파트라서 내가 웬만하면 엔커리지 시켜줄려고
지현	웬만하면 통과시켜주는데
지현	시원찮은부분이 너무 많아서 막 숨긴것도 너무 많고
지현	그래서 좋은 FPGA 솔루션이 10월에 나와
**	(도망)
지현	FPGA의 장점이 뭐에요
지현	FPGA 는 저전력 달성이 쉬워요
지현	회로를 커스터마이즈해서 소프트웨어를 하드웨어로 만드는게 되게 빠르지
지현	페치 디코드 익스큐트가 없지
지현	칩과 CPU의 중간쯤으로 보면 되지
지현	우리나라는
지현	너무 전기값이 싸서
지현	사실 FPGA가 큰 문제가 안돼
지현	산업전기가
지현	미친듯이 싸
지현	우리나라같은데가 없어요
지현	지금 알테라 솔루션은
지현	범용 프로그래밍이 안돼
지현	사람이 손댈부분도 너무 많아
지현	힌팅해야돼고
지현	그런게 극복이 되면
지현	FPGA는 널리 쓰일텐데
지현	미국같으면
지현	주식 트레이딩하는데에 FPGA 써
지현	우리나라에선 쓰겠어 안쓰겠어
지현	코스콤에서 그런 솔루션을 만들어서 배포를 하는데
지현	걔들은 FPGA 쓰고싶어해
지현	근데 왜 못쓸까
지현	전문인력이 없어서
지현	미국엔 차고널린게 그거하는사람인데
지현	저기 코스콤같은데가
지현	신의 직장이야
지현	적장이 나도 월급이 엄청나게 나오지
지현	내가 걔네 직장으로는 나쁘게 보지 않아
지현	연구 업계 물을 흐리는게 문제야
지현	300억 갔다가 슈퍼컴을 못만들었어
지현	내가 그거 생각할때마다 가슴이 아파
지현	ADD 애틀리 다 처음 생겼을땐 훌륭한곳이었지
지현	왜 우리는 쇼를 해야되냐 이거야
지현	아무것도 없으면서 겉만 번지르르하게 해서
지현	다른것도 있어
지현	공무원들 일 벌여놓고 성과가 났냐 안났냐
지현	확인을 안해요
지현	100억짜리 프로젝트 담당 공무원이 실행했다
**	지현: 에트리
지현	그러면 그 공무원은 프로젝트 끝날때엔 거기에 없어
지현	순환보직이라서
**	나는 로그에서 에틀리라고 할때마다 가슴이 아픔[?]
지현	그런 성과 체크가 잘 되겠어요 안되겠어요
지현	묶어놓을라면 거기 가라그랬잖아
지현	직장으로썬 좋아
지현	KT 간 친구 얘기 들어보니까
지현	도저히 미안해서 월급을 못받겠대
지현	아무것도 안했는데 월급을 줘서
kcm	FPGA로 비트코인 마이닝하고 싶다 -
지현	KT SKT 다그래요
지현	우리나라에선 거기서 연구 안해
지현	다 뭐하겠어
지현	연구를 안하고
지현	아웃소싱을 해요
지현	아웃소싱할려면 뭘해야돼
지현	일 한걸 체크를 할 수 있어야돼
지현	그래서 거기서 박사가 필요한거야
지현	우리나라에서 연구한건 거의 ㅇ벗어
지현	내가 제대로 한거 본건 그거야
지현	양자 통신
지현	SK에서 열심히하고있죠
지현	여러분 선배 거기 가있어
지현	보면 잘해
지현	그건 뭔가 성과가 나올거야
지현	아주 선택 잘한거야 그거 SK에서
지현	결국 연구가 되냐 안되냐고 사람이야
지현	아무나 가서 되는게 아니니까
지현	내가 하고싶은말은 그거야
지현	너 컴퓨터 그래픽스 하고싶다그랬지
지현	컴퓨터그래픽스 하면 여거 필요해
지현	기초가 탄탄해야지
지현	그런 기초가 든든한사람이 여러곳에 가서 일을 해야
지현	사회가 발전해
지현	R&D 혁신방안이 곧 나와요
kcm	왠지 곧 게임을 깔 것 같다
지현	그게 주된 포커스가
지현	출연량
지현	애트리같은애들을 어떻게 깔것이냐
**	><
지현	1700명이 6000억이라는 무시무시한 돈을 갖고 연구를 하는데
지현	성과가 안나와
지현	미국 학교에서 하는 연구가
지현	정부연구비의 30%야
지현	우리나라는?
지현	10%.
지현	자.
지현	국방은 비밀이라 카운트가 안돼
지현	국방까지 포함하면 훨씬 많겠지
지현	5%
지현	학교는 몇명?
지현	전체 박사과정있는애들 쳐봐
지현	5만명 할거야
지현	그정도는 안되나?
지현	만명이라고 치자
지현	애트리는 단일 기관.
지현	1800명이 6000억을 가져가지
지현	우리는 2000억을 만명이 나눠.
지현	말이 안돼는거야
지현	그 이야기를 내가 기회가 있을때마다 떠들고있는데
지현	안좋은게 뭐라그랬어요?
지현	나는
지현	애트리같은사람들의
지현	공적이 되는거야
지현	하지만 내가
지현	우리나라를 위해 할 임무가
지현	바로 이런거 바로잡는거야
지현	내가 이렇게 공적이 되어버리면
지현	우리학생들이 고생할 수 있어
지현	아 이재진교수 학생이야? 넌 안뽑아
wook	ㅠㅠ
지현	하지만 어쩔수없어
지현	어차피 난 우리애들 그런데 보낼생각없어
Gallen	에틀맄ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
지현	사실 지금도 우리애들 보내달라는말 많이해
지현	안돼 돌아가
Gallen	엌ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
지현	이야
지현	오늘 아주
지현	로그가 풍작이구만
지현	훈훈
```

### Reduction
알아서 Reduction 코드를 만들어줌

### Task Construct
재귀적인 Task 정의가 가능함

### Taskyield Construct
### Master Construct
고정된 하나의 스레드가 이걸 실행함

single은 배리어가 있고, master는 배리어가 없음.

### Barrier Construct
### Taskwait Construct
### Atomic Construct
### Ordered Construct
코드를 순서대로 실행하겠다는 소리지. 이건 패러렐로 돌리는 의미가 없어요.
병렬코드 사이에 넣어야돼서 있는거야.

OpenMP Memory Consistency
--------
메모리 컨시스턴시가 어떤 문제에 대해 대답하는거에요?

**내가 업데이트한 메모리를 누가 언제 보겠느냐.**

### Flush Construct
이재진교수님 박사논문

### Environment Variables

--------

> 5월 27일

MPI
--------
Message Passing Interface

조강원 박사가 대신 수업

Shared Memory Model, SMP가 아닌것.

80년대까지만 해도 슈퍼컴퓨터라고 하면, SMP이고 벡터프로세스이고 이런것들이었음.
90년대까지도 벡터프로세서를 썼음. 후지쯔, NC같은 일본회사들이 이걸 잘했음.
90년대까지 기술적으로 앞서나가있던 슈퍼컴들을 많이 만들었음.

2000년대에 들어오면서 벡터 Width를 늘리는걸로 성능을 올릴 수 없는 벽에 부딛침.

대안: MPP. 각 프로세서마다 별도의 메모리공간을 줌. 프로세서마다 OS도 따로돌고
등등 그럼. 우리가 기존에 갖던 프로그래밍 모델로는 이걸 구현할 수 없음. 그래서
만들어진것이 MPI

90년대에 벡터프로세서 만들던 일본회사들 다 망했음. 슈퍼컴퓨터는 원래
돈많은나라가 잘하게 되어있다. 연구하는데에도 돈이 많이들고, 사는데에도 돈이 많이
듬. 원래 전통적으로 이거 잘하던나라는 미국이랑 일본이었음. 미국은 90년대에 이미
MPP, 클러스터로 갈아탐. 처음 클러스터 만든 회사들 다 미국임. 평범한 데스크톱
PC를 붙여서 네트워크로 붙여서 Beowulf 클러스터를 만듬.

베오울프의 전설. 힘이 성인 남성 30명에 육박하는 괴물. 역설적으로 말하면, 평범한 사람
30명이면 베오울프와 대등하고 60명이면 괴물에 대적할 수 있음. 그런 취지로 이런
이름이 붙음.

버클리에서 만든 것. NOW: 네트워크 오브 워크스테이션.

일본은 여기에 전혀 준비가 되지 않았고, 전부다 사라짐. 그리고 10년동안 미국이 탑
500을 차지하다가, 최근 중국이 올라감. 중국은 미국이 적국인 관계로,
Tianhe-2. 인텔 제온파이랑 팬티엄4랑, GPU를 사서 만든 슈퍼컴. 성능이 33PF. 그리고
이걸 성능을 100PF로 올리려고 그랬더니, 미국이 CPU 수출을 막았음. 그래서 중국은
인터커넥션 네트워크를 자체적으로 만들었고, CPU도 성능이 중요하지 않은 부분에선
다 자체 CPU 만들고있음. 언젠가 미국에서 막아도 슈퍼컴을 자급자족할거임.

교수님께서도 수업시간에 이런저런 잡담을 많이 하시는데, 여러분들한테 어떻게
기술들이 흘러가고있나를 알려주기 위해서 하는 이야기가 아닌가 싶습니다.

### MPI

--------

> 6월 1일

병렬프로그래밍 할 주 알면 나가서 무시받지 않는다.

### 애트리
누가 애트리가 1000명이서 3000억 나눠먹었죠 이러니까 교수님이,

> 정확히 기억해.
> 2000명이서 6000억이야.

### 최양희 교수님
최양희교수님 칭찬하시는중.
옆방이라시네.
R&D 개선방안 이런거 내놓으면서,
연구비도둑들 물리치고 불쌍한 대학원생들 월급 올려준다고
하면서,
이미 월급 많이받는 핏짱한테
너 호사스럽게 산다고
그러심.
최양희교수님이 신조가 있는 사람이라고
지켜보면 뭔가 할거라고 말씀하심.
그리고 미래부가 뉴스에 안나온다고
좋아하심.
뉴스에 나오면 뭔가 잘못된거라고.

### 데드락
데드락 체크하는 소프트웨어를 만들었다그러면 거짓말이야
이건 기본적으로 비결정적인 문제라서

### 더블버퍼링
OpenCL과 MPI로 하는 더블버퍼링이란?

말 그대로.
예를 들면 OpenCL같으면
buffer A랑 B를 만들어서
A의 데이터로 NDRangeKernel할 동안 B에다가는 WriteBuffer하고
다시 B의 데이터로 NDRangeKernel할 동안 A에다가 WriteBuffer하고.
실로 그러하다.

### 물바다
이재진교수님이 네트워크 수업을 들었었는데,
프로그래밍 70프로 중간15프로 기말15프로였는데,
중간고사 보러갈때
화재경보기때문에 시험장이 물바다가 되어서
프로그래밍 70프로 기말 30프로로 변한 이야기를
해주셨다.

### 초보자
초보자일수록
책 내용 구석에 있는 내용을
잘 알아요.
초보자일수록 기성품을 많이써요.

### 마이크로 컨트롤
사람 손으로 자 대고 줄그었을때
낼 수 있는 정밀도의 한계가 몇일까요?
내가 할 수 있는게
50미크론까지 해봤어.
0.05mm

### 고무동력기
거기에 고무동력기의 모든것이 녹아들어있어.
과학의 원리를 떠나서 그게 공학이에요 공학.
프로그래밍 하는것도 마찬가지잖아.
이 프로그래밍을 이 시간 안에 돌아가는걸 만들어라,
컨스트레인트를 주고 할 수 있는걸 고민하는거지.
방법은 뭘까,
재료는 뭘 쓰면 좋을까,
프로세서를 몇개를 써야할까,
똑같은거에요.
나는
카본을 써요 카본.
그러면 나무로하는것보다 좀더 프로페셔널하게 보이지.

### 안식년
안식년인데
안식 못해.
2주는 미국있고 한달은 한국있고
죽도록 연구해야돼.

--------

> 6월 3일

경험 없이 입으로만 한건 다 그짓말이야
정말이야 앞으로 경험을 많이 해봐요
해본거랑 안해본거는 천지차이기때문에

Optimization III
--------
### Induction Variables

내가 6개월동안 해서
학부 졸업논문으로 뉴럴넷을 했어
공부 오래했어요
근데 내가 이걸 교수앞에서 발표하는데
안믿어
근데 일본에서 교수가 와서
내가한거랑 똑같은 발표를 하는데
믿는거야
학부학생도 오랫동안 공부하면 얼마든지 할 수 있어요
사람들은 딥러닝이 두번의 브레이크쓰루가 있었다고 하는데
내가보기엔 별것도 아닌거같애
그냥 이미 다 있던게 컴퓨팅파워가 늘어나면서 가능해진거지
구글이나 페이스북 뒤에 뭐가있겠어요
벨크로가 뭔지 알아요
찍찍이 있잖아
구글 서버 farm에는
메모리를 하도 자주갈아주니까
메모리가 벨크로로 붙어있어요
아키텍츠들이 인텔에서 구글로 굉장히 많이 옮겼어요
안보이지만 그런것들 지식이 필요하단말야
근데 우린 표면만 보잖아
빅데이타 이러면서
특히 저 높이있는 공무원들
그런 것들을 갔다가 여러분들이 생각을 좀 해야돼
패러렐프로세싱 이거 굉장히 중요한 기초기술이야
내가 그얘기 했나요
생물정보학쪽 시스템이 엉망이라고
코빅한번 들어가보세요
우리나라 생물정보학 국가센터라는데
내가 그거보고 실망을 금치 못했어
ㅇ자기가 갖고있는 웹서버가 500대가 있대
걔네가 왜 웹서버가 500대가 필요해?
소통도 안돼고
존중하는 마음이 있어야돼요
모든 학문이 중요하다
제일 건방진놈들이 누군지 알아?
물리하는 놈들
애로건트 phㅣ지시스트라고 해서
물리애들한테 물어보면
뭐든지 다 할 수 있어
물리교수가
나한테 컴파일러 강의를 하더라고
물리교수인데 말야
내가 컴파일러 전공이 모르고한거긴한데
한시간동안 수업을 하더라
우리쪽에 보면 미국도 그런게있긴 있는데
비전공자를 위한 물리학
비전공자를 위한 컴퓨터사이언스
이런수업 다 없애버려야돼
비전공 전공한테 왜 다른걸 가르쳐야돼?
똑같이 들어서 똑같이 들어서 깨쳐야돼요
공부하면 돼
자기전공 아니면 뭔상관이요
전공하는애들은 그거 처음부터 잘했나
공부를 하다보면
어딜가나 학문의 방법론이 다 비슷비슷해요
똑같애 방법론 저기 기계공학 하는거다 생물하는거다 가서 보면
다 같은 과학적 방법론을 쓰고있어
내가 시간이 없어서 그렇지
3년이에요 3년
내가 컴공 박사라고 하면
다른학문으로 건너가는데 3년이면 충분해
전문가가 되는데에 몇시간이 필요하다그래요?
만시간?
만시간이 몇년이지
하루에 8시간 쓰면
4년이면 된
되네
별로 많진 않네
학무 4년 들으면
여러분 컴퓨터공학의 전문가라는 소리 들을거아냐
컴퓨터공학 전공하면 전문가 되어야되는거 아냐?

### Loop Distribution
루프안에
스테이트먼트 두개이상 들어가면
벡터리제이션이 잘 안돼요
그래서 일부러 이렇게 포문을 여러개로 쪼개주는거야

### Hardware Scheduling Unit in GPUs
지피유에서 스케줄링을 하는 제일 기본적인 단위

* 엔비디아: 워프라고 부름 (32 hardware thread)
* 암드: wavefront (64 hardware thread)
* 벤더마다 다른 이름을 씀

워크그룹 사이즈는 저 베이직 유닛의 배수인것이 더 나음. 코어가 놀아서.

### Consideration for Performance
여러가지가 있음

* 배리어 현명하게 쓰기. 싱크로나이제이션 하면 당근 느리지.
* Occupancy. 몇개의 워프가 현재 Active 한가. 레지스터 갯수를 줄이는게 중요함.

### Index Space Optimization

### Memory Coalescing

이재진교수님이
콩깐다
2등은 기억이 안돼요
여러분이 자일링스는 알아도
알테라는 모르죠?
인텔이
CPU 하나 놓고
옆에 FPGA를 넣으려고해요
프로토타이핑은 이미 했고
알테라랑 협력하다가
알테라를 사버렸어
SnuCL FPGA 버전이 1년후에 나올거야
안나오면 한놈이 박사를 못받아요
못받을 뿐더러 쫓겨날거야
우리가 알테라랑 MOU를 맺어서 연구를 하고있어요
인텔은 근데 내가 인텔을 안좋아해서 문젠데
나는 OpenCL도 그렇고
항상 2등하고만 일해요
왜냐
1등은 절박하지 않아
2등은 절박해서 협력이 잘돼
그리고 약자를 도와주는게 더 정의로워보이잖아
FPGA 시스템 트레이딩같은데에서 엄청 많이쓰고있어요
근데 우리는 하는사람이 없지

### Asynchronous Copy
### GPU Local Memory
### Control Flow
divergency

### 질문
##### 읽기전용 버퍼랑 이미지랑 왜 속도차이가 나나요?
그냥 하드웨어 자체가
텍스처메모리가 더 빠르게 만들어놔서 그럼
암드만 그렇고 엔비디아는 안그럴거에요
텍스처들이 들어가는곳
엔당에서 텍스처메모리라고 부르는 그것인거같은데여

##### 디폴트 워크 그룹 사이즈가 제일 빨라요?
아니에요. 절대 그렇지 않아요.

옵티멀한 워크그룹 사이즈 찾아내는 리서치를 많이 해요. 우리가 쓰는 방법이 뭐게?
딥러닝으로 찾음.

유전알고리즘은 이건 왜 잘돼는지 몰라. 심지어 이건 점치는거라고 이야기하는 사람도
있어.

--------

> 6월 8일

```
MMX
SSE
니가 좋아하는 동영상을 많이 보게되었어요
20년은 됐어
64비트 레지스터 안에
16비트 데이터를 여러개 넣어서
네 계산을 한방에 처리
픽셀 하나가 8bit면
RGBA 32비트를 한방에 처리
효과가 좋더라
데이터를 많이 넣는 방향으로 가고있음
128비트, 256비트
브로드웰 나오면 아마 컴플릿한 벡터 인스트럭션 셋이 지원 될거같은데
인텔쪽이랑 AMD랑 서로 다른 벡터인스트럭션을 써요
익스텐션이 달라
우근아
일곱배밖에 안빨라진다든데?
시퀄셜 포션이 길어가지고
네
랜덤 초기화하는부분이 있어서 그렇게 될거같긴 한데요
넌 몇배빨라졌냐?
제가 해본건 아니라서 모릅니다
우리가 예전에 숙제로 내줬었잖아.
네 근데 제가했을때엔 랜덤값을 파일에 저장해놨었어요
그럼 플젝에 그거 추가해
네
랜덤넘버 제네레이션 병렬로 돌리는건 아직까지 우리가 못하는거에요
<@wook> 플젝..
<@kcm^wvu> 플젝에 추가햌ㅋㅋㅋㅋ
랜덤이 뭐야
<@kcm^wvu> 병렬로는 아니더라도 SIMD 쓰는 pseudo random은 https://software.intel.com/en-us/articles/fast-random-number-generator-on-the-intel-pentiumr-4-processor
이재진교수님이
참 랜덤이 없지않을까 하는 이야기를 하셔서
벨 부등식 이야기를 말씀드림
선민준 역설
여기 메르스 걸린사람 있어요?
너무 혼내지마
<印> ??
여러분들은 몸 좋은 바이러스 인큐베이터야
<印> 전 갑자기 왜
EPR 역설 (?)
장내세균을 바꾸는 기술이 있더라
공생세균은
발란스가 중요해
좋은세균 안좋은세균이 있는게 아니라
일정 세균들이 일정 비율로 존재하는게 중요하지
근데 이 발란스가 깨진사람이 있어
맨날 설사하는거지
이 발란스를 맞추는 기법이 있대요
건강한사람 응아를 쓰는거지
학생) 근데 메르스는 균이 아니라 바이러스잖아요
<@kcm^wvu> 항생제로 싹 정리하고 넣으면 되나 (...
균이니 바이러스니 뭐가달러
여러분도 바이러스 맨날 먹으면서 살아요
끊임없이 감염되고 끊임없이 치료되면서 살고있어
<@wook> 다른데...
<@wook> ...
여러분들은 메르스 걸리면 그냥 건강한 면역력으로 물리치면 돼
나같은사람이 문제지
<@wook> ㅋㅋㅋㅋㅋ
내가 독감을 걸려보니까
정말 죽겠더라
근데 면역력 있는사람들은
<@kcm^wvu> standalone 바이러스 없나요 (?)
해열제 잘 먹고 하면 견딜 수 있으니까
크게 걱정하지 마세요
<@kcm^wvu> 정의상 없을 것 같긴 한데
메르스 죽는사람들 다
노약자래잖아
원래 폐렴있고 원래 신장병있는 사람들이 메르스가 트리거로 죽은거지
<@kcm^wvu> 저 경계를 애매하게 만드는 생명체 조합해보고 싶다
죽고 사는건 원래 하늘의 뜻이야
조심은 해야겠지만
너무 걱정할필요는 없다 이거야
패닉하지 마세요
벡타 보면
SIMDization
<@kcm^wvu> ㅋㅋㅋㅋ
나는 우리 아버지꼐서
연로하신데
감기걸리셨다셔서 마스크 쓰고 갔더니만
옆에있던 다른환자들이 막 욕을했대
어떻게 아들이라는 놈이 마스크를 쓰고 병문안을 와
내가
<@kcm^wvu> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
응 그사람들한테 안옮길라고 마스크쓰고간건데
왜 욕을해
내가 그 병문안갔을때
좀 전에 치과를 갔는데 내가 막 목이 붓고 기침이 나오더라고
그래서 마스크쓰고갔더니만
보통 벡타 레지스터가 있어서
보통 32비트보다 커요 이 크기가
CPU 안에 여러 종류의 벡타 레지스터가 준비되어있어
얘네들을 쓸라그러면 특별한 벡타 인스트럭션을 써야돼고
*되
그다음에
GPU는 뭐라그랬어요
GPU도 SIMD인데
지피유는 어떻다그랬어
하나의 인스트럭션이 있으면 이걸 카피를 해서 여러개의 ALU가 돌린다그랬지
고게 다르다
여러 연산을 한번에 하는데
프로그램 카운터는 하나다
Auto 벡터리제이션은
굉장히 민감해요
아주 조금씩만 뭐 해줘도 안되고 막 그래
이건 30년전에 다 끝난연구야
포인터같은거 덜쓰고 그래야 벡터화가 잘돼
벡터화 잘할라면 컴파일러가 어떻게 작동하는지도 잘 알아야돼
그러면 사람이 벡터화 잘되게 코딩해줄 수 있지
인텔의 MMX, SSE, AVX
인텔의 제온빠이에는 512비트와이드 벡터가 들어있지
MMX는 길어야 128비트야
512비트면 32비트가 한번에 16개 들어가지
IBM 파워피시는 AltiVec
ARM은 Neon
여러분 갖고있는 핸드폰도 다 벡터리제이션 다 돼요
이중에 컴파일러 제일 구린게 어느걸까?
ARM이 제일 구려요
IBM 컴파일러가 굉장히 쎘어 옛날부터
IBM 왓슨 이런거에 여러 컴파일러 논문이 나왔죠
IBM같은게 미국 국민기업이에요
내가 석사받고 연습삼아 취직이력서 냈더니만
코리안이라 냈더니
내 인터뷰만 오래하더라고
거기 30명 들어있는데
나하고 다른애만 양복입고
28명은 다 청바지입고왔는데
거기 인터뷰갔더니 애가
정말 미안하다고
시민권 없으면 못뽑는다 그러더라고
요즘은 많이 뽑아요
그당시에도 박사는 다 시티즌쉽 없어도 다 뽑고 그랬지만
벡터 슈퍼컴퓨터로 제일 먼저 나온게 크레이 원이에요
로드스토어, 스칼라 레지스터, 64비트 레지스터
이게 76년인데 그당시는 데이터가 8비트 16비트 이랬으니 64비트 레지스터는 큰거지
메모리 인터리빙이 모야
아이 시험을 쳐야돼는데
<@wook> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
메모리를
한 칩에 싹다 몰아넣는것보다
여러 칩에 나눠 넣는게 더 낫지?
이게 메모리 인터리빙이야
이게 좀 웃긴게
크레이쪽은 버추얼메모리도 없고 캐쉬도 없는데
엄청나게 빨라
여러 다른방법을 쓴거지
요새는 AMD에서 나온 옵테론을 사서 클러스터로 만들어요
그래서 요즘은 얘네만의 아키텍처랄만한건 없는데
그당시엔 제일 앞섰지
멀티미디아 익스텐션이라 그래서
인텔에서 MMX랑 SSE를 내놨어
동영상 빨리보려고
Limited vector instruction set
모든 벡터연산을 다 주지 않았어
No vector length control
No strided load/store, No scatter/gather
띄엄띄엄 떨어져있는 메모리를 한번에 액세스 못하는거지
또 벡터 쓸라면
64/128비트 바운더리로 얼라인 되어있어야 하고
벡타레지스터 길이가 짧았기때문에
벡터연산이지만 스칼라연산에 비해 2배정도밖에 안빨랐어
그래서 슈퍼스칼라 디스패치의 힘을 빌려야했어
슈퍼스칼라가 뭐야
CU가 여러개있다고?
동시에 여러개의 인스트럭션을 이슈하는거지
벡타의 길이가 짧으니까
펑셔널 유닛이 100% 유틸라이즈가 안되니까
슈퍼스칼라로 이걸 끌어올리는거지
루프언롤링을 해서 레이턴시 하이딩을 할 수 있지
언롤링하면 안좋은점이 뭐라그럤어 레지스터 프레셔가 높아지지
이건 트레이드오프고
Unalgined Memory Accesses
dㅕ러분 이거 지난번에 한번 설명 했죠
안했나?
책에 있어
안읽어봤지?
<@kcm^wvu> ㅋㅋ
중간범위인데 이거?
간단하게 이거 볼필요 없고
예를 봅시다
얼라인이 안되며는
딱 메모리 4바이트 액세스하는데 이 4바이트가 캐쉬에 걸쳐있다고 쳐봐
그러면 여기서 읽고 여기서 읽어서 합쳐야될거아냐
그러니까 얼라인을 하는거지
<@kcm^wvu> movdqa movdqu 인스트럭션이 생각나는 시점
<@kcm^wvu> 음.. 캐시 바운더리만 아니면 운좋게 작동하는 건 그런 이유인가 (?
얼라인이 안되는걸
허용하는 아키텍처도 있고
없는 아키텍처도 있는데
보통 벡터인스트럭션을 얼라인먼트를 엄격하게 맞춰줘야돼
<@p> 안 되는거면 프로세서 설계 하기 쉽겠징
벡타인스트럭션도 스칼라 인스트럭션이랑 똑같아요
메모리액세스 데이터카피 타입컨버젼 데이타프로세싱
Vector intrinsics
인라인 어셈블리로 벡타를 써도 되지만
함수로 만들어놓으면 더 좋지
인라이닝을 해서 함수호출 오버헤드를 줄일 수 있지
컴파일러가 알아서 다 해준다
보통 함수단위로 레지스터 알로케이션을 해요
레지스터 알로케이션 안배웠어?
<@p> 컴파일러!
컨트롤 플로우 그래프 나온게 다 함수단위였잖아
이게 함수니까 벡터인스트릭식을 부르는 함수하고 불리는 인트린식 안의 함수하고 다 고려해서 레지스터 알로케이션이 되어야 더 좋은건데
함수로 해버리니까 이게 별도로 취급되지
그래서 특별히 이걸 인라인해서
저런 오버헤드가 없게하는거야
인라인 어셈블리를 쓰는거랑 차이가 없게만드는거지
벡터인트린짓
컴파일러가 제공하는 빌트인 함수
사용하긴 좀 복잡해요
여러 규약도 있고 종류도 아주 많아
하지만 효율적인 벡터연산을 수행할 수 있어요
그래서 이건 좀 아는사람이 해야되고
여러분들은 오토매틱하게 다 척척되는거 좋아하잖아
그건 gcc가 이제 다 알아서 해주는거지
벡터인트린직의 예를 보며는
<@kcm^wvu> ICC 만세 (뜬금없는 찬양)
여기 애드라는 어떤 함수가 있고 여기 뽀 루프가 있고 여기 덧셈하는게 있지
이거 포문을
이 부분만 따로 떼면
벡터화가 돼요
여기 디펜던스가 있어없어
없으니까 벡터화 다 된다고
디펜던스 어날러시스랑 벡터화랑 똑같은 연구야
디펜던스가 없어야돼
인텔 SSE의 벡타 인트린직을 이용을할수가 있는데
방금 봤던거 봐라
v4sf A = __builtin_ia32_loadups(a + i);
v4sf B = __builtin_ia32_loadups(b + i);
<@kcm^wvu> for (int i = 0; i < 64; i++) a[i] = i; <- 이런 것도 해줌. a[0~3] = {0,1,2,3}, a[i~i+3] = a[i-4~i-1]+{4,4,4,4}
v4sf C = __builtin_ia32_addps(A, B);
<@wook> 오 재밌는 내용이당
학생)교수님 근데 이거 CPU가 32비트인걸 알고쓰는거 아닌가요
당연하지
이건 아키텍처 디펜던트한거야
typedef float v4sf __attribute__ ((vector_size (16)));
<@kcm^wvu> int c[4]; for (int i = 0; i < 4; i++) c[i] = a[i] + b[i]; 하면 리얼 저렇게 하는데 개신기
4바이트가 네개라는 소리야
이건 인텔이에요
IA32
아키텍처 레퍼런스 메뉴얼에 다 써있어요
교수님 size가 4의배수가 아니면 어떻게돼요
세그폴나지 않을까?
그니까
size % 4 해서
남는 맨 마지막 부분만 따로 처리해야돼
<@kcm^wvu> for (int i = 0; i < n; i++) 하면 실제로 -O3에 flag 잘 주면 남는 거 따로 처리... (괴물들)
이게 또
gcc에서랑 icc에서랑 하는법이 달라
icc는 여러분 공짜야
<@kcm^wvu> ?!
<@kcm^wvu> 오픈소스 하고 있다고 증명해야 하던데
icc가 20프로정도 빨라요
여러분들은 그냥 쓸 수 있다니까
벡터화를 어떻게 해야하는거
벡터화를 어떻게 해야하는가
벡터화가 되는 조건을 알아야될거아냐
<**> 2년 전에는 academic licence 있었는데
<**> 지금은 모르겠다
Triplet Notation
<**> 근데 그게 인텔 홈페이지에서 찾기 힘들었음 [?]
배열갔다 계산하는걸 트리플렛 노테이션으로 써보자
a[0:m:2]
첫번째가 엘리먼트의 인덱스, 두번째가 마지막 인덱스, 세번째가 step
<@kcm^wvu> https://software.intel.com/en-us/qualify-for-free-software 어머 진짜로 있네요
<@elnn> 여기가 컴파일러 수업하는 곳인가용
a[0:m:2]라고 쓰면 a[0], a[2], a[4], ...
a[m:0:-2] 라고 쓰면 반대방향
세번째꺼 omit하면 1
a[0:99] 는 a[0], a[1], ... a[99]
for (int i=0; i<100; ++i) a[i] = b[i]
이거 줄여서
a[0:99] = b[0:99]
a[0:m:2] = b[m:0:-2]
이거 벡터화를 해보자
제나랄 룰은 모냐
<@kcm^wvu> shuffle해야 할 것 같은데.. ㅎㄷㄷ
A statement contained in at least one loop can be vectorized if the statement is not included in any cycle of dependences
for(~) { a[i+1] = a[i] + b[i] } 이런건 사이클로 트루 디펜던시가 있지
이런건 안돼
for룹 안에 스테이트먼트가 여러개 있는데 디펜던시가 단방향이다
이러면 loop distribution 하면 돼요
<@kcm^wvu> !
Loop carried 디펜던스가 아니잖아
룹 디스트리뷰션의 조건이 뭐였죠?
방향이 바뀌면 안되는거잖아
이렇게 각각 쪼개면
둘다 벡터화가 가능하지
Vector Scatter/Gather 인스트럭쎤
썹스크립트 오브 썹스크립트
for(~) { A[i] = B[i] + C[D[i]] };
이런건 어떻게할까
인덱스가 어디로 건너뛸지 모르죠
이걸 한꺼번에 다 끌어올 수 있는게 개더에요
스캐터는 반대
for(~) { A[B[i]] = C[i] + i; }
멀티미디어 인스트럭션엔 이게 안들어가있어
제온빠이엔 있어요
굉장히 에fㅣ시언트해요
이거 쓰면 얼마나 빨라져 우근?
두배정도 빨라져요
두배정도 빨라진대
굉장히 편리해요
이거 중간고사 보너스문젠대
한놈도 못풀었다며?
큰일났다
<@p> zzzzzz
Vector Conditional Execution
뽀문 앞에 이프문이 있지
요것도 벡터화가 된다
요건 MMX에도 부분적으로 있고
AVX에 완전하게 있지
Vector Reduction
벡터 리덕쎤도 있지
벡터는 왜 리덕션을 해야겠어
벡터는 길이가 있잖아
네개까지밖에 못하면 한번에 네개씩 해주면 되지
sum = 0; for(~) { sum += A[i]; }
(교수님이 상상했던 알고리즘과 피피티에 써있는 코드가 다름)
Strip Mining
루프를 벡터 길이에 맞게 여러조각으로 잘라서
벡터길이만큼 한번에 하기
왜 다음장이 없지?
끝 아닌데
메르스도 돌고 하는데
종강이나 할까
쿠다는 가르치기 싫고
질문) 쿠다는 더 쉬워요?
<**> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
난이도는 더 똑같아요
거의 1:1 매핑이 돼
용어만 달러
질문) OpenCL 너무 쓰기 어려운거가타서
써봐
CUDA -> OpenCL은 안되는게 있어
OpenCL -> CUDA는 다 되지
질문) 덧셈순서 바꾸면 결과가 달라지는데
과제 스펙에 결과 달라지면 안된대서
피곤해여
0.5초 차이로 아이패드 날아가면 뼈아프겠다
우리가 인턴을 모집하고있는데
인턴 하고픈사람 연락해요
여름방학동안이나 뭐
엄청나게 빡셀거야
문귀환이 너 왜 질문안해
저요?
잘 하지도 못하고
잘 하지도 못하는거 아네
전에 질문했을땐 잘 하는거같았어?
아뇨 의욕이 떨어졌어요
그래 넌 조금 조용히있는게 더 좋은거야
<@p> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<**> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
이런것도 경험하고 이런것도 경험하고
근데 너 무슨 일 있냐?
무ㅡㄴ일인데
사
사적인일이야?
네 사적인 일이에요
죽고 사는건 다 하늘 뜻이잖아
그런말 있잖아 안죽으면 다 니한테 도움 되는거라고
<@Nemo> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
(니체 인용인듯)
<@Nemo> what doesn't kill you makes you stronger?
우리떈 수강신청할라면
<@Nemo> but the important thing is that it almost kills you
손으로 적어서 도장 받아야했어
근데 요즘은 많이 발전해서
막 암거나 신청하고
알고싶은거 있으면 수업 안듣고 인터넷에 찾아보면 되잖아
우리땐 인터넷도 없었어
심지어 영어 못해도
인터넷에서 다 고쳐주지
우리는 논문 못구했어요
도서관에 없으면 그냥 논문 못보는거였어
그래서 교수님들 안식년때 주로 하는일이
미국가서
논문 수만페이지씩 복사해오는거였어
오늘이 마지막 수업인데
행정적으로 할말이 있나?
질문
시간 많이 남았으니까 다른 질문 있으니까 해봐요
어떤거라도 좋으니까
질문) 교재는 언제나와요?
내가 기운이 빠져서 못하고있어요
이제 곧 다시 시작할거야
누가 책에 한 챕터를 써달라그래서
그 다른책을 먼저 써야돼
써주고
8월달에 다시 시작하면
연말쯤 나오지 않을까
학생) 교수님도 개강때엔 열심히하고 종강즈음엔 천천히 하시는거같아요
니가 8시에 집에 들어가봐
<**> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
와이프가 좋아하나
도저히 두달 하니까 못하겠어
체력도 떨어지고
<@p> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@p> ㅠㅠ
<@p> 8시에 집에 가고 싶다
<@Gallen> 엌ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
우큰) 근데 요즘도 고무동력기 많이하시잖아요
<**> 저 8시는 아침 8시겠지
<@p> ㅇㅎ
고무동력기는 하다가 기분전환하려고 하는거야
<@p> 8시에 안 가고 싶어요
히익 오따꾸
<@kcm^wvu> 고무동력깈ㅋㅋㅋ
그 책 1/3정도 썼어요
연말엔 좀 쉴라고
200페이지정도 됐나
200페이지 넘었을거같은데?
1/4쯤 썼네
천천히 다시 시동을 걸어야겠어
<**> 맞아 빨리 오타비 달라고 해 [?]
아 맞아
오타비는
프로젝트 끝나고나면
공고를 할거야
내가
학생별로 다 돈 세어서
조교한테 돈을 맡겨놓을테니까
원래 그렇게했어
<@Gallen> 크
안찾아가는애들 좀 있었지?
한명도 남김없이 다 찾아갔었어요
그래?
그거 얼마나한다고
팥빙수 한두개 사먹으면 끝나는돈인데
애들 데리고
<@Nemo> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㄲ
투썸플레이스 가면 좋아하던데
애들이 금방알아 뭐가 맛있는지
<@p> 그 팥빙수 한두개 사먹으려고 받아가는거 아닌가!
녹두에 설빙 새로 생겼지?
거기도 한번 가야되는데
설빙 맛있든데
<@p> 좀 오래 됐는데
아
하 십...
다른 질문있으면 해봐요
<@p> 뭐지
질문) 수업 뒷풀이 안하나요
안해 임마
<@p> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@kcm^wvu> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
갑자기 한숨쉬셨음
<@Gallen> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@Gallen> 안해 임맠ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
내가 아이패드를 주는데
양심이 있지
<@p> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
플젝 끝나고 주면 되겠다
뒷풀이
어떤데가 좋아?
교수님 집이요
너 우리집 함 와볼래?
<@p> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
우리 대학원생도 초대 못하는곳인데
<@p> 미치겠다
<**> 이사람들잌ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
<@Gallen> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
25평 아파트에 살아
큰애들 두명
<@Gallen> 캬
초등학생 두명
집 빨리 큰데로 옮겨야되는데
여기 낙성대 아파트에 있는 집이야
그래서 난 술먹고 늦게들어가도 도
돼
낙성대에서 마시면
어디가 좋아?
낙성대가 좋은것같습니다
시골집 같은데 좋나?
<@p> ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
삼겹살 구워먹으면 좋아?
그럼 거기를 잡아갖고 한번 해볼게
요새 소주가 좋은게 나왔는데
순하리라고
야 난 그게
디게좋드라고
너네 다 아네?
그건 대박을 터뜨리겠든데
<**> 근데 플젝 듀가 언제임?
<**> 19일?
19일이요
<**> 그렇군
<**> 22일이나 23일쯤이 적당하겠다
<**> (뒷풀이)
요즘 허니버터가 우후죽순처럼 등장하잖아
전부 허니버터가 들어있는게 나와서
<**> 그 뒤로는 조교가 당분간 서울에 없어서
맛이 다똑같애
요즘도 허니버터칩 품귀인가?
요새도 없나
아직까지도 그래?
우리집은 다 안좋아해
있어도 안먹어
짜와는 어때
짜와 몰라?
짜파게티 말고
나는 아직 못먹어봤는데
내가 그걸 한번 먹어볼라고
한심하다
한학기동안 수고했어요
공고할께 거 뒷풀이는
오케이
```
